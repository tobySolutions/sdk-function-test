import {
  empty_exports,
  init_empty
} from "./chunk-UHP4SR3D.js";
import {
  require_aspromise,
  require_base64,
  require_eventemitter,
  require_float,
  require_inquire,
  require_pool,
  require_utf8,
  require_varint
} from "./chunk-77WUQNS7.js";
import {
  __commonJS,
  __export,
  __privateAdd,
  __privateGet,
  __privateSet,
  __publicField,
  __toESM
} from "./chunk-DNE4QC7K.js";

// ../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/lib/retry_operation.js
var require_retry_operation = __commonJS({
  "../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/lib/retry_operation.js"(exports, module) {
    function RetryOperation(timeouts, options) {
      if (typeof options === "boolean") {
        options = { forever: options };
      }
      this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));
      this._timeouts = timeouts;
      this._options = options || {};
      this._maxRetryTime = options && options.maxRetryTime || Infinity;
      this._fn = null;
      this._errors = [];
      this._attempts = 1;
      this._operationTimeout = null;
      this._operationTimeoutCb = null;
      this._timeout = null;
      this._operationStart = null;
      this._timer = null;
      if (this._options.forever) {
        this._cachedTimeouts = this._timeouts.slice(0);
      }
    }
    module.exports = RetryOperation;
    RetryOperation.prototype.reset = function() {
      this._attempts = 1;
      this._timeouts = this._originalTimeouts.slice(0);
    };
    RetryOperation.prototype.stop = function() {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (this._timer) {
        clearTimeout(this._timer);
      }
      this._timeouts = [];
      this._cachedTimeouts = null;
    };
    RetryOperation.prototype.retry = function(err) {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (!err) {
        return false;
      }
      var currentTime = (/* @__PURE__ */ new Date()).getTime();
      if (err && currentTime - this._operationStart >= this._maxRetryTime) {
        this._errors.push(err);
        this._errors.unshift(new Error("RetryOperation timeout occurred"));
        return false;
      }
      this._errors.push(err);
      var timeout = this._timeouts.shift();
      if (timeout === void 0) {
        if (this._cachedTimeouts) {
          this._errors.splice(0, this._errors.length - 1);
          timeout = this._cachedTimeouts.slice(-1);
        } else {
          return false;
        }
      }
      var self2 = this;
      this._timer = setTimeout(function() {
        self2._attempts++;
        if (self2._operationTimeoutCb) {
          self2._timeout = setTimeout(function() {
            self2._operationTimeoutCb(self2._attempts);
          }, self2._operationTimeout);
          if (self2._options.unref) {
            self2._timeout.unref();
          }
        }
        self2._fn(self2._attempts);
      }, timeout);
      if (this._options.unref) {
        this._timer.unref();
      }
      return true;
    };
    RetryOperation.prototype.attempt = function(fn, timeoutOps) {
      this._fn = fn;
      if (timeoutOps) {
        if (timeoutOps.timeout) {
          this._operationTimeout = timeoutOps.timeout;
        }
        if (timeoutOps.cb) {
          this._operationTimeoutCb = timeoutOps.cb;
        }
      }
      var self2 = this;
      if (this._operationTimeoutCb) {
        this._timeout = setTimeout(function() {
          self2._operationTimeoutCb();
        }, self2._operationTimeout);
      }
      this._operationStart = (/* @__PURE__ */ new Date()).getTime();
      this._fn(this._attempts);
    };
    RetryOperation.prototype.try = function(fn) {
      console.log("Using RetryOperation.try() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = function(fn) {
      console.log("Using RetryOperation.start() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = RetryOperation.prototype.try;
    RetryOperation.prototype.errors = function() {
      return this._errors;
    };
    RetryOperation.prototype.attempts = function() {
      return this._attempts;
    };
    RetryOperation.prototype.mainError = function() {
      if (this._errors.length === 0) {
        return null;
      }
      var counts = {};
      var mainError = null;
      var mainErrorCount = 0;
      for (var i = 0; i < this._errors.length; i++) {
        var error3 = this._errors[i];
        var message = error3.message;
        var count = (counts[message] || 0) + 1;
        counts[message] = count;
        if (count >= mainErrorCount) {
          mainError = error3;
          mainErrorCount = count;
        }
      }
      return mainError;
    };
  }
});

// ../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/lib/retry.js
var require_retry = __commonJS({
  "../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/lib/retry.js"(exports) {
    var RetryOperation = require_retry_operation();
    exports.operation = function(options) {
      var timeouts = exports.timeouts(options);
      return new RetryOperation(timeouts, {
        forever: options && (options.forever || options.retries === Infinity),
        unref: options && options.unref,
        maxRetryTime: options && options.maxRetryTime
      });
    };
    exports.timeouts = function(options) {
      if (options instanceof Array) {
        return [].concat(options);
      }
      var opts = {
        retries: 10,
        factor: 2,
        minTimeout: 1 * 1e3,
        maxTimeout: Infinity,
        randomize: false
      };
      for (var key in options) {
        opts[key] = options[key];
      }
      if (opts.minTimeout > opts.maxTimeout) {
        throw new Error("minTimeout is greater than maxTimeout");
      }
      var timeouts = [];
      for (var i = 0; i < opts.retries; i++) {
        timeouts.push(this.createTimeout(i, opts));
      }
      if (options && options.forever && !timeouts.length) {
        timeouts.push(this.createTimeout(i, opts));
      }
      timeouts.sort(function(a, b) {
        return a - b;
      });
      return timeouts;
    };
    exports.createTimeout = function(attempt, opts) {
      var random = opts.randomize ? Math.random() + 1 : 1;
      var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));
      timeout = Math.min(timeout, opts.maxTimeout);
      return timeout;
    };
    exports.wrap = function(obj, options, methods) {
      if (options instanceof Array) {
        methods = options;
        options = null;
      }
      if (!methods) {
        methods = [];
        for (var key in obj) {
          if (typeof obj[key] === "function") {
            methods.push(key);
          }
        }
      }
      for (var i = 0; i < methods.length; i++) {
        var method = methods[i];
        var original = obj[method];
        obj[method] = function retryWrapper(original2) {
          var op = exports.operation(options);
          var args = Array.prototype.slice.call(arguments, 1);
          var callback = args.pop();
          args.push(function(err) {
            if (op.retry(err)) {
              return;
            }
            if (err) {
              arguments[0] = op.mainError();
            }
            callback.apply(this, arguments);
          });
          op.attempt(function() {
            original2.apply(obj, args);
          });
        }.bind(obj, original);
        obj[method].options = options;
      }
    };
  }
});

// ../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/index.js
var require_retry2 = __commonJS({
  "../../node_modules/.pnpm/retry@0.13.1/node_modules/retry/index.js"(exports, module) {
    module.exports = require_retry();
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/util/longbits.js
var require_longbits = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/util/longbits.js"(exports, module) {
    "use strict";
    module.exports = LongBits;
    var util = require_minimal();
    function LongBits(lo, hi) {
      this.lo = lo >>> 0;
      this.hi = hi >>> 0;
    }
    var zero = LongBits.zero = new LongBits(0, 0);
    zero.toNumber = function() {
      return 0;
    };
    zero.zzEncode = zero.zzDecode = function() {
      return this;
    };
    zero.length = function() {
      return 1;
    };
    var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";
    LongBits.fromNumber = function fromNumber(value) {
      if (value === 0)
        return zero;
      var sign2 = value < 0;
      if (sign2)
        value = -value;
      var lo = value >>> 0, hi = (value - lo) / 4294967296 >>> 0;
      if (sign2) {
        hi = ~hi >>> 0;
        lo = ~lo >>> 0;
        if (++lo > 4294967295) {
          lo = 0;
          if (++hi > 4294967295)
            hi = 0;
        }
      }
      return new LongBits(lo, hi);
    };
    LongBits.from = function from19(value) {
      if (typeof value === "number")
        return LongBits.fromNumber(value);
      if (util.isString(value)) {
        if (util.Long)
          value = util.Long.fromString(value);
        else
          return LongBits.fromNumber(parseInt(value, 10));
      }
      return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
    };
    LongBits.prototype.toNumber = function toNumber(unsigned) {
      if (!unsigned && this.hi >>> 31) {
        var lo = ~this.lo + 1 >>> 0, hi = ~this.hi >>> 0;
        if (!lo)
          hi = hi + 1 >>> 0;
        return -(lo + hi * 4294967296);
      }
      return this.lo + this.hi * 4294967296;
    };
    LongBits.prototype.toLong = function toLong(unsigned) {
      return util.Long ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned)) : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
    };
    var charCodeAt = String.prototype.charCodeAt;
    LongBits.fromHash = function fromHash(hash) {
      if (hash === zeroHash)
        return zero;
      return new LongBits(
        (charCodeAt.call(hash, 0) | charCodeAt.call(hash, 1) << 8 | charCodeAt.call(hash, 2) << 16 | charCodeAt.call(hash, 3) << 24) >>> 0,
        (charCodeAt.call(hash, 4) | charCodeAt.call(hash, 5) << 8 | charCodeAt.call(hash, 6) << 16 | charCodeAt.call(hash, 7) << 24) >>> 0
      );
    };
    LongBits.prototype.toHash = function toHash() {
      return String.fromCharCode(
        this.lo & 255,
        this.lo >>> 8 & 255,
        this.lo >>> 16 & 255,
        this.lo >>> 24,
        this.hi & 255,
        this.hi >>> 8 & 255,
        this.hi >>> 16 & 255,
        this.hi >>> 24
      );
    };
    LongBits.prototype.zzEncode = function zzEncode() {
      var mask2 = this.hi >> 31;
      this.hi = ((this.hi << 1 | this.lo >>> 31) ^ mask2) >>> 0;
      this.lo = (this.lo << 1 ^ mask2) >>> 0;
      return this;
    };
    LongBits.prototype.zzDecode = function zzDecode() {
      var mask2 = -(this.lo & 1);
      this.lo = ((this.lo >>> 1 | this.hi << 31) ^ mask2) >>> 0;
      this.hi = (this.hi >>> 1 ^ mask2) >>> 0;
      return this;
    };
    LongBits.prototype.length = function length4() {
      var part0 = this.lo, part1 = (this.lo >>> 28 | this.hi << 4) >>> 0, part2 = this.hi >>> 24;
      return part2 === 0 ? part1 === 0 ? part0 < 16384 ? part0 < 128 ? 1 : 2 : part0 < 2097152 ? 3 : 4 : part1 < 16384 ? part1 < 128 ? 5 : 6 : part1 < 2097152 ? 7 : 8 : part2 < 128 ? 9 : 10;
    };
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/util/minimal.js
var require_minimal = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/util/minimal.js"(exports) {
    "use strict";
    var util = exports;
    util.asPromise = require_aspromise();
    util.base64 = require_base64();
    util.EventEmitter = require_eventemitter();
    util.float = require_float();
    util.inquire = require_inquire();
    util.utf8 = require_utf8();
    util.pool = require_pool();
    util.LongBits = require_longbits();
    util.isNode = Boolean(typeof global !== "undefined" && global && global.process && global.process.versions && global.process.versions.node);
    util.global = util.isNode && global || typeof window !== "undefined" && window || typeof self !== "undefined" && self || exports;
    util.emptyArray = Object.freeze ? Object.freeze([]) : (
      /* istanbul ignore next */
      []
    );
    util.emptyObject = Object.freeze ? Object.freeze({}) : (
      /* istanbul ignore next */
      {}
    );
    util.isInteger = Number.isInteger || /* istanbul ignore next */
    function isInteger(value) {
      return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
    };
    util.isString = function isString(value) {
      return typeof value === "string" || value instanceof String;
    };
    util.isObject = function isObject(value) {
      return value && typeof value === "object";
    };
    util.isset = /**
     * Checks if a property on a message is considered to be present.
     * @param {Object} obj Plain object or message instance
     * @param {string} prop Property name
     * @returns {boolean} `true` if considered to be present, otherwise `false`
     */
    util.isSet = function isSet(obj, prop) {
      var value = obj[prop];
      if (value != null && obj.hasOwnProperty(prop))
        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
      return false;
    };
    util.Buffer = function() {
      try {
        var Buffer = util.inquire("buffer").Buffer;
        return Buffer.prototype.utf8Write ? Buffer : (
          /* istanbul ignore next */
          null
        );
      } catch (e) {
        return null;
      }
    }();
    util._Buffer_from = null;
    util._Buffer_allocUnsafe = null;
    util.newBuffer = function newBuffer(sizeOrArray) {
      return typeof sizeOrArray === "number" ? util.Buffer ? util._Buffer_allocUnsafe(sizeOrArray) : new util.Array(sizeOrArray) : util.Buffer ? util._Buffer_from(sizeOrArray) : typeof Uint8Array === "undefined" ? sizeOrArray : new Uint8Array(sizeOrArray);
    };
    util.Array = typeof Uint8Array !== "undefined" ? Uint8Array : Array;
    util.Long = /* istanbul ignore next */
    util.global.dcodeIO && /* istanbul ignore next */
    util.global.dcodeIO.Long || /* istanbul ignore next */
    util.global.Long || util.inquire("long");
    util.key2Re = /^true|false|0|1$/;
    util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;
    util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;
    util.longToHash = function longToHash(value) {
      return value ? util.LongBits.from(value).toHash() : util.LongBits.zeroHash;
    };
    util.longFromHash = function longFromHash(hash, unsigned) {
      var bits = util.LongBits.fromHash(hash);
      if (util.Long)
        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
      return bits.toNumber(Boolean(unsigned));
    };
    function merge(dst, src4, ifNotSet) {
      for (var keys2 = Object.keys(src4), i = 0; i < keys2.length; ++i)
        if (dst[keys2[i]] === void 0 || !ifNotSet)
          dst[keys2[i]] = src4[keys2[i]];
      return dst;
    }
    util.merge = merge;
    util.lcFirst = function lcFirst(str) {
      return str.charAt(0).toLowerCase() + str.substring(1);
    };
    function newError(name14) {
      function CustomError(message, properties) {
        if (!(this instanceof CustomError))
          return new CustomError(message, properties);
        Object.defineProperty(this, "message", { get: function() {
          return message;
        } });
        if (Error.captureStackTrace)
          Error.captureStackTrace(this, CustomError);
        else
          Object.defineProperty(this, "stack", { value: new Error().stack || "" });
        if (properties)
          merge(this, properties);
      }
      CustomError.prototype = Object.create(Error.prototype, {
        constructor: {
          value: CustomError,
          writable: true,
          enumerable: false,
          configurable: true
        },
        name: {
          get: function get15() {
            return name14;
          },
          set: void 0,
          enumerable: false,
          // configurable: false would accurately preserve the behavior of
          // the original, but I'm guessing that was not intentional.
          // For an actual error subclass, this property would
          // be configurable.
          configurable: true
        },
        toString: {
          value: function value() {
            return this.name + ": " + this.message;
          },
          writable: true,
          enumerable: false,
          configurable: true
        }
      });
      return CustomError;
    }
    util.newError = newError;
    util.ProtocolError = newError("ProtocolError");
    util.oneOfGetter = function getOneOf(fieldNames) {
      var fieldMap = {};
      for (var i = 0; i < fieldNames.length; ++i)
        fieldMap[fieldNames[i]] = 1;
      return function() {
        for (var keys2 = Object.keys(this), i2 = keys2.length - 1; i2 > -1; --i2)
          if (fieldMap[keys2[i2]] === 1 && this[keys2[i2]] !== void 0 && this[keys2[i2]] !== null)
            return keys2[i2];
      };
    };
    util.oneOfSetter = function setOneOf(fieldNames) {
      return function(name14) {
        for (var i = 0; i < fieldNames.length; ++i)
          if (fieldNames[i] !== name14)
            delete this[fieldNames[i]];
      };
    };
    util.toJSONOptions = {
      longs: String,
      enums: String,
      bytes: String,
      json: true
    };
    util._configure = function() {
      var Buffer = util.Buffer;
      if (!Buffer) {
        util._Buffer_from = util._Buffer_allocUnsafe = null;
        return;
      }
      util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from || /* istanbul ignore next */
      function Buffer_from(value, encoding) {
        return new Buffer(value, encoding);
      };
      util._Buffer_allocUnsafe = Buffer.allocUnsafe || /* istanbul ignore next */
      function Buffer_allocUnsafe(size5) {
        return new Buffer(size5);
      };
    };
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/writer.js
var require_writer = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/writer.js"(exports, module) {
    "use strict";
    module.exports = Writer2;
    var util = require_minimal();
    var BufferWriter;
    var LongBits = util.LongBits;
    var base643 = util.base64;
    var utf84 = util.utf8;
    function Op(fn, len, val) {
      this.fn = fn;
      this.len = len;
      this.next = void 0;
      this.val = val;
    }
    function noop2() {
    }
    function State2(writer) {
      this.head = writer.head;
      this.tail = writer.tail;
      this.len = writer.len;
      this.next = writer.states;
    }
    function Writer2() {
      this.len = 0;
      this.head = new Op(noop2, 0, 0);
      this.tail = this.head;
      this.states = null;
    }
    var create19 = function create20() {
      return util.Buffer ? function create_buffer_setup() {
        return (Writer2.create = function create_buffer() {
          return new BufferWriter();
        })();
      } : function create_array() {
        return new Writer2();
      };
    };
    Writer2.create = create19();
    Writer2.alloc = function alloc3(size5) {
      return new util.Array(size5);
    };
    if (util.Array !== Array)
      Writer2.alloc = util.pool(Writer2.alloc, util.Array.prototype.subarray);
    Writer2.prototype._push = function push2(fn, len, val) {
      this.tail = this.tail.next = new Op(fn, len, val);
      this.len += len;
      return this;
    };
    function writeByte(val, buf2, pos) {
      buf2[pos] = val & 255;
    }
    function writeVarint32(val, buf2, pos) {
      while (val > 127) {
        buf2[pos++] = val & 127 | 128;
        val >>>= 7;
      }
      buf2[pos] = val;
    }
    function VarintOp(len, val) {
      this.len = len;
      this.next = void 0;
      this.val = val;
    }
    VarintOp.prototype = Object.create(Op.prototype);
    VarintOp.prototype.fn = writeVarint32;
    Writer2.prototype.uint32 = function write_uint32(value) {
      this.len += (this.tail = this.tail.next = new VarintOp(
        (value = value >>> 0) < 128 ? 1 : value < 16384 ? 2 : value < 2097152 ? 3 : value < 268435456 ? 4 : 5,
        value
      )).len;
      return this;
    };
    Writer2.prototype.int32 = function write_int32(value) {
      return value < 0 ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) : this.uint32(value);
    };
    Writer2.prototype.sint32 = function write_sint32(value) {
      return this.uint32((value << 1 ^ value >> 31) >>> 0);
    };
    function writeVarint64(val, buf2, pos) {
      while (val.hi) {
        buf2[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
      }
      while (val.lo > 127) {
        buf2[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
      }
      buf2[pos++] = val.lo;
    }
    Writer2.prototype.uint64 = function write_uint64(value) {
      var bits = LongBits.from(value);
      return this._push(writeVarint64, bits.length(), bits);
    };
    Writer2.prototype.int64 = Writer2.prototype.uint64;
    Writer2.prototype.sint64 = function write_sint64(value) {
      var bits = LongBits.from(value).zzEncode();
      return this._push(writeVarint64, bits.length(), bits);
    };
    Writer2.prototype.bool = function write_bool(value) {
      return this._push(writeByte, 1, value ? 1 : 0);
    };
    function writeFixed32(val, buf2, pos) {
      buf2[pos] = val & 255;
      buf2[pos + 1] = val >>> 8 & 255;
      buf2[pos + 2] = val >>> 16 & 255;
      buf2[pos + 3] = val >>> 24;
    }
    Writer2.prototype.fixed32 = function write_fixed32(value) {
      return this._push(writeFixed32, 4, value >>> 0);
    };
    Writer2.prototype.sfixed32 = Writer2.prototype.fixed32;
    Writer2.prototype.fixed64 = function write_fixed64(value) {
      var bits = LongBits.from(value);
      return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
    };
    Writer2.prototype.sfixed64 = Writer2.prototype.fixed64;
    Writer2.prototype.float = function write_float(value) {
      return this._push(util.float.writeFloatLE, 4, value);
    };
    Writer2.prototype.double = function write_double(value) {
      return this._push(util.float.writeDoubleLE, 8, value);
    };
    var writeBytes2 = util.Array.prototype.set ? function writeBytes_set(val, buf2, pos) {
      buf2.set(val, pos);
    } : function writeBytes_for(val, buf2, pos) {
      for (var i = 0; i < val.length; ++i)
        buf2[pos + i] = val[i];
    };
    Writer2.prototype.bytes = function write_bytes(value) {
      var len = value.length >>> 0;
      if (!len)
        return this._push(writeByte, 1, 0);
      if (util.isString(value)) {
        var buf2 = Writer2.alloc(len = base643.length(value));
        base643.decode(value, buf2, 0);
        value = buf2;
      }
      return this.uint32(len)._push(writeBytes2, len, value);
    };
    Writer2.prototype.string = function write_string(value) {
      var len = utf84.length(value);
      return len ? this.uint32(len)._push(utf84.write, len, value) : this._push(writeByte, 1, 0);
    };
    Writer2.prototype.fork = function fork5() {
      this.states = new State2(this);
      this.head = this.tail = new Op(noop2, 0, 0);
      this.len = 0;
      return this;
    };
    Writer2.prototype.reset = function reset() {
      if (this.states) {
        this.head = this.states.head;
        this.tail = this.states.tail;
        this.len = this.states.len;
        this.states = this.states.next;
      } else {
        this.head = this.tail = new Op(noop2, 0, 0);
        this.len = 0;
      }
      return this;
    };
    Writer2.prototype.ldelim = function ldelim() {
      var head = this.head, tail = this.tail, len = this.len;
      this.reset().uint32(len);
      if (len) {
        this.tail.next = head.next;
        this.tail = tail;
        this.len += len;
      }
      return this;
    };
    Writer2.prototype.finish = function finish() {
      var head = this.head.next, buf2 = this.constructor.alloc(this.len), pos = 0;
      while (head) {
        head.fn(head.val, buf2, pos);
        pos += head.len;
        head = head.next;
      }
      return buf2;
    };
    Writer2._configure = function(BufferWriter_) {
      BufferWriter = BufferWriter_;
      Writer2.create = create19();
      BufferWriter._configure();
    };
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/writer_buffer.js
var require_writer_buffer = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/writer_buffer.js"(exports, module) {
    "use strict";
    module.exports = BufferWriter;
    var Writer2 = require_writer();
    (BufferWriter.prototype = Object.create(Writer2.prototype)).constructor = BufferWriter;
    var util = require_minimal();
    function BufferWriter() {
      Writer2.call(this);
    }
    BufferWriter._configure = function() {
      BufferWriter.alloc = util._Buffer_allocUnsafe;
      BufferWriter.writeBytesBuffer = util.Buffer && util.Buffer.prototype instanceof Uint8Array && util.Buffer.prototype.set.name === "set" ? function writeBytesBuffer_set(val, buf2, pos) {
        buf2.set(val, pos);
      } : function writeBytesBuffer_copy(val, buf2, pos) {
        if (val.copy)
          val.copy(buf2, pos, 0, val.length);
        else for (var i = 0; i < val.length; )
          buf2[pos++] = val[i++];
      };
    };
    BufferWriter.prototype.bytes = function write_bytes_buffer(value) {
      if (util.isString(value))
        value = util._Buffer_from(value, "base64");
      var len = value.length >>> 0;
      this.uint32(len);
      if (len)
        this._push(BufferWriter.writeBytesBuffer, len, value);
      return this;
    };
    function writeStringBuffer(val, buf2, pos) {
      if (val.length < 40)
        util.utf8.write(val, buf2, pos);
      else if (buf2.utf8Write)
        buf2.utf8Write(val, pos);
      else
        buf2.write(val, pos);
    }
    BufferWriter.prototype.string = function write_string_buffer(value) {
      var len = util.Buffer.byteLength(value);
      this.uint32(len);
      if (len)
        this._push(writeStringBuffer, len, value);
      return this;
    };
    BufferWriter._configure();
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/reader.js
var require_reader = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/reader.js"(exports, module) {
    "use strict";
    module.exports = Reader;
    var util = require_minimal();
    var BufferReader;
    var LongBits = util.LongBits;
    var utf84 = util.utf8;
    function indexOutOfRange(reader, writeLength) {
      return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
    }
    function Reader(buffer2) {
      this.buf = buffer2;
      this.pos = 0;
      this.len = buffer2.length;
    }
    var create_array = typeof Uint8Array !== "undefined" ? function create_typed_array(buffer2) {
      if (buffer2 instanceof Uint8Array || Array.isArray(buffer2))
        return new Reader(buffer2);
      throw Error("illegal buffer");
    } : function create_array2(buffer2) {
      if (Array.isArray(buffer2))
        return new Reader(buffer2);
      throw Error("illegal buffer");
    };
    var create19 = function create20() {
      return util.Buffer ? function create_buffer_setup(buffer2) {
        return (Reader.create = function create_buffer(buffer3) {
          return util.Buffer.isBuffer(buffer3) ? new BufferReader(buffer3) : create_array(buffer3);
        })(buffer2);
      } : create_array;
    };
    Reader.create = create19();
    Reader.prototype._slice = util.Array.prototype.subarray || /* istanbul ignore next */
    util.Array.prototype.slice;
    Reader.prototype.uint32 = /* @__PURE__ */ function read_uint32_setup() {
      var value = 4294967295;
      return function read_uint32() {
        value = (this.buf[this.pos] & 127) >>> 0;
        if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 7) >>> 0;
        if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0;
        if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0;
        if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 15) << 28) >>> 0;
        if (this.buf[this.pos++] < 128) return value;
        if ((this.pos += 5) > this.len) {
          this.pos = this.len;
          throw indexOutOfRange(this, 10);
        }
        return value;
      };
    }();
    Reader.prototype.int32 = function read_int32() {
      return this.uint32() | 0;
    };
    Reader.prototype.sint32 = function read_sint32() {
      var value = this.uint32();
      return value >>> 1 ^ -(value & 1) | 0;
    };
    function readLongVarint() {
      var bits = new LongBits(0, 0);
      var i = 0;
      if (this.len - this.pos > 4) {
        for (; i < 4; ++i) {
          bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
          if (this.buf[this.pos++] < 128)
            return bits;
        }
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >> 4) >>> 0;
        if (this.buf[this.pos++] < 128)
          return bits;
        i = 0;
      } else {
        for (; i < 3; ++i) {
          if (this.pos >= this.len)
            throw indexOutOfRange(this);
          bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
          if (this.buf[this.pos++] < 128)
            return bits;
        }
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
      }
      if (this.len - this.pos > 4) {
        for (; i < 5; ++i) {
          bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
          if (this.buf[this.pos++] < 128)
            return bits;
        }
      } else {
        for (; i < 5; ++i) {
          if (this.pos >= this.len)
            throw indexOutOfRange(this);
          bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
          if (this.buf[this.pos++] < 128)
            return bits;
        }
      }
      throw Error("invalid varint encoding");
    }
    Reader.prototype.bool = function read_bool() {
      return this.uint32() !== 0;
    };
    function readFixed32_end(buf2, end) {
      return (buf2[end - 4] | buf2[end - 3] << 8 | buf2[end - 2] << 16 | buf2[end - 1] << 24) >>> 0;
    }
    Reader.prototype.fixed32 = function read_fixed32() {
      if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);
      return readFixed32_end(this.buf, this.pos += 4);
    };
    Reader.prototype.sfixed32 = function read_sfixed32() {
      if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);
      return readFixed32_end(this.buf, this.pos += 4) | 0;
    };
    function readFixed64() {
      if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 8);
      return new LongBits(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));
    }
    Reader.prototype.float = function read_float() {
      if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);
      var value = util.float.readFloatLE(this.buf, this.pos);
      this.pos += 4;
      return value;
    };
    Reader.prototype.double = function read_double() {
      if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 4);
      var value = util.float.readDoubleLE(this.buf, this.pos);
      this.pos += 8;
      return value;
    };
    Reader.prototype.bytes = function read_bytes() {
      var length4 = this.uint32(), start = this.pos, end = this.pos + length4;
      if (end > this.len)
        throw indexOutOfRange(this, length4);
      this.pos += length4;
      if (Array.isArray(this.buf))
        return this.buf.slice(start, end);
      if (start === end) {
        var nativeBuffer = util.Buffer;
        return nativeBuffer ? nativeBuffer.alloc(0) : new this.buf.constructor(0);
      }
      return this._slice.call(this.buf, start, end);
    };
    Reader.prototype.string = function read_string() {
      var bytes2 = this.bytes();
      return utf84.read(bytes2, 0, bytes2.length);
    };
    Reader.prototype.skip = function skip2(length4) {
      if (typeof length4 === "number") {
        if (this.pos + length4 > this.len)
          throw indexOutOfRange(this, length4);
        this.pos += length4;
      } else {
        do {
          if (this.pos >= this.len)
            throw indexOutOfRange(this);
        } while (this.buf[this.pos++] & 128);
      }
      return this;
    };
    Reader.prototype.skipType = function(wireType) {
      switch (wireType) {
        case 0:
          this.skip();
          break;
        case 1:
          this.skip(8);
          break;
        case 2:
          this.skip(this.uint32());
          break;
        case 3:
          while ((wireType = this.uint32() & 7) !== 4) {
            this.skipType(wireType);
          }
          break;
        case 5:
          this.skip(4);
          break;
        default:
          throw Error("invalid wire type " + wireType + " at offset " + this.pos);
      }
      return this;
    };
    Reader._configure = function(BufferReader_) {
      BufferReader = BufferReader_;
      Reader.create = create19();
      BufferReader._configure();
      var fn = util.Long ? "toLong" : (
        /* istanbul ignore next */
        "toNumber"
      );
      util.merge(Reader.prototype, {
        int64: function read_int64() {
          return readLongVarint.call(this)[fn](false);
        },
        uint64: function read_uint64() {
          return readLongVarint.call(this)[fn](true);
        },
        sint64: function read_sint64() {
          return readLongVarint.call(this).zzDecode()[fn](false);
        },
        fixed64: function read_fixed64() {
          return readFixed64.call(this)[fn](true);
        },
        sfixed64: function read_sfixed64() {
          return readFixed64.call(this)[fn](false);
        }
      });
    };
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/reader_buffer.js
var require_reader_buffer = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/reader_buffer.js"(exports, module) {
    "use strict";
    module.exports = BufferReader;
    var Reader = require_reader();
    (BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;
    var util = require_minimal();
    function BufferReader(buffer2) {
      Reader.call(this, buffer2);
    }
    BufferReader._configure = function() {
      if (util.Buffer)
        BufferReader.prototype._slice = util.Buffer.prototype.slice;
    };
    BufferReader.prototype.string = function read_string_buffer() {
      var len = this.uint32();
      return this.buf.utf8Slice ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len)) : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
    };
    BufferReader._configure();
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/rpc/service.js
var require_service = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/rpc/service.js"(exports, module) {
    "use strict";
    module.exports = Service;
    var util = require_minimal();
    (Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;
    function Service(rpcImpl, requestDelimited, responseDelimited) {
      if (typeof rpcImpl !== "function")
        throw TypeError("rpcImpl must be a function");
      util.EventEmitter.call(this);
      this.rpcImpl = rpcImpl;
      this.requestDelimited = Boolean(requestDelimited);
      this.responseDelimited = Boolean(responseDelimited);
    }
    Service.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {
      if (!request)
        throw TypeError("request must be specified");
      var self2 = this;
      if (!callback)
        return util.asPromise(rpcCall, self2, method, requestCtor, responseCtor, request);
      if (!self2.rpcImpl) {
        setTimeout(function() {
          callback(Error("already ended"));
        }, 0);
        return void 0;
      }
      try {
        return self2.rpcImpl(
          method,
          requestCtor[self2.requestDelimited ? "encodeDelimited" : "encode"](request).finish(),
          function rpcCallback(err, response) {
            if (err) {
              self2.emit("error", err, method);
              return callback(err);
            }
            if (response === null) {
              self2.end(
                /* endedByRPC */
                true
              );
              return void 0;
            }
            if (!(response instanceof responseCtor)) {
              try {
                response = responseCtor[self2.responseDelimited ? "decodeDelimited" : "decode"](response);
              } catch (err2) {
                self2.emit("error", err2, method);
                return callback(err2);
              }
            }
            self2.emit("data", response, method);
            return callback(null, response);
          }
        );
      } catch (err) {
        self2.emit("error", err, method);
        setTimeout(function() {
          callback(err);
        }, 0);
        return void 0;
      }
    };
    Service.prototype.end = function end(endedByRPC) {
      if (this.rpcImpl) {
        if (!endedByRPC)
          this.rpcImpl(null, null, null);
        this.rpcImpl = null;
        this.emit("end").off();
      }
      return this;
    };
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/rpc.js
var require_rpc = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/rpc.js"(exports) {
    "use strict";
    var rpc = exports;
    rpc.Service = require_service();
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/roots.js
var require_roots = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/roots.js"(exports, module) {
    "use strict";
    module.exports = {};
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/index-minimal.js
var require_index_minimal = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/src/index-minimal.js"(exports) {
    "use strict";
    var protobuf = exports;
    protobuf.build = "minimal";
    protobuf.Writer = require_writer();
    protobuf.BufferWriter = require_writer_buffer();
    protobuf.Reader = require_reader();
    protobuf.BufferReader = require_reader_buffer();
    protobuf.util = require_minimal();
    protobuf.rpc = require_rpc();
    protobuf.roots = require_roots();
    protobuf.configure = configure6;
    function configure6() {
      protobuf.util._configure();
      protobuf.Writer._configure(protobuf.BufferWriter);
      protobuf.Reader._configure(protobuf.BufferReader);
    }
    configure6();
  }
});

// ../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/minimal.js
var require_minimal2 = __commonJS({
  "../../node_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs/minimal.js"(exports, module) {
    "use strict";
    module.exports = require_index_minimal();
  }
});

// ../../node_modules/.pnpm/murmurhash3js-revisited@3.0.0/node_modules/murmurhash3js-revisited/lib/murmurHash3js.js
var require_murmurHash3js = __commonJS({
  "../../node_modules/.pnpm/murmurhash3js-revisited@3.0.0/node_modules/murmurhash3js-revisited/lib/murmurHash3js.js"(exports, module) {
    (function(root2, undefined2) {
      "use strict";
      var library = {
        "version": "3.0.0",
        "x86": {},
        "x64": {},
        "inputValidation": true
      };
      function _validBytes(bytes2) {
        if (!Array.isArray(bytes2) && !ArrayBuffer.isView(bytes2)) {
          return false;
        }
        for (var i = 0; i < bytes2.length; i++) {
          if (!Number.isInteger(bytes2[i]) || bytes2[i] < 0 || bytes2[i] > 255) {
            return false;
          }
        }
        return true;
      }
      function _x86Multiply(m, n) {
        return (m & 65535) * n + (((m >>> 16) * n & 65535) << 16);
      }
      function _x86Rotl(m, n) {
        return m << n | m >>> 32 - n;
      }
      function _x86Fmix(h) {
        h ^= h >>> 16;
        h = _x86Multiply(h, 2246822507);
        h ^= h >>> 13;
        h = _x86Multiply(h, 3266489909);
        h ^= h >>> 16;
        return h;
      }
      function _x64Add(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] + n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] + n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] + n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] + n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Multiply(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] * n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] * n[3];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[2] += m[3] * n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] * n[3];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[2] * n[2];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[3] * n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Rotl(m, n) {
        n %= 64;
        if (n === 32) {
          return [m[1], m[0]];
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];
        } else {
          n -= 32;
          return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];
        }
      }
      function _x64LeftShift(m, n) {
        n %= 64;
        if (n === 0) {
          return m;
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n];
        } else {
          return [m[1] << n - 32, 0];
        }
      }
      function _x64Xor(m, n) {
        return [m[0] ^ n[0], m[1] ^ n[1]];
      }
      function _x64Fmix(h) {
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [4283543511, 3981806797]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [3301882366, 444984403]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        return h;
      }
      library.x86.hash32 = function(bytes2, seed) {
        if (library.inputValidation && !_validBytes(bytes2)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes2.length % 4;
        var blocks = bytes2.length - remainder;
        var h1 = seed;
        var k1 = 0;
        var c1 = 3432918353;
        var c2 = 461845907;
        for (var i = 0; i < blocks; i = i + 4) {
          k1 = bytes2[i] | bytes2[i + 1] << 8 | bytes2[i + 2] << 16 | bytes2[i + 3] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 13);
          h1 = _x86Multiply(h1, 5) + 3864292196;
        }
        k1 = 0;
        switch (remainder) {
          case 3:
            k1 ^= bytes2[i + 2] << 16;
          case 2:
            k1 ^= bytes2[i + 1] << 8;
          case 1:
            k1 ^= bytes2[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes2.length;
        h1 = _x86Fmix(h1);
        return h1 >>> 0;
      };
      library.x86.hash128 = function(bytes2, seed) {
        if (library.inputValidation && !_validBytes(bytes2)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes2.length % 16;
        var blocks = bytes2.length - remainder;
        var h1 = seed;
        var h2 = seed;
        var h3 = seed;
        var h4 = seed;
        var k1 = 0;
        var k2 = 0;
        var k3 = 0;
        var k4 = 0;
        var c1 = 597399067;
        var c2 = 2869860233;
        var c3 = 951274213;
        var c4 = 2716044179;
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = bytes2[i] | bytes2[i + 1] << 8 | bytes2[i + 2] << 16 | bytes2[i + 3] << 24;
          k2 = bytes2[i + 4] | bytes2[i + 5] << 8 | bytes2[i + 6] << 16 | bytes2[i + 7] << 24;
          k3 = bytes2[i + 8] | bytes2[i + 9] << 8 | bytes2[i + 10] << 16 | bytes2[i + 11] << 24;
          k4 = bytes2[i + 12] | bytes2[i + 13] << 8 | bytes2[i + 14] << 16 | bytes2[i + 15] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 19);
          h1 += h2;
          h1 = _x86Multiply(h1, 5) + 1444728091;
          k2 = _x86Multiply(k2, c2);
          k2 = _x86Rotl(k2, 16);
          k2 = _x86Multiply(k2, c3);
          h2 ^= k2;
          h2 = _x86Rotl(h2, 17);
          h2 += h3;
          h2 = _x86Multiply(h2, 5) + 197830471;
          k3 = _x86Multiply(k3, c3);
          k3 = _x86Rotl(k3, 17);
          k3 = _x86Multiply(k3, c4);
          h3 ^= k3;
          h3 = _x86Rotl(h3, 15);
          h3 += h4;
          h3 = _x86Multiply(h3, 5) + 2530024501;
          k4 = _x86Multiply(k4, c4);
          k4 = _x86Rotl(k4, 18);
          k4 = _x86Multiply(k4, c1);
          h4 ^= k4;
          h4 = _x86Rotl(h4, 13);
          h4 += h1;
          h4 = _x86Multiply(h4, 5) + 850148119;
        }
        k1 = 0;
        k2 = 0;
        k3 = 0;
        k4 = 0;
        switch (remainder) {
          case 15:
            k4 ^= bytes2[i + 14] << 16;
          case 14:
            k4 ^= bytes2[i + 13] << 8;
          case 13:
            k4 ^= bytes2[i + 12];
            k4 = _x86Multiply(k4, c4);
            k4 = _x86Rotl(k4, 18);
            k4 = _x86Multiply(k4, c1);
            h4 ^= k4;
          case 12:
            k3 ^= bytes2[i + 11] << 24;
          case 11:
            k3 ^= bytes2[i + 10] << 16;
          case 10:
            k3 ^= bytes2[i + 9] << 8;
          case 9:
            k3 ^= bytes2[i + 8];
            k3 = _x86Multiply(k3, c3);
            k3 = _x86Rotl(k3, 17);
            k3 = _x86Multiply(k3, c4);
            h3 ^= k3;
          case 8:
            k2 ^= bytes2[i + 7] << 24;
          case 7:
            k2 ^= bytes2[i + 6] << 16;
          case 6:
            k2 ^= bytes2[i + 5] << 8;
          case 5:
            k2 ^= bytes2[i + 4];
            k2 = _x86Multiply(k2, c2);
            k2 = _x86Rotl(k2, 16);
            k2 = _x86Multiply(k2, c3);
            h2 ^= k2;
          case 4:
            k1 ^= bytes2[i + 3] << 24;
          case 3:
            k1 ^= bytes2[i + 2] << 16;
          case 2:
            k1 ^= bytes2[i + 1] << 8;
          case 1:
            k1 ^= bytes2[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes2.length;
        h2 ^= bytes2.length;
        h3 ^= bytes2.length;
        h4 ^= bytes2.length;
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        h1 = _x86Fmix(h1);
        h2 = _x86Fmix(h2);
        h3 = _x86Fmix(h3);
        h4 = _x86Fmix(h4);
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        return ("00000000" + (h1 >>> 0).toString(16)).slice(-8) + ("00000000" + (h2 >>> 0).toString(16)).slice(-8) + ("00000000" + (h3 >>> 0).toString(16)).slice(-8) + ("00000000" + (h4 >>> 0).toString(16)).slice(-8);
      };
      library.x64.hash128 = function(bytes2, seed) {
        if (library.inputValidation && !_validBytes(bytes2)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes2.length % 16;
        var blocks = bytes2.length - remainder;
        var h1 = [0, seed];
        var h2 = [0, seed];
        var k1 = [0, 0];
        var k2 = [0, 0];
        var c1 = [2277735313, 289559509];
        var c2 = [1291169091, 658871167];
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = [bytes2[i + 4] | bytes2[i + 5] << 8 | bytes2[i + 6] << 16 | bytes2[i + 7] << 24, bytes2[i] | bytes2[i + 1] << 8 | bytes2[i + 2] << 16 | bytes2[i + 3] << 24];
          k2 = [bytes2[i + 12] | bytes2[i + 13] << 8 | bytes2[i + 14] << 16 | bytes2[i + 15] << 24, bytes2[i + 8] | bytes2[i + 9] << 8 | bytes2[i + 10] << 16 | bytes2[i + 11] << 24];
          k1 = _x64Multiply(k1, c1);
          k1 = _x64Rotl(k1, 31);
          k1 = _x64Multiply(k1, c2);
          h1 = _x64Xor(h1, k1);
          h1 = _x64Rotl(h1, 27);
          h1 = _x64Add(h1, h2);
          h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 1390208809]);
          k2 = _x64Multiply(k2, c2);
          k2 = _x64Rotl(k2, 33);
          k2 = _x64Multiply(k2, c1);
          h2 = _x64Xor(h2, k2);
          h2 = _x64Rotl(h2, 31);
          h2 = _x64Add(h2, h1);
          h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 944331445]);
        }
        k1 = [0, 0];
        k2 = [0, 0];
        switch (remainder) {
          case 15:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 14]], 48));
          case 14:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 13]], 40));
          case 13:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 12]], 32));
          case 12:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 11]], 24));
          case 11:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 10]], 16));
          case 10:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes2[i + 9]], 8));
          case 9:
            k2 = _x64Xor(k2, [0, bytes2[i + 8]]);
            k2 = _x64Multiply(k2, c2);
            k2 = _x64Rotl(k2, 33);
            k2 = _x64Multiply(k2, c1);
            h2 = _x64Xor(h2, k2);
          case 8:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 7]], 56));
          case 7:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 6]], 48));
          case 6:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 5]], 40));
          case 5:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 4]], 32));
          case 4:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 3]], 24));
          case 3:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 2]], 16));
          case 2:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes2[i + 1]], 8));
          case 1:
            k1 = _x64Xor(k1, [0, bytes2[i]]);
            k1 = _x64Multiply(k1, c1);
            k1 = _x64Rotl(k1, 31);
            k1 = _x64Multiply(k1, c2);
            h1 = _x64Xor(h1, k1);
        }
        h1 = _x64Xor(h1, [0, bytes2.length]);
        h2 = _x64Xor(h2, [0, bytes2.length]);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        h1 = _x64Fmix(h1);
        h2 = _x64Fmix(h2);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        return ("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8);
      };
      if (typeof exports !== "undefined") {
        if (typeof module !== "undefined" && module.exports) {
          exports = module.exports = library;
        }
        exports.murmurHash3 = library;
      } else if (typeof define === "function" && define.amd) {
        define([], function() {
          return library;
        });
      } else {
        library._murmurHash3 = root2.murmurHash3;
        library.noConflict = function() {
          root2.murmurHash3 = library._murmurHash3;
          library._murmurHash3 = undefined2;
          library.noConflict = undefined2;
          return library;
        };
        root2.murmurHash3 = library;
      }
    })(exports);
  }
});

// ../../node_modules/.pnpm/murmurhash3js-revisited@3.0.0/node_modules/murmurhash3js-revisited/index.js
var require_murmurhash3js_revisited = __commonJS({
  "../../node_modules/.pnpm/murmurhash3js-revisited@3.0.0/node_modules/murmurhash3js-revisited/index.js"(exports, module) {
    module.exports = require_murmurHash3js();
  }
});

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/multihash.js
var multihash_exports = {};
__export(multihash_exports, {
  Digest: () => digest_exports3,
  MAX_HEIGHT: () => MAX_HEIGHT2,
  MAX_PAYLOAD_SIZE: () => MAX_PAYLOAD_SIZE2,
  code: () => code5,
  create: () => create4,
  digest: () => digest2,
  name: () => name4
});

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/constant.js
var BITS_PER_BYTE = 8;
var FRS_PER_QUAD = 4;
var LEAFS_PER_QUAD = (
  /** @type {4n} */
  BigInt(FRS_PER_QUAD)
);
var IN_BITS_FR = 254;
var OUT_BITS_FR = 256;
var IN_BYTES_PER_QUAD = (
  /** @type {127} */
  FRS_PER_QUAD * IN_BITS_FR / BITS_PER_BYTE
);
var OUT_BYTES_PER_QUAD = (
  /** @type {128} */
  FRS_PER_QUAD * OUT_BITS_FR / BITS_PER_BYTE
);
var PADDED_BYTES_PER_QUAD = (
  /** @type {127n} */
  BigInt(IN_BYTES_PER_QUAD)
);
var EXPANDED_BYTES_PER_QUAD = (
  /** @type {128n} */
  BigInt(OUT_BYTES_PER_QUAD)
);
var BYTES_PER_FR = (
  /** @type {32} */
  OUT_BYTES_PER_QUAD / FRS_PER_QUAD
);
var FR_RATIO = IN_BITS_FR / OUT_BITS_FR;
var NODE_SIZE = (
  /** @type {32} */
  OUT_BYTES_PER_QUAD / FRS_PER_QUAD
);
var EXPANDED_BYTES_PER_NODE = (
  /** @type {32n} */
  BigInt(NODE_SIZE)
);
var MIN_PAYLOAD_SIZE = 2 * NODE_SIZE + 1;

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/node.js
var from = (bytes2) => {
  if (bytes2 instanceof Uint8Array) {
    if (bytes2.length > NODE_SIZE) {
      return bytes2.subarray(0, NODE_SIZE);
    } else if (bytes2.length == NODE_SIZE) {
      return bytes2;
    }
  }
  const node = new Uint8Array(NODE_SIZE);
  node.set([...bytes2]);
  return node;
};
var empty = () => EMPTY;
var EMPTY = from(new Uint8Array(NODE_SIZE).fill(0));
Object.freeze(EMPTY.buffer);

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/bytes.js
var empty2 = new Uint8Array(0);
var equals = (aa, bb) => {
  if (aa === bb) return true;
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
};
var coerce = (o) => {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") return o;
  if (o instanceof ArrayBuffer) return new Uint8Array(o);
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/ipld/sha256.js
var sha256_exports = {};
__export(sha256_exports, {
  code: () => code2,
  digest: () => digest,
  name: () => name,
  size: () => size
});

// ../../node_modules/.pnpm/sync-multihash-sha2@1.0.0/node_modules/sync-multihash-sha2/src/sha256/web.js
import { sha256 } from "@noble/hashes/sha256";

// ../../node_modules/.pnpm/sync-multihash-sha2@1.0.0/node_modules/sync-multihash-sha2/src/sha256/digest.js
var name = "sha2-256";
var code = 18;
var size = 32;
var prefix = new Uint8Array([18, 32]);
var Digest = class {
  /**
   * @param {Uint8Array} bytes
   */
  constructor(bytes2) {
    this.code = code;
    this.name = name;
    this.bytes = bytes2;
    this.size = size;
    this.digest = bytes2.subarray(2);
  }
};

// ../../node_modules/.pnpm/sync-multihash-sha2@1.0.0/node_modules/sync-multihash-sha2/src/sha256/web.js
var digest = (payload) => {
  const digest5 = new Uint8Array(prefix.length + size);
  digest5.set(prefix, 0);
  digest5.set(sha256(payload), prefix.length);
  return new Digest(digest5);
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/ipld/sha256.js
var code2 = code;

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/is.js
var typeofs = [
  "string",
  "number",
  "bigint",
  "symbol"
];
var objectTypeNames = [
  "Function",
  "Generator",
  "AsyncGenerator",
  "GeneratorFunction",
  "AsyncGeneratorFunction",
  "AsyncFunction",
  "Observable",
  "Array",
  "Buffer",
  "Object",
  "RegExp",
  "Date",
  "Error",
  "Map",
  "Set",
  "WeakMap",
  "WeakSet",
  "ArrayBuffer",
  "SharedArrayBuffer",
  "DataView",
  "Promise",
  "URL",
  "HTMLElement",
  "Int8Array",
  "Uint8Array",
  "Uint8ClampedArray",
  "Int16Array",
  "Uint16Array",
  "Int32Array",
  "Uint32Array",
  "Float32Array",
  "Float64Array",
  "BigInt64Array",
  "BigUint64Array"
];
function is(value) {
  if (value === null) {
    return "null";
  }
  if (value === void 0) {
    return "undefined";
  }
  if (value === true || value === false) {
    return "boolean";
  }
  const typeOf = typeof value;
  if (typeofs.includes(typeOf)) {
    return typeOf;
  }
  if (typeOf === "function") {
    return "Function";
  }
  if (Array.isArray(value)) {
    return "Array";
  }
  if (isBuffer(value)) {
    return "Buffer";
  }
  const objectType = getObjectType(value);
  if (objectType) {
    return objectType;
  }
  return "Object";
}
function isBuffer(value) {
  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value);
}
function getObjectType(value) {
  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1);
  if (objectTypeNames.includes(objectTypeName)) {
    return objectTypeName;
  }
  return void 0;
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/token.js
var Type = class {
  /**
   * @param {number} major
   * @param {string} name
   * @param {boolean} terminal
   */
  constructor(major, name14, terminal) {
    this.major = major;
    this.majorEncoded = major << 5;
    this.name = name14;
    this.terminal = terminal;
  }
  /* c8 ignore next 3 */
  toString() {
    return `Type[${this.major}].${this.name}`;
  }
  /**
   * @param {Type} typ
   * @returns {number}
   */
  compare(typ) {
    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0;
  }
};
Type.uint = new Type(0, "uint", true);
Type.negint = new Type(1, "negint", true);
Type.bytes = new Type(2, "bytes", true);
Type.string = new Type(3, "string", true);
Type.array = new Type(4, "array", false);
Type.map = new Type(5, "map", false);
Type.tag = new Type(6, "tag", false);
Type.float = new Type(7, "float", true);
Type.false = new Type(7, "false", true);
Type.true = new Type(7, "true", true);
Type.null = new Type(7, "null", true);
Type.undefined = new Type(7, "undefined", true);
Type.break = new Type(7, "break", true);
var Token = class {
  /**
   * @param {Type} type
   * @param {any} [value]
   * @param {number} [encodedLength]
   */
  constructor(type2, value, encodedLength) {
    this.type = type2;
    this.value = value;
    this.encodedLength = encodedLength;
    this.encodedBytes = void 0;
    this.byteValue = void 0;
  }
  /* c8 ignore next 3 */
  toString() {
    return `Token[${this.type}].${this.value}`;
  }
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/byte-utils.js
var useBuffer = globalThis.process && // @ts-ignore
!globalThis.process.browser && // @ts-ignore
globalThis.Buffer && // @ts-ignore
typeof globalThis.Buffer.isBuffer === "function";
var textDecoder = new TextDecoder();
var textEncoder = new TextEncoder();
function isBuffer2(buf2) {
  return useBuffer && globalThis.Buffer.isBuffer(buf2);
}
function asU8A(buf2) {
  if (!(buf2 instanceof Uint8Array)) {
    return Uint8Array.from(buf2);
  }
  return isBuffer2(buf2) ? new Uint8Array(buf2.buffer, buf2.byteOffset, buf2.byteLength) : buf2;
}
var toString = useBuffer ? (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array} bytes
   * @param {number} start
   * @param {number} end
   */
  (bytes2, start, end) => {
    return end - start > 64 ? (
      // eslint-disable-line operator-linebreak
      // @ts-ignore
      globalThis.Buffer.from(bytes2.subarray(start, end)).toString("utf8")
    ) : utf8Slice(bytes2, start, end);
  }
) : (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array} bytes
   * @param {number} start
   * @param {number} end
   */
  (bytes2, start, end) => {
    return end - start > 64 ? textDecoder.decode(bytes2.subarray(start, end)) : utf8Slice(bytes2, start, end);
  }
);
var fromString = useBuffer ? (
  // eslint-disable-line operator-linebreak
  /**
   * @param {string} string
   */
  (string3) => {
    return string3.length > 64 ? (
      // eslint-disable-line operator-linebreak
      // @ts-ignore
      globalThis.Buffer.from(string3)
    ) : utf8ToBytes(string3);
  }
) : (
  // eslint-disable-line operator-linebreak
  /**
   * @param {string} string
   */
  (string3) => {
    return string3.length > 64 ? textEncoder.encode(string3) : utf8ToBytes(string3);
  }
);
var fromArray = (arr) => {
  return Uint8Array.from(arr);
};
var slice = useBuffer ? (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array} bytes
   * @param {number} start
   * @param {number} end
   */
  (bytes2, start, end) => {
    if (isBuffer2(bytes2)) {
      return new Uint8Array(bytes2.subarray(start, end));
    }
    return bytes2.slice(start, end);
  }
) : (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array} bytes
   * @param {number} start
   * @param {number} end
   */
  (bytes2, start, end) => {
    return bytes2.slice(start, end);
  }
);
var concat = useBuffer ? (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array[]} chunks
   * @param {number} length
   * @returns {Uint8Array}
   */
  (chunks, length4) => {
    chunks = chunks.map((c) => c instanceof Uint8Array ? c : (
      // eslint-disable-line operator-linebreak
      // @ts-ignore
      globalThis.Buffer.from(c)
    ));
    return asU8A(globalThis.Buffer.concat(chunks, length4));
  }
) : (
  // eslint-disable-line operator-linebreak
  /**
   * @param {Uint8Array[]} chunks
   * @param {number} length
   * @returns {Uint8Array}
   */
  (chunks, length4) => {
    const out = new Uint8Array(length4);
    let off = 0;
    for (let b of chunks) {
      if (off + b.length > out.length) {
        b = b.subarray(0, out.length - off);
      }
      out.set(b, off);
      off += b.length;
    }
    return out;
  }
);
var alloc = useBuffer ? (
  // eslint-disable-line operator-linebreak
  /**
   * @param {number} size
   * @returns {Uint8Array}
   */
  (size5) => {
    return globalThis.Buffer.allocUnsafe(size5);
  }
) : (
  // eslint-disable-line operator-linebreak
  /**
   * @param {number} size
   * @returns {Uint8Array}
   */
  (size5) => {
    return new Uint8Array(size5);
  }
);
function compare(b1, b2) {
  if (isBuffer2(b1) && isBuffer2(b2)) {
    return b1.compare(b2);
  }
  for (let i = 0; i < b1.length; i++) {
    if (b1[i] === b2[i]) {
      continue;
    }
    return b1[i] < b2[i] ? -1 : 1;
  }
  return 0;
}
function utf8ToBytes(str) {
  const out = [];
  let p = 0;
  for (let i = 0; i < str.length; i++) {
    let c = str.charCodeAt(i);
    if (c < 128) {
      out[p++] = c;
    } else if (c < 2048) {
      out[p++] = c >> 6 | 192;
      out[p++] = c & 63 | 128;
    } else if ((c & 64512) === 55296 && i + 1 < str.length && (str.charCodeAt(i + 1) & 64512) === 56320) {
      c = 65536 + ((c & 1023) << 10) + (str.charCodeAt(++i) & 1023);
      out[p++] = c >> 18 | 240;
      out[p++] = c >> 12 & 63 | 128;
      out[p++] = c >> 6 & 63 | 128;
      out[p++] = c & 63 | 128;
    } else {
      out[p++] = c >> 12 | 224;
      out[p++] = c >> 6 & 63 | 128;
      out[p++] = c & 63 | 128;
    }
  }
  return out;
}
function utf8Slice(buf2, offset2, end) {
  const res = [];
  while (offset2 < end) {
    const firstByte = buf2[offset2];
    let codePoint = null;
    let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;
    if (offset2 + bytesPerSequence <= end) {
      let secondByte, thirdByte, fourthByte, tempCodePoint;
      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 128) {
            codePoint = firstByte;
          }
          break;
        case 2:
          secondByte = buf2[offset2 + 1];
          if ((secondByte & 192) === 128) {
            tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;
            if (tempCodePoint > 127) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 3:
          secondByte = buf2[offset2 + 1];
          thirdByte = buf2[offset2 + 2];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;
            if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 4:
          secondByte = buf2[offset2 + 1];
          thirdByte = buf2[offset2 + 2];
          fourthByte = buf2[offset2 + 3];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;
            if (tempCodePoint > 65535 && tempCodePoint < 1114112) {
              codePoint = tempCodePoint;
            }
          }
      }
    }
    if (codePoint === null) {
      codePoint = 65533;
      bytesPerSequence = 1;
    } else if (codePoint > 65535) {
      codePoint -= 65536;
      res.push(codePoint >>> 10 & 1023 | 55296);
      codePoint = 56320 | codePoint & 1023;
    }
    res.push(codePoint);
    offset2 += bytesPerSequence;
  }
  return decodeCodePointsArray(res);
}
var MAX_ARGUMENTS_LENGTH = 4096;
function decodeCodePointsArray(codePoints) {
  const len = codePoints.length;
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints);
  }
  let res = "";
  let i = 0;
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    );
  }
  return res;
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/bl.js
var defaultChunkSize = 256;
var Bl = class {
  /**
   * @param {number} [chunkSize]
   */
  constructor(chunkSize = defaultChunkSize) {
    this.chunkSize = chunkSize;
    this.cursor = 0;
    this.maxCursor = -1;
    this.chunks = [];
    this._initReuseChunk = null;
  }
  reset() {
    this.cursor = 0;
    this.maxCursor = -1;
    if (this.chunks.length) {
      this.chunks = [];
    }
    if (this._initReuseChunk !== null) {
      this.chunks.push(this._initReuseChunk);
      this.maxCursor = this._initReuseChunk.length - 1;
    }
  }
  /**
   * @param {Uint8Array|number[]} bytes
   */
  push(bytes2) {
    let topChunk = this.chunks[this.chunks.length - 1];
    const newMax = this.cursor + bytes2.length;
    if (newMax <= this.maxCursor + 1) {
      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;
      topChunk.set(bytes2, chunkPos);
    } else {
      if (topChunk) {
        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;
        if (chunkPos < topChunk.length) {
          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos);
          this.maxCursor = this.cursor - 1;
        }
      }
      if (bytes2.length < 64 && bytes2.length < this.chunkSize) {
        topChunk = alloc(this.chunkSize);
        this.chunks.push(topChunk);
        this.maxCursor += topChunk.length;
        if (this._initReuseChunk === null) {
          this._initReuseChunk = topChunk;
        }
        topChunk.set(bytes2, 0);
      } else {
        this.chunks.push(bytes2);
        this.maxCursor += bytes2.length;
      }
    }
    this.cursor += bytes2.length;
  }
  /**
   * @param {boolean} [reset]
   * @returns {Uint8Array}
   */
  toBytes(reset = false) {
    let byts;
    if (this.chunks.length === 1) {
      const chunk = this.chunks[0];
      if (reset && this.cursor > chunk.length / 2) {
        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor);
        this._initReuseChunk = null;
        this.chunks = [];
      } else {
        byts = slice(chunk, 0, this.cursor);
      }
    } else {
      byts = concat(this.chunks, this.cursor);
    }
    if (reset) {
      this.reset();
    }
    return byts;
  }
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/common.js
var decodeErrPrefix = "CBOR decode error:";
var encodeErrPrefix = "CBOR encode error:";
var uintMinorPrefixBytes = [];
uintMinorPrefixBytes[23] = 1;
uintMinorPrefixBytes[24] = 2;
uintMinorPrefixBytes[25] = 3;
uintMinorPrefixBytes[26] = 5;
uintMinorPrefixBytes[27] = 9;
function assertEnoughData(data, pos, need) {
  if (data.length - pos < need) {
    throw new Error(`${decodeErrPrefix} not enough data for type`);
  }
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/0uint.js
var uintBoundaries = [24, 256, 65536, 4294967296, BigInt("18446744073709551616")];
function readUint8(data, offset2, options) {
  assertEnoughData(data, offset2, 1);
  const value = data[offset2];
  if (options.strict === true && value < uintBoundaries[0]) {
    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);
  }
  return value;
}
function readUint16(data, offset2, options) {
  assertEnoughData(data, offset2, 2);
  const value = data[offset2] << 8 | data[offset2 + 1];
  if (options.strict === true && value < uintBoundaries[1]) {
    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);
  }
  return value;
}
function readUint32(data, offset2, options) {
  assertEnoughData(data, offset2, 4);
  const value = data[offset2] * 16777216 + (data[offset2 + 1] << 16) + (data[offset2 + 2] << 8) + data[offset2 + 3];
  if (options.strict === true && value < uintBoundaries[2]) {
    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);
  }
  return value;
}
function readUint64(data, offset2, options) {
  assertEnoughData(data, offset2, 8);
  const hi = data[offset2] * 16777216 + (data[offset2 + 1] << 16) + (data[offset2 + 2] << 8) + data[offset2 + 3];
  const lo = data[offset2 + 4] * 16777216 + (data[offset2 + 5] << 16) + (data[offset2 + 6] << 8) + data[offset2 + 7];
  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo);
  if (options.strict === true && value < uintBoundaries[3]) {
    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);
  }
  if (value <= Number.MAX_SAFE_INTEGER) {
    return Number(value);
  }
  if (options.allowBigInt === true) {
    return value;
  }
  throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`);
}
function decodeUint8(data, pos, _minor, options) {
  return new Token(Type.uint, readUint8(data, pos + 1, options), 2);
}
function decodeUint16(data, pos, _minor, options) {
  return new Token(Type.uint, readUint16(data, pos + 1, options), 3);
}
function decodeUint32(data, pos, _minor, options) {
  return new Token(Type.uint, readUint32(data, pos + 1, options), 5);
}
function decodeUint64(data, pos, _minor, options) {
  return new Token(Type.uint, readUint64(data, pos + 1, options), 9);
}
function encodeUint(buf2, token) {
  return encodeUintValue(buf2, 0, token.value);
}
function encodeUintValue(buf2, major, uint) {
  if (uint < uintBoundaries[0]) {
    const nuint = Number(uint);
    buf2.push([major | nuint]);
  } else if (uint < uintBoundaries[1]) {
    const nuint = Number(uint);
    buf2.push([major | 24, nuint]);
  } else if (uint < uintBoundaries[2]) {
    const nuint = Number(uint);
    buf2.push([major | 25, nuint >>> 8, nuint & 255]);
  } else if (uint < uintBoundaries[3]) {
    const nuint = Number(uint);
    buf2.push([major | 26, nuint >>> 24 & 255, nuint >>> 16 & 255, nuint >>> 8 & 255, nuint & 255]);
  } else {
    const buint = BigInt(uint);
    if (buint < uintBoundaries[4]) {
      const set5 = [major | 27, 0, 0, 0, 0, 0, 0, 0];
      let lo = Number(buint & BigInt(4294967295));
      let hi = Number(buint >> BigInt(32) & BigInt(4294967295));
      set5[8] = lo & 255;
      lo = lo >> 8;
      set5[7] = lo & 255;
      lo = lo >> 8;
      set5[6] = lo & 255;
      lo = lo >> 8;
      set5[5] = lo & 255;
      set5[4] = hi & 255;
      hi = hi >> 8;
      set5[3] = hi & 255;
      hi = hi >> 8;
      set5[2] = hi & 255;
      hi = hi >> 8;
      set5[1] = hi & 255;
      buf2.push(set5);
    } else {
      throw new Error(`${decodeErrPrefix} encountered BigInt larger than allowable range`);
    }
  }
}
encodeUint.encodedSize = function encodedSize(token) {
  return encodeUintValue.encodedSize(token.value);
};
encodeUintValue.encodedSize = function encodedSize2(uint) {
  if (uint < uintBoundaries[0]) {
    return 1;
  }
  if (uint < uintBoundaries[1]) {
    return 2;
  }
  if (uint < uintBoundaries[2]) {
    return 3;
  }
  if (uint < uintBoundaries[3]) {
    return 5;
  }
  return 9;
};
encodeUint.compareTokens = function compareTokens(tok1, tok2) {
  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : (
    /* c8 ignore next */
    0
  );
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/1negint.js
function decodeNegint8(data, pos, _minor, options) {
  return new Token(Type.negint, -1 - readUint8(data, pos + 1, options), 2);
}
function decodeNegint16(data, pos, _minor, options) {
  return new Token(Type.negint, -1 - readUint16(data, pos + 1, options), 3);
}
function decodeNegint32(data, pos, _minor, options) {
  return new Token(Type.negint, -1 - readUint32(data, pos + 1, options), 5);
}
var neg1b = BigInt(-1);
var pos1b = BigInt(1);
function decodeNegint64(data, pos, _minor, options) {
  const int = readUint64(data, pos + 1, options);
  if (typeof int !== "bigint") {
    const value = -1 - int;
    if (value >= Number.MIN_SAFE_INTEGER) {
      return new Token(Type.negint, value, 9);
    }
  }
  if (options.allowBigInt !== true) {
    throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`);
  }
  return new Token(Type.negint, neg1b - BigInt(int), 9);
}
function encodeNegint(buf2, token) {
  const negint = token.value;
  const unsigned = typeof negint === "bigint" ? negint * neg1b - pos1b : negint * -1 - 1;
  encodeUintValue(buf2, token.type.majorEncoded, unsigned);
}
encodeNegint.encodedSize = function encodedSize3(token) {
  const negint = token.value;
  const unsigned = typeof negint === "bigint" ? negint * neg1b - pos1b : negint * -1 - 1;
  if (unsigned < uintBoundaries[0]) {
    return 1;
  }
  if (unsigned < uintBoundaries[1]) {
    return 2;
  }
  if (unsigned < uintBoundaries[2]) {
    return 3;
  }
  if (unsigned < uintBoundaries[3]) {
    return 5;
  }
  return 9;
};
encodeNegint.compareTokens = function compareTokens2(tok1, tok2) {
  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : (
    /* c8 ignore next */
    0
  );
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/2bytes.js
function toToken(data, pos, prefix2, length4) {
  assertEnoughData(data, pos, prefix2 + length4);
  const buf2 = slice(data, pos + prefix2, pos + prefix2 + length4);
  return new Token(Type.bytes, buf2, prefix2 + length4);
}
function decodeBytesCompact(data, pos, minor, _options2) {
  return toToken(data, pos, 1, minor);
}
function decodeBytes8(data, pos, _minor, options) {
  return toToken(data, pos, 2, readUint8(data, pos + 1, options));
}
function decodeBytes16(data, pos, _minor, options) {
  return toToken(data, pos, 3, readUint16(data, pos + 1, options));
}
function decodeBytes32(data, pos, _minor, options) {
  return toToken(data, pos, 5, readUint32(data, pos + 1, options));
}
function decodeBytes64(data, pos, _minor, options) {
  const l = readUint64(data, pos + 1, options);
  if (typeof l === "bigint") {
    throw new Error(`${decodeErrPrefix} 64-bit integer bytes lengths not supported`);
  }
  return toToken(data, pos, 9, l);
}
function tokenBytes(token) {
  if (token.encodedBytes === void 0) {
    token.encodedBytes = token.type === Type.string ? fromString(token.value) : token.value;
  }
  return token.encodedBytes;
}
function encodeBytes(buf2, token) {
  const bytes2 = tokenBytes(token);
  encodeUintValue(buf2, token.type.majorEncoded, bytes2.length);
  buf2.push(bytes2);
}
encodeBytes.encodedSize = function encodedSize4(token) {
  const bytes2 = tokenBytes(token);
  return encodeUintValue.encodedSize(bytes2.length) + bytes2.length;
};
encodeBytes.compareTokens = function compareTokens3(tok1, tok2) {
  return compareBytes(tokenBytes(tok1), tokenBytes(tok2));
};
function compareBytes(b1, b2) {
  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : compare(b1, b2);
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/3string.js
function toToken2(data, pos, prefix2, length4, options) {
  const totLength = prefix2 + length4;
  assertEnoughData(data, pos, totLength);
  const tok = new Token(Type.string, toString(data, pos + prefix2, pos + totLength), totLength);
  if (options.retainStringBytes === true) {
    tok.byteValue = slice(data, pos + prefix2, pos + totLength);
  }
  return tok;
}
function decodeStringCompact(data, pos, minor, options) {
  return toToken2(data, pos, 1, minor, options);
}
function decodeString8(data, pos, _minor, options) {
  return toToken2(data, pos, 2, readUint8(data, pos + 1, options), options);
}
function decodeString16(data, pos, _minor, options) {
  return toToken2(data, pos, 3, readUint16(data, pos + 1, options), options);
}
function decodeString32(data, pos, _minor, options) {
  return toToken2(data, pos, 5, readUint32(data, pos + 1, options), options);
}
function decodeString64(data, pos, _minor, options) {
  const l = readUint64(data, pos + 1, options);
  if (typeof l === "bigint") {
    throw new Error(`${decodeErrPrefix} 64-bit integer string lengths not supported`);
  }
  return toToken2(data, pos, 9, l, options);
}
var encodeString = encodeBytes;

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/4array.js
function toToken3(_data2, _pos, prefix2, length4) {
  return new Token(Type.array, length4, prefix2);
}
function decodeArrayCompact(data, pos, minor, _options2) {
  return toToken3(data, pos, 1, minor);
}
function decodeArray8(data, pos, _minor, options) {
  return toToken3(data, pos, 2, readUint8(data, pos + 1, options));
}
function decodeArray16(data, pos, _minor, options) {
  return toToken3(data, pos, 3, readUint16(data, pos + 1, options));
}
function decodeArray32(data, pos, _minor, options) {
  return toToken3(data, pos, 5, readUint32(data, pos + 1, options));
}
function decodeArray64(data, pos, _minor, options) {
  const l = readUint64(data, pos + 1, options);
  if (typeof l === "bigint") {
    throw new Error(`${decodeErrPrefix} 64-bit integer array lengths not supported`);
  }
  return toToken3(data, pos, 9, l);
}
function decodeArrayIndefinite(data, pos, _minor, options) {
  if (options.allowIndefinite === false) {
    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`);
  }
  return toToken3(data, pos, 1, Infinity);
}
function encodeArray(buf2, token) {
  encodeUintValue(buf2, Type.array.majorEncoded, token.value);
}
encodeArray.compareTokens = encodeUint.compareTokens;
encodeArray.encodedSize = function encodedSize5(token) {
  return encodeUintValue.encodedSize(token.value);
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/5map.js
function toToken4(_data2, _pos, prefix2, length4) {
  return new Token(Type.map, length4, prefix2);
}
function decodeMapCompact(data, pos, minor, _options2) {
  return toToken4(data, pos, 1, minor);
}
function decodeMap8(data, pos, _minor, options) {
  return toToken4(data, pos, 2, readUint8(data, pos + 1, options));
}
function decodeMap16(data, pos, _minor, options) {
  return toToken4(data, pos, 3, readUint16(data, pos + 1, options));
}
function decodeMap32(data, pos, _minor, options) {
  return toToken4(data, pos, 5, readUint32(data, pos + 1, options));
}
function decodeMap64(data, pos, _minor, options) {
  const l = readUint64(data, pos + 1, options);
  if (typeof l === "bigint") {
    throw new Error(`${decodeErrPrefix} 64-bit integer map lengths not supported`);
  }
  return toToken4(data, pos, 9, l);
}
function decodeMapIndefinite(data, pos, _minor, options) {
  if (options.allowIndefinite === false) {
    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`);
  }
  return toToken4(data, pos, 1, Infinity);
}
function encodeMap(buf2, token) {
  encodeUintValue(buf2, Type.map.majorEncoded, token.value);
}
encodeMap.compareTokens = encodeUint.compareTokens;
encodeMap.encodedSize = function encodedSize6(token) {
  return encodeUintValue.encodedSize(token.value);
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/6tag.js
function decodeTagCompact(_data2, _pos, minor, _options2) {
  return new Token(Type.tag, minor, 1);
}
function decodeTag8(data, pos, _minor, options) {
  return new Token(Type.tag, readUint8(data, pos + 1, options), 2);
}
function decodeTag16(data, pos, _minor, options) {
  return new Token(Type.tag, readUint16(data, pos + 1, options), 3);
}
function decodeTag32(data, pos, _minor, options) {
  return new Token(Type.tag, readUint32(data, pos + 1, options), 5);
}
function decodeTag64(data, pos, _minor, options) {
  return new Token(Type.tag, readUint64(data, pos + 1, options), 9);
}
function encodeTag(buf2, token) {
  encodeUintValue(buf2, Type.tag.majorEncoded, token.value);
}
encodeTag.compareTokens = encodeUint.compareTokens;
encodeTag.encodedSize = function encodedSize7(token) {
  return encodeUintValue.encodedSize(token.value);
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/7float.js
var MINOR_FALSE = 20;
var MINOR_TRUE = 21;
var MINOR_NULL = 22;
var MINOR_UNDEFINED = 23;
function decodeUndefined(_data2, _pos, _minor, options) {
  if (options.allowUndefined === false) {
    throw new Error(`${decodeErrPrefix} undefined values are not supported`);
  } else if (options.coerceUndefinedToNull === true) {
    return new Token(Type.null, null, 1);
  }
  return new Token(Type.undefined, void 0, 1);
}
function decodeBreak(_data2, _pos, _minor, options) {
  if (options.allowIndefinite === false) {
    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`);
  }
  return new Token(Type.break, void 0, 1);
}
function createToken(value, bytes2, options) {
  if (options) {
    if (options.allowNaN === false && Number.isNaN(value)) {
      throw new Error(`${decodeErrPrefix} NaN values are not supported`);
    }
    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {
      throw new Error(`${decodeErrPrefix} Infinity values are not supported`);
    }
  }
  return new Token(Type.float, value, bytes2);
}
function decodeFloat16(data, pos, _minor, options) {
  return createToken(readFloat16(data, pos + 1), 3, options);
}
function decodeFloat32(data, pos, _minor, options) {
  return createToken(readFloat32(data, pos + 1), 5, options);
}
function decodeFloat64(data, pos, _minor, options) {
  return createToken(readFloat64(data, pos + 1), 9, options);
}
function encodeFloat(buf2, token, options) {
  const float2 = token.value;
  if (float2 === false) {
    buf2.push([Type.float.majorEncoded | MINOR_FALSE]);
  } else if (float2 === true) {
    buf2.push([Type.float.majorEncoded | MINOR_TRUE]);
  } else if (float2 === null) {
    buf2.push([Type.float.majorEncoded | MINOR_NULL]);
  } else if (float2 === void 0) {
    buf2.push([Type.float.majorEncoded | MINOR_UNDEFINED]);
  } else {
    let decoded;
    let success = false;
    if (!options || options.float64 !== true) {
      encodeFloat16(float2);
      decoded = readFloat16(ui8a, 1);
      if (float2 === decoded || Number.isNaN(float2)) {
        ui8a[0] = 249;
        buf2.push(ui8a.slice(0, 3));
        success = true;
      } else {
        encodeFloat32(float2);
        decoded = readFloat32(ui8a, 1);
        if (float2 === decoded) {
          ui8a[0] = 250;
          buf2.push(ui8a.slice(0, 5));
          success = true;
        }
      }
    }
    if (!success) {
      encodeFloat64(float2);
      decoded = readFloat64(ui8a, 1);
      ui8a[0] = 251;
      buf2.push(ui8a.slice(0, 9));
    }
  }
}
encodeFloat.encodedSize = function encodedSize8(token, options) {
  const float2 = token.value;
  if (float2 === false || float2 === true || float2 === null || float2 === void 0) {
    return 1;
  }
  if (!options || options.float64 !== true) {
    encodeFloat16(float2);
    let decoded = readFloat16(ui8a, 1);
    if (float2 === decoded || Number.isNaN(float2)) {
      return 3;
    }
    encodeFloat32(float2);
    decoded = readFloat32(ui8a, 1);
    if (float2 === decoded) {
      return 5;
    }
  }
  return 9;
};
var buffer = new ArrayBuffer(9);
var dataView = new DataView(buffer, 1);
var ui8a = new Uint8Array(buffer, 0);
function encodeFloat16(inp) {
  if (inp === Infinity) {
    dataView.setUint16(0, 31744, false);
  } else if (inp === -Infinity) {
    dataView.setUint16(0, 64512, false);
  } else if (Number.isNaN(inp)) {
    dataView.setUint16(0, 32256, false);
  } else {
    dataView.setFloat32(0, inp);
    const valu32 = dataView.getUint32(0);
    const exponent = (valu32 & 2139095040) >> 23;
    const mantissa = valu32 & 8388607;
    if (exponent === 255) {
      dataView.setUint16(0, 31744, false);
    } else if (exponent === 0) {
      dataView.setUint16(0, (inp & 2147483648) >> 16 | mantissa >> 13, false);
    } else {
      const logicalExponent = exponent - 127;
      if (logicalExponent < -24) {
        dataView.setUint16(0, 0);
      } else if (logicalExponent < -14) {
        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | /* sign bit */
        1 << 24 + logicalExponent, false);
      } else {
        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | logicalExponent + 15 << 10 | mantissa >> 13, false);
      }
    }
  }
}
function readFloat16(ui8a2, pos) {
  if (ui8a2.length - pos < 2) {
    throw new Error(`${decodeErrPrefix} not enough data for float16`);
  }
  const half = (ui8a2[pos] << 8) + ui8a2[pos + 1];
  if (half === 31744) {
    return Infinity;
  }
  if (half === 64512) {
    return -Infinity;
  }
  if (half === 32256) {
    return NaN;
  }
  const exp = half >> 10 & 31;
  const mant = half & 1023;
  let val;
  if (exp === 0) {
    val = mant * 2 ** -24;
  } else if (exp !== 31) {
    val = (mant + 1024) * 2 ** (exp - 25);
  } else {
    val = mant === 0 ? Infinity : NaN;
  }
  return half & 32768 ? -val : val;
}
function encodeFloat32(inp) {
  dataView.setFloat32(0, inp, false);
}
function readFloat32(ui8a2, pos) {
  if (ui8a2.length - pos < 4) {
    throw new Error(`${decodeErrPrefix} not enough data for float32`);
  }
  const offset2 = (ui8a2.byteOffset || 0) + pos;
  return new DataView(ui8a2.buffer, offset2, 4).getFloat32(0, false);
}
function encodeFloat64(inp) {
  dataView.setFloat64(0, inp, false);
}
function readFloat64(ui8a2, pos) {
  if (ui8a2.length - pos < 8) {
    throw new Error(`${decodeErrPrefix} not enough data for float64`);
  }
  const offset2 = (ui8a2.byteOffset || 0) + pos;
  return new DataView(ui8a2.buffer, offset2, 8).getFloat64(0, false);
}
encodeFloat.compareTokens = encodeUint.compareTokens;

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/jump.js
function invalidMinor(data, pos, minor) {
  throw new Error(`${decodeErrPrefix} encountered invalid minor (${minor}) for major ${data[pos] >>> 5}`);
}
function errorer(msg) {
  return () => {
    throw new Error(`${decodeErrPrefix} ${msg}`);
  };
}
var jump = [];
for (let i = 0; i <= 23; i++) {
  jump[i] = invalidMinor;
}
jump[24] = decodeUint8;
jump[25] = decodeUint16;
jump[26] = decodeUint32;
jump[27] = decodeUint64;
jump[28] = invalidMinor;
jump[29] = invalidMinor;
jump[30] = invalidMinor;
jump[31] = invalidMinor;
for (let i = 32; i <= 55; i++) {
  jump[i] = invalidMinor;
}
jump[56] = decodeNegint8;
jump[57] = decodeNegint16;
jump[58] = decodeNegint32;
jump[59] = decodeNegint64;
jump[60] = invalidMinor;
jump[61] = invalidMinor;
jump[62] = invalidMinor;
jump[63] = invalidMinor;
for (let i = 64; i <= 87; i++) {
  jump[i] = decodeBytesCompact;
}
jump[88] = decodeBytes8;
jump[89] = decodeBytes16;
jump[90] = decodeBytes32;
jump[91] = decodeBytes64;
jump[92] = invalidMinor;
jump[93] = invalidMinor;
jump[94] = invalidMinor;
jump[95] = errorer("indefinite length bytes/strings are not supported");
for (let i = 96; i <= 119; i++) {
  jump[i] = decodeStringCompact;
}
jump[120] = decodeString8;
jump[121] = decodeString16;
jump[122] = decodeString32;
jump[123] = decodeString64;
jump[124] = invalidMinor;
jump[125] = invalidMinor;
jump[126] = invalidMinor;
jump[127] = errorer("indefinite length bytes/strings are not supported");
for (let i = 128; i <= 151; i++) {
  jump[i] = decodeArrayCompact;
}
jump[152] = decodeArray8;
jump[153] = decodeArray16;
jump[154] = decodeArray32;
jump[155] = decodeArray64;
jump[156] = invalidMinor;
jump[157] = invalidMinor;
jump[158] = invalidMinor;
jump[159] = decodeArrayIndefinite;
for (let i = 160; i <= 183; i++) {
  jump[i] = decodeMapCompact;
}
jump[184] = decodeMap8;
jump[185] = decodeMap16;
jump[186] = decodeMap32;
jump[187] = decodeMap64;
jump[188] = invalidMinor;
jump[189] = invalidMinor;
jump[190] = invalidMinor;
jump[191] = decodeMapIndefinite;
for (let i = 192; i <= 215; i++) {
  jump[i] = decodeTagCompact;
}
jump[216] = decodeTag8;
jump[217] = decodeTag16;
jump[218] = decodeTag32;
jump[219] = decodeTag64;
jump[220] = invalidMinor;
jump[221] = invalidMinor;
jump[222] = invalidMinor;
jump[223] = invalidMinor;
for (let i = 224; i <= 243; i++) {
  jump[i] = errorer("simple values are not supported");
}
jump[244] = invalidMinor;
jump[245] = invalidMinor;
jump[246] = invalidMinor;
jump[247] = decodeUndefined;
jump[248] = errorer("simple values are not supported");
jump[249] = decodeFloat16;
jump[250] = decodeFloat32;
jump[251] = decodeFloat64;
jump[252] = invalidMinor;
jump[253] = invalidMinor;
jump[254] = invalidMinor;
jump[255] = decodeBreak;
var quick = [];
for (let i = 0; i < 24; i++) {
  quick[i] = new Token(Type.uint, i, 1);
}
for (let i = -1; i >= -24; i--) {
  quick[31 - i] = new Token(Type.negint, i, 1);
}
quick[64] = new Token(Type.bytes, new Uint8Array(0), 1);
quick[96] = new Token(Type.string, "", 1);
quick[128] = new Token(Type.array, 0, 1);
quick[160] = new Token(Type.map, 0, 1);
quick[244] = new Token(Type.false, false, 1);
quick[245] = new Token(Type.true, true, 1);
quick[246] = new Token(Type.null, null, 1);
function quickEncodeToken(token) {
  switch (token.type) {
    case Type.false:
      return fromArray([244]);
    case Type.true:
      return fromArray([245]);
    case Type.null:
      return fromArray([246]);
    case Type.bytes:
      if (!token.value.length) {
        return fromArray([64]);
      }
      return;
    case Type.string:
      if (token.value === "") {
        return fromArray([96]);
      }
      return;
    case Type.array:
      if (token.value === 0) {
        return fromArray([128]);
      }
      return;
    case Type.map:
      if (token.value === 0) {
        return fromArray([160]);
      }
      return;
    case Type.uint:
      if (token.value < 24) {
        return fromArray([Number(token.value)]);
      }
      return;
    case Type.negint:
      if (token.value >= -24) {
        return fromArray([31 - Number(token.value)]);
      }
  }
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/encode.js
var defaultEncodeOptions = {
  float64: false,
  mapSorter,
  quickEncodeToken
};
function makeCborEncoders() {
  const encoders = [];
  encoders[Type.uint.major] = encodeUint;
  encoders[Type.negint.major] = encodeNegint;
  encoders[Type.bytes.major] = encodeBytes;
  encoders[Type.string.major] = encodeString;
  encoders[Type.array.major] = encodeArray;
  encoders[Type.map.major] = encodeMap;
  encoders[Type.tag.major] = encodeTag;
  encoders[Type.float.major] = encodeFloat;
  return encoders;
}
var cborEncoders = makeCborEncoders();
var buf = new Bl();
var Ref = class _Ref {
  /**
   * @param {object|any[]} obj
   * @param {Reference|undefined} parent
   */
  constructor(obj, parent) {
    this.obj = obj;
    this.parent = parent;
  }
  /**
   * @param {object|any[]} obj
   * @returns {boolean}
   */
  includes(obj) {
    let p = this;
    do {
      if (p.obj === obj) {
        return true;
      }
    } while (p = p.parent);
    return false;
  }
  /**
   * @param {Reference|undefined} stack
   * @param {object|any[]} obj
   * @returns {Reference}
   */
  static createCheck(stack, obj) {
    if (stack && stack.includes(obj)) {
      throw new Error(`${encodeErrPrefix} object contains circular references`);
    }
    return new _Ref(obj, stack);
  }
};
var simpleTokens = {
  null: new Token(Type.null, null),
  undefined: new Token(Type.undefined, void 0),
  true: new Token(Type.true, true),
  false: new Token(Type.false, false),
  emptyArray: new Token(Type.array, 0),
  emptyMap: new Token(Type.map, 0)
};
var typeEncoders = {
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  number(obj, _typ, _options2, _refStack) {
    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {
      return new Token(Type.float, obj);
    } else if (obj >= 0) {
      return new Token(Type.uint, obj);
    } else {
      return new Token(Type.negint, obj);
    }
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  bigint(obj, _typ, _options2, _refStack) {
    if (obj >= BigInt(0)) {
      return new Token(Type.uint, obj);
    } else {
      return new Token(Type.negint, obj);
    }
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  Uint8Array(obj, _typ, _options2, _refStack) {
    return new Token(Type.bytes, obj);
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  string(obj, _typ, _options2, _refStack) {
    return new Token(Type.string, obj);
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  boolean(obj, _typ, _options2, _refStack) {
    return obj ? simpleTokens.true : simpleTokens.false;
  },
  /**
   * @param {any} _obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  null(_obj, _typ, _options2, _refStack) {
    return simpleTokens.null;
  },
  /**
   * @param {any} _obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  undefined(_obj, _typ, _options2, _refStack) {
    return simpleTokens.undefined;
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  ArrayBuffer(obj, _typ, _options2, _refStack) {
    return new Token(Type.bytes, new Uint8Array(obj));
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} _options
   * @param {Reference} [_refStack]
   * @returns {TokenOrNestedTokens}
   */
  DataView(obj, _typ, _options2, _refStack) {
    return new Token(Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength));
  },
  /**
   * @param {any} obj
   * @param {string} _typ
   * @param {EncodeOptions} options
   * @param {Reference} [refStack]
   * @returns {TokenOrNestedTokens}
   */
  Array(obj, _typ, options, refStack) {
    if (!obj.length) {
      if (options.addBreakTokens === true) {
        return [simpleTokens.emptyArray, new Token(Type.break)];
      }
      return simpleTokens.emptyArray;
    }
    refStack = Ref.createCheck(refStack, obj);
    const entries3 = [];
    let i = 0;
    for (const e of obj) {
      entries3[i++] = objectToTokens(e, options, refStack);
    }
    if (options.addBreakTokens) {
      return [new Token(Type.array, obj.length), entries3, new Token(Type.break)];
    }
    return [new Token(Type.array, obj.length), entries3];
  },
  /**
   * @param {any} obj
   * @param {string} typ
   * @param {EncodeOptions} options
   * @param {Reference} [refStack]
   * @returns {TokenOrNestedTokens}
   */
  Object(obj, typ, options, refStack) {
    const isMap = typ !== "Object";
    const keys2 = isMap ? obj.keys() : Object.keys(obj);
    const length4 = isMap ? obj.size : keys2.length;
    if (!length4) {
      if (options.addBreakTokens === true) {
        return [simpleTokens.emptyMap, new Token(Type.break)];
      }
      return simpleTokens.emptyMap;
    }
    refStack = Ref.createCheck(refStack, obj);
    const entries3 = [];
    let i = 0;
    for (const key of keys2) {
      entries3[i++] = [
        objectToTokens(key, options, refStack),
        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)
      ];
    }
    sortMapEntries(entries3, options);
    if (options.addBreakTokens) {
      return [new Token(Type.map, length4), entries3, new Token(Type.break)];
    }
    return [new Token(Type.map, length4), entries3];
  }
};
typeEncoders.Map = typeEncoders.Object;
typeEncoders.Buffer = typeEncoders.Uint8Array;
for (const typ of "Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64".split(" ")) {
  typeEncoders[`${typ}Array`] = typeEncoders.DataView;
}
function objectToTokens(obj, options = {}, refStack) {
  const typ = is(obj);
  const customTypeEncoder = options && options.typeEncoders && /** @type {OptionalTypeEncoder} */
  options.typeEncoders[typ] || typeEncoders[typ];
  if (typeof customTypeEncoder === "function") {
    const tokens = customTypeEncoder(obj, typ, options, refStack);
    if (tokens != null) {
      return tokens;
    }
  }
  const typeEncoder = typeEncoders[typ];
  if (!typeEncoder) {
    throw new Error(`${encodeErrPrefix} unsupported type: ${typ}`);
  }
  return typeEncoder(obj, typ, options, refStack);
}
function sortMapEntries(entries3, options) {
  if (options.mapSorter) {
    entries3.sort(options.mapSorter);
  }
}
function mapSorter(e1, e2) {
  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0];
  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0];
  if (keyToken1.type !== keyToken2.type) {
    return keyToken1.type.compare(keyToken2.type);
  }
  const major = keyToken1.type.major;
  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2);
  if (tcmp === 0) {
    console.warn("WARNING: complex key types used, CBOR key sorting guarantees are gone");
  }
  return tcmp;
}
function tokensToEncoded(buf2, tokens, encoders, options) {
  if (Array.isArray(tokens)) {
    for (const token of tokens) {
      tokensToEncoded(buf2, token, encoders, options);
    }
  } else {
    encoders[tokens.type.major](buf2, tokens, options);
  }
}
function encodeCustom(data, encoders, options) {
  const tokens = objectToTokens(data, options);
  if (!Array.isArray(tokens) && options.quickEncodeToken) {
    const quickBytes = options.quickEncodeToken(tokens);
    if (quickBytes) {
      return quickBytes;
    }
    const encoder3 = encoders[tokens.type.major];
    if (encoder3.encodedSize) {
      const size5 = encoder3.encodedSize(tokens, options);
      const buf2 = new Bl(size5);
      encoder3(buf2, tokens, options);
      if (buf2.chunks.length !== 1) {
        throw new Error(`Unexpected error: pre-calculated length for ${tokens} was wrong`);
      }
      return asU8A(buf2.chunks[0]);
    }
  }
  buf.reset();
  tokensToEncoded(buf, tokens, encoders, options);
  return buf.toBytes(true);
}
function encode(data, options) {
  options = Object.assign({}, defaultEncodeOptions, options);
  return encodeCustom(data, cborEncoders, options);
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/decode.js
var defaultDecodeOptions = {
  strict: false,
  allowIndefinite: true,
  allowUndefined: true,
  allowBigInt: true
};
var Tokeniser = class {
  /**
   * @param {Uint8Array} data
   * @param {DecodeOptions} options
   */
  constructor(data, options = {}) {
    this._pos = 0;
    this.data = data;
    this.options = options;
  }
  pos() {
    return this._pos;
  }
  done() {
    return this._pos >= this.data.length;
  }
  next() {
    const byt = this.data[this._pos];
    let token = quick[byt];
    if (token === void 0) {
      const decoder3 = jump[byt];
      if (!decoder3) {
        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, "0")})`);
      }
      const minor = byt & 31;
      token = decoder3(this.data, this._pos, minor, this.options);
    }
    this._pos += token.encodedLength;
    return token;
  }
};
var DONE = Symbol.for("DONE");
var BREAK = Symbol.for("BREAK");
function tokenToArray(token, tokeniser, options) {
  const arr = [];
  for (let i = 0; i < token.value; i++) {
    const value = tokensToObject(tokeniser, options);
    if (value === BREAK) {
      if (token.value === Infinity) {
        break;
      }
      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`);
    }
    if (value === DONE) {
      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`);
    }
    arr[i] = value;
  }
  return arr;
}
function tokenToMap(token, tokeniser, options) {
  const useMaps = options.useMaps === true;
  const obj = useMaps ? void 0 : {};
  const m = useMaps ? /* @__PURE__ */ new Map() : void 0;
  for (let i = 0; i < token.value; i++) {
    const key = tokensToObject(tokeniser, options);
    if (key === BREAK) {
      if (token.value === Infinity) {
        break;
      }
      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`);
    }
    if (key === DONE) {
      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`);
    }
    if (useMaps !== true && typeof key !== "string") {
      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`);
    }
    if (options.rejectDuplicateMapKeys === true) {
      if (useMaps && m.has(key) || !useMaps && key in obj) {
        throw new Error(`${decodeErrPrefix} found repeat map key "${key}"`);
      }
    }
    const value = tokensToObject(tokeniser, options);
    if (value === DONE) {
      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`);
    }
    if (useMaps) {
      m.set(key, value);
    } else {
      obj[key] = value;
    }
  }
  return useMaps ? m : obj;
}
function tokensToObject(tokeniser, options) {
  if (tokeniser.done()) {
    return DONE;
  }
  const token = tokeniser.next();
  if (token.type === Type.break) {
    return BREAK;
  }
  if (token.type.terminal) {
    return token.value;
  }
  if (token.type === Type.array) {
    return tokenToArray(token, tokeniser, options);
  }
  if (token.type === Type.map) {
    return tokenToMap(token, tokeniser, options);
  }
  if (token.type === Type.tag) {
    if (options.tags && typeof options.tags[token.value] === "function") {
      const tagged = tokensToObject(tokeniser, options);
      return options.tags[token.value](tagged);
    }
    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`);
  }
  throw new Error("unsupported");
}
function decodeFirst(data, options) {
  if (!(data instanceof Uint8Array)) {
    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`);
  }
  options = Object.assign({}, defaultDecodeOptions, options);
  const tokeniser = options.tokenizer || new Tokeniser(data, options);
  const decoded = tokensToObject(tokeniser, options);
  if (decoded === DONE) {
    throw new Error(`${decodeErrPrefix} did not find any content to decode`);
  }
  if (decoded === BREAK) {
    throw new Error(`${decodeErrPrefix} got unexpected break`);
  }
  return [decoded, data.subarray(tokeniser.pos())];
}
function decode(data, options) {
  const [decoded, remainder] = decodeFirst(data, options);
  if (remainder.length > 0) {
    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`);
  }
  return decoded;
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base32.js
var base32_exports = {};
__export(base32_exports, {
  base32: () => base32,
  base32hex: () => base32hex,
  base32hexpad: () => base32hexpad,
  base32hexpadupper: () => base32hexpadupper,
  base32hexupper: () => base32hexupper,
  base32pad: () => base32pad,
  base32padupper: () => base32padupper,
  base32upper: () => base32upper,
  base32z: () => base32z
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bytes.js
var bytes_exports2 = {};
__export(bytes_exports2, {
  coerce: () => coerce2,
  empty: () => empty3,
  equals: () => equals2,
  fromHex: () => fromHex,
  fromString: () => fromString2,
  isBinary: () => isBinary,
  toHex: () => toHex,
  toString: () => toString2
});
var empty3 = new Uint8Array(0);
function toHex(d) {
  return d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, "0"), "");
}
function fromHex(hex) {
  const hexes2 = hex.match(/../g);
  return hexes2 != null ? new Uint8Array(hexes2.map((b) => parseInt(b, 16))) : empty3;
}
function equals2(aa, bb) {
  if (aa === bb)
    return true;
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
}
function coerce2(o) {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array")
    return o;
  if (o instanceof ArrayBuffer)
    return new Uint8Array(o);
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
}
function isBinary(o) {
  return o instanceof ArrayBuffer || ArrayBuffer.isView(o);
}
function fromString2(str) {
  return new TextEncoder().encode(str);
}
function toString2(b) {
  return new TextDecoder().decode(b);
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/vendor/base-x.js
function base(ALPHABET, name14) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode34(source) {
    if (source instanceof Uint8Array)
      ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length4 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size5 = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size5);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size5 - 1; (carry !== 0 || i2 < length4) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      pbegin++;
    }
    var it2 = size5 - length4;
    while (it2 !== size5 && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size5; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length4 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size5 = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size5);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size5 - 1; (carry !== 0 || i2 < length4) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size5 - length4;
    while (it4 !== size5 && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size5 - it4));
    var j2 = zeroes;
    while (it4 !== size5) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode41(string3) {
    var buffer2 = decodeUnsafe(string3);
    if (buffer2) {
      return buffer2;
    }
    throw new Error(`Non-${name14} character`);
  }
  return {
    encode: encode34,
    decodeUnsafe,
    decode: decode41
  };
}
var src = base;
var _brrp__multiformats_scope_baseX = src;
var base_x_default = _brrp__multiformats_scope_baseX;

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base.js
var Encoder = class {
  constructor(name14, prefix2, baseEncode) {
    __publicField(this, "name");
    __publicField(this, "prefix");
    __publicField(this, "baseEncode");
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
  }
  encode(bytes2) {
    if (bytes2 instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes2)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder = class {
  constructor(name14, prefix2, baseDecode) {
    __publicField(this, "name");
    __publicField(this, "prefix");
    __publicField(this, "baseDecode");
    __publicField(this, "prefixCodePoint");
    this.name = name14;
    this.prefix = prefix2;
    if (prefix2.codePointAt(0) === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = prefix2.codePointAt(0);
    this.baseDecode = baseDecode;
  }
  decode(text2) {
    if (typeof text2 === "string") {
      if (text2.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text2)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text2.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  or(decoder3) {
    return or(this, decoder3);
  }
};
var ComposedDecoder = class {
  constructor(decoders) {
    __publicField(this, "decoders");
    this.decoders = decoders;
  }
  or(decoder3) {
    return or(this, decoder3);
  }
  decode(input10) {
    const prefix2 = input10[0];
    const decoder3 = this.decoders[prefix2];
    if (decoder3 != null) {
      return decoder3.decode(input10);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input10)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
function or(left, right) {
  return new ComposedDecoder({
    ...left.decoders ?? { [left.prefix]: left },
    ...right.decoders ?? { [right.prefix]: right }
  });
}
var Codec = class {
  constructor(name14, prefix2, baseEncode, baseDecode) {
    __publicField(this, "name");
    __publicField(this, "prefix");
    __publicField(this, "baseEncode");
    __publicField(this, "baseDecode");
    __publicField(this, "encoder");
    __publicField(this, "decoder");
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder(name14, prefix2, baseEncode);
    this.decoder = new Decoder(name14, prefix2, baseDecode);
  }
  encode(input10) {
    return this.encoder.encode(input10);
  }
  decode(input10) {
    return this.decoder.decode(input10);
  }
};
function from2({ name: name14, prefix: prefix2, encode: encode34, decode: decode41 }) {
  return new Codec(name14, prefix2, encode34, decode41);
}
function baseX({ name: name14, prefix: prefix2, alphabet: alphabet2 }) {
  const { encode: encode34, decode: decode41 } = base_x_default(alphabet2, name14);
  return from2({
    prefix: prefix2,
    name: name14,
    encode: encode34,
    decode: (text2) => coerce2(decode41(text2))
  });
}
function decode2(string3, alphabet2, bitsPerChar, name14) {
  const codes = {};
  for (let i = 0; i < alphabet2.length; ++i) {
    codes[alphabet2[i]] = i;
  }
  let end = string3.length;
  while (string3[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer2 = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = codes[string3[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name14} character`);
    }
    buffer2 = buffer2 << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer2 >> bits;
    }
  }
  if (bits >= bitsPerChar || (255 & buffer2 << 8 - bits) !== 0) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
}
function encode2(data, alphabet2, bitsPerChar) {
  const pad2 = alphabet2[alphabet2.length - 1] === "=";
  const mask2 = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer2 = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer2 = buffer2 << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet2[mask2 & buffer2 >> bits];
    }
  }
  if (bits !== 0) {
    out += alphabet2[mask2 & buffer2 << bitsPerChar - bits];
  }
  if (pad2) {
    while ((out.length * bitsPerChar & 7) !== 0) {
      out += "=";
    }
  }
  return out;
}
function rfc4648({ name: name14, prefix: prefix2, bitsPerChar, alphabet: alphabet2 }) {
  return from2({
    prefix: prefix2,
    name: name14,
    encode(input10) {
      return encode2(input10, alphabet2, bitsPerChar);
    },
    decode(input10) {
      return decode2(input10, alphabet2, bitsPerChar, name14);
    }
  });
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base32.js
var base32 = rfc4648({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper = rfc4648({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad = rfc4648({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper = rfc4648({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex = rfc4648({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper = rfc4648({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad = rfc4648({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper = rfc4648({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z = rfc4648({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base58.js
var base58_exports = {};
__export(base58_exports, {
  base58btc: () => base58btc,
  base58flickr: () => base58flickr
});
var base58btc = baseX({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr = baseX({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/vendor/varint.js
var encode_1 = encode3;
var MSB = 128;
var REST = 127;
var MSBALL = ~REST;
var INT = Math.pow(2, 31);
function encode3(num, out, offset2) {
  out = out || [];
  offset2 = offset2 || 0;
  var oldOffset = offset2;
  while (num >= INT) {
    out[offset2++] = num & 255 | MSB;
    num /= 128;
  }
  while (num & MSBALL) {
    out[offset2++] = num & 255 | MSB;
    num >>>= 7;
  }
  out[offset2] = num | 0;
  encode3.bytes = offset2 - oldOffset + 1;
  return out;
}
var decode3 = read;
var MSB$1 = 128;
var REST$1 = 127;
function read(buf2, offset2) {
  var res = 0, offset2 = offset2 || 0, shift = 0, counter = offset2, b, l = buf2.length;
  do {
    if (counter >= l) {
      read.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf2[counter++];
    res += shift < 28 ? (b & REST$1) << shift : (b & REST$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1);
  read.bytes = counter - offset2;
  return res;
}
var N1 = Math.pow(2, 7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);
var length = function(value) {
  return value < N1 ? 1 : value < N2 ? 2 : value < N3 ? 3 : value < N4 ? 4 : value < N5 ? 5 : value < N6 ? 6 : value < N7 ? 7 : value < N8 ? 8 : value < N9 ? 9 : 10;
};
var varint = {
  encode: encode_1,
  decode: decode3,
  encodingLength: length
};
var _brrp_varint = varint;
var varint_default = _brrp_varint;

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/varint.js
function decode4(data, offset2 = 0) {
  const code19 = varint_default.decode(data, offset2);
  return [code19, varint_default.decode.bytes];
}
function encodeTo(int, target, offset2 = 0) {
  varint_default.encode(int, target, offset2);
  return target;
}
function encodingLength(int) {
  return varint_default.encodingLength(int);
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/hashes/digest.js
function create(code19, digest5) {
  const size5 = digest5.byteLength;
  const sizeOffset = encodingLength(code19);
  const digestOffset = sizeOffset + encodingLength(size5);
  const bytes2 = new Uint8Array(digestOffset + size5);
  encodeTo(code19, bytes2, 0);
  encodeTo(size5, bytes2, sizeOffset);
  bytes2.set(digest5, digestOffset);
  return new Digest2(code19, size5, digest5, bytes2);
}
function decode5(multihash) {
  const bytes2 = coerce2(multihash);
  const [code19, sizeOffset] = decode4(bytes2);
  const [size5, digestOffset] = decode4(bytes2.subarray(sizeOffset));
  const digest5 = bytes2.subarray(sizeOffset + digestOffset);
  if (digest5.byteLength !== size5) {
    throw new Error("Incorrect length");
  }
  return new Digest2(code19, size5, digest5, bytes2);
}
function equals3(a, b) {
  if (a === b) {
    return true;
  } else {
    const data = b;
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals2(a.bytes, data.bytes);
  }
}
var Digest2 = class {
  /**
   * Creates a multihash digest.
   */
  constructor(code19, size5, digest5, bytes2) {
    __publicField(this, "code");
    __publicField(this, "size");
    __publicField(this, "digest");
    __publicField(this, "bytes");
    this.code = code19;
    this.size = size5;
    this.digest = digest5;
    this.bytes = bytes2;
  }
};

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/cid.js
function format(link5, base4) {
  const { bytes: bytes2, version: version2 } = link5;
  switch (version2) {
    case 0:
      return toStringV0(bytes2, baseCache(link5), base4 ?? base58btc.encoder);
    default:
      return toStringV1(bytes2, baseCache(link5), base4 ?? base32.encoder);
  }
}
var cache = /* @__PURE__ */ new WeakMap();
function baseCache(cid) {
  const baseCache4 = cache.get(cid);
  if (baseCache4 == null) {
    const baseCache5 = /* @__PURE__ */ new Map();
    cache.set(cid, baseCache5);
    return baseCache5;
  }
  return baseCache4;
}
var _a;
var CID = class _CID {
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param multihash - (Multi)hash of the of the content.
   */
  constructor(version2, code19, multihash, bytes2) {
    __publicField(this, "code");
    __publicField(this, "version");
    __publicField(this, "multihash");
    __publicField(this, "bytes");
    __publicField(this, "/");
    __publicField(this, _a, "CID");
    this.code = code19;
    this.version = version2;
    this.multihash = multihash;
    this.bytes = bytes2;
    this["/"] = bytes2;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  toV0() {
    switch (this.version) {
      case 0: {
        return this;
      }
      case 1: {
        const { code: code19, multihash } = this;
        if (code19 !== DAG_PB_CODE) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return _CID.createV0(multihash);
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
      }
    }
  }
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code19, digest: digest5 } = this.multihash;
        const multihash = create(code19, digest5);
        return _CID.createV1(this.code, multihash);
      }
      case 1: {
        return this;
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
      }
    }
  }
  equals(other) {
    return _CID.equals(this, other);
  }
  static equals(self2, other) {
    const unknown2 = other;
    return unknown2 != null && self2.code === unknown2.code && self2.version === unknown2.version && equals3(self2.multihash, unknown2.multihash);
  }
  toString(base4) {
    return format(this, base4);
  }
  toJSON() {
    return { "/": format(this) };
  }
  link() {
    return this;
  }
  // Legacy
  [(_a = Symbol.toStringTag, Symbol.for("nodejs.util.inspect.custom"))]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   */
  static asCID(input10) {
    if (input10 == null) {
      return null;
    }
    const value = input10;
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version: version2, code: code19, multihash, bytes: bytes2 } = value;
      return new _CID(version2, code19, multihash, bytes2 ?? encodeCID(version2, code19, multihash.bytes));
    } else if (value[cidSymbol] === true) {
      const { version: version2, multihash, code: code19 } = value;
      const digest5 = decode5(multihash);
      return _CID.create(version2, code19, digest5);
    } else {
      return null;
    }
  }
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param digest - (Multi)hash of the of the content.
   */
  static create(version2, code19, digest5) {
    if (typeof code19 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest5.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version2) {
      case 0: {
        if (code19 !== DAG_PB_CODE) {
          throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);
        } else {
          return new _CID(version2, code19, digest5, digest5.bytes);
        }
      }
      case 1: {
        const bytes2 = encodeCID(version2, code19, digest5.bytes);
        return new _CID(version2, code19, digest5, bytes2);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   */
  static createV0(digest5) {
    return _CID.create(0, DAG_PB_CODE, digest5);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @param code - Content encoding format code.
   * @param digest - Multihash of the content.
   */
  static createV1(code19, digest5) {
    return _CID.create(1, code19, digest5);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   */
  static decode(bytes2) {
    const [cid, remainder] = _CID.decodeFirst(bytes2);
    if (remainder.length !== 0) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   */
  static decodeFirst(bytes2) {
    const specs = _CID.inspectBytes(bytes2);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce2(bytes2.subarray(prefixSize, prefixSize + specs.multihashSize));
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
    const digest5 = new Digest2(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
    const cid = specs.version === 0 ? _CID.createV0(digest5) : _CID.createV1(specs.codec, digest5);
    return [cid, bytes2.subarray(specs.size)];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   */
  static inspectBytes(initialBytes) {
    let offset2 = 0;
    const next = () => {
      const [i, length4] = decode4(initialBytes.subarray(offset2));
      offset2 += length4;
      return i;
    };
    let version2 = next();
    let codec = DAG_PB_CODE;
    if (version2 === 18) {
      version2 = 0;
      offset2 = 0;
    } else {
      codec = next();
    }
    if (version2 !== 0 && version2 !== 1) {
      throw new RangeError(`Invalid CID version ${version2}`);
    }
    const prefixSize = offset2;
    const multihashCode = next();
    const digestSize = next();
    const size5 = offset2 + digestSize;
    const multihashSize = size5 - prefixSize;
    return { version: version2, codec, multihashCode, digestSize, multihashSize, size: size5 };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   */
  static parse(source, base4) {
    const [prefix2, bytes2] = parseCIDtoBytes(source, base4);
    const cid = _CID.decode(bytes2);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache(cid).set(prefix2, source);
    return cid;
  }
};
function parseCIDtoBytes(source, base4) {
  switch (source[0]) {
    case "Q": {
      const decoder3 = base4 ?? base58btc;
      return [
        base58btc.prefix,
        decoder3.decode(`${base58btc.prefix}${source}`)
      ];
    }
    case base58btc.prefix: {
      const decoder3 = base4 ?? base58btc;
      return [base58btc.prefix, decoder3.decode(source)];
    }
    case base32.prefix: {
      const decoder3 = base4 ?? base32;
      return [base32.prefix, decoder3.decode(source)];
    }
    default: {
      if (base4 == null) {
        throw Error("To parse non base32 or base58btc encoded CID multibase decoder must be provided");
      }
      return [source[0], base4.decode(source)];
    }
  }
}
function toStringV0(bytes2, cache5, base4) {
  const { prefix: prefix2 } = base4;
  if (prefix2 !== base58btc.prefix) {
    throw Error(`Cannot string encode V0 in ${base4.name} encoding`);
  }
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2).slice(1);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
}
function toStringV1(bytes2, cache5, base4) {
  const { prefix: prefix2 } = base4;
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
}
var DAG_PB_CODE = 112;
var SHA_256_CODE = 18;
function encodeCID(version2, code19, multihash) {
  const codeOffset = encodingLength(version2);
  const hashOffset = codeOffset + encodingLength(code19);
  const bytes2 = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo(version2, bytes2, 0);
  encodeTo(code19, bytes2, codeOffset);
  bytes2.set(multihash, hashOffset);
  return bytes2;
}
var cidSymbol = Symbol.for("@ipld/js-cid/CID");

// ../../node_modules/.pnpm/@ipld+dag-cbor@9.2.1/node_modules/@ipld/dag-cbor/src/index.js
var CID_CBOR_TAG = 42;
function toByteView(buf2) {
  if (buf2 instanceof ArrayBuffer) {
    return new Uint8Array(buf2, 0, buf2.byteLength);
  }
  return buf2;
}
function cidEncoder(obj) {
  if (obj.asCID !== obj && obj["/"] !== obj.bytes) {
    return null;
  }
  const cid = CID.asCID(obj);
  if (!cid) {
    return null;
  }
  const bytes2 = new Uint8Array(cid.bytes.byteLength + 1);
  bytes2.set(cid.bytes, 1);
  return [
    new Token(Type.tag, CID_CBOR_TAG),
    new Token(Type.bytes, bytes2)
  ];
}
function undefinedEncoder() {
  throw new Error("`undefined` is not supported by the IPLD Data Model and cannot be encoded");
}
function numberEncoder(num) {
  if (Number.isNaN(num)) {
    throw new Error("`NaN` is not supported by the IPLD Data Model and cannot be encoded");
  }
  if (num === Infinity || num === -Infinity) {
    throw new Error("`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded");
  }
  return null;
}
var _encodeOptions = {
  float64: true,
  typeEncoders: {
    Object: cidEncoder,
    undefined: undefinedEncoder,
    number: numberEncoder
  }
};
var encodeOptions = {
  ..._encodeOptions,
  typeEncoders: {
    ..._encodeOptions.typeEncoders
  }
};
function cidDecoder(bytes2) {
  if (bytes2[0] !== 0) {
    throw new Error("Invalid CID for CBOR tag 42; expected leading 0x00");
  }
  return CID.decode(bytes2.subarray(1));
}
var _decodeOptions = {
  allowIndefinite: false,
  coerceUndefinedToNull: true,
  allowNaN: false,
  allowInfinity: false,
  allowBigInt: true,
  // this will lead to BigInt for ints outside of
  // safe-integer range, which may surprise users
  strict: true,
  useMaps: false,
  rejectDuplicateMapKeys: true,
  /** @type {import('cborg').TagDecoder[]} */
  tags: []
};
_decodeOptions.tags[CID_CBOR_TAG] = cidDecoder;
var decodeOptions = {
  ..._decodeOptions,
  tags: _decodeOptions.tags.slice()
};
var name2 = "dag-cbor";
var code3 = 113;
var encode4 = (node) => encode(node, _encodeOptions);
var decode6 = (data) => decode(toByteView(data), _decodeOptions);

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/varint.js
var varint_exports2 = {};
__export(varint_exports2, {
  decode: () => decode8,
  encodeTo: () => encodeTo2,
  encodingLength: () => encodingLength2
});

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/vendor/varint.js
var encode_12 = encode5;
var MSB2 = 128;
var REST2 = 127;
var MSBALL2 = ~REST2;
var INT2 = Math.pow(2, 31);
function encode5(num, out, offset2) {
  out = out || [];
  offset2 = offset2 || 0;
  var oldOffset = offset2;
  while (num >= INT2) {
    out[offset2++] = num & 255 | MSB2;
    num /= 128;
  }
  while (num & MSBALL2) {
    out[offset2++] = num & 255 | MSB2;
    num >>>= 7;
  }
  out[offset2] = num | 0;
  encode5.bytes = offset2 - oldOffset + 1;
  return out;
}
var decode7 = read2;
var MSB$12 = 128;
var REST$12 = 127;
function read2(buf2, offset2) {
  var res = 0, offset2 = offset2 || 0, shift = 0, counter = offset2, b, l = buf2.length;
  do {
    if (counter >= l) {
      read2.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf2[counter++];
    res += shift < 28 ? (b & REST$12) << shift : (b & REST$12) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$12);
  read2.bytes = counter - offset2;
  return res;
}
var N12 = Math.pow(2, 7);
var N22 = Math.pow(2, 14);
var N32 = Math.pow(2, 21);
var N42 = Math.pow(2, 28);
var N52 = Math.pow(2, 35);
var N62 = Math.pow(2, 42);
var N72 = Math.pow(2, 49);
var N82 = Math.pow(2, 56);
var N92 = Math.pow(2, 63);
var length2 = function(value) {
  return value < N12 ? 1 : value < N22 ? 2 : value < N32 ? 3 : value < N42 ? 4 : value < N52 ? 5 : value < N62 ? 6 : value < N72 ? 7 : value < N82 ? 8 : value < N92 ? 9 : 10;
};
var varint2 = {
  encode: encode_12,
  decode: decode7,
  encodingLength: length2
};
var _brrp_varint2 = varint2;
var varint_default2 = _brrp_varint2;

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/varint.js
var decode8 = (data, offset2 = 0) => {
  const code19 = varint_default2.decode(data, offset2);
  return [code19, varint_default2.decode.bytes];
};
var encodeTo2 = (int, target, offset2 = 0) => {
  varint_default2.encode(int, target, offset2);
  return target;
};
var encodingLength2 = (int) => {
  return varint_default2.encodingLength(int);
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/hashes/digest.js
var create2 = (code19, digest5) => {
  const size5 = digest5.byteLength;
  const sizeOffset = encodingLength2(code19);
  const digestOffset = sizeOffset + encodingLength2(size5);
  const bytes2 = new Uint8Array(digestOffset + size5);
  encodeTo2(code19, bytes2, 0);
  encodeTo2(size5, bytes2, sizeOffset);
  bytes2.set(digest5, digestOffset);
  return new Digest3(code19, size5, digest5, bytes2);
};
var decode9 = (multihash) => {
  const bytes2 = coerce(multihash);
  const [code19, sizeOffset] = decode8(bytes2);
  const [size5, digestOffset] = decode8(bytes2.subarray(sizeOffset));
  const digest5 = bytes2.subarray(sizeOffset + digestOffset);
  if (digest5.byteLength !== size5) {
    throw new Error("Incorrect length");
  }
  return new Digest3(code19, size5, digest5, bytes2);
};
var equals4 = (a, b) => {
  if (a === b) {
    return true;
  } else {
    const data = (
      /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */
      b
    );
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals(a.bytes, data.bytes);
  }
};
var Digest3 = class {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor(code19, size5, digest5, bytes2) {
    this.code = code19;
    this.size = size5;
    this.digest = digest5;
    this.bytes = bytes2;
  }
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/vendor/base-x.js
function base2(ALPHABET, name14) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode34(source) {
    if (source instanceof Uint8Array) ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length4 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size5 = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size5);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size5 - 1; (carry !== 0 || i2 < length4) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      pbegin++;
    }
    var it2 = size5 - length4;
    while (it2 !== size5 && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size5; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length4 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size5 = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size5);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size5 - 1; (carry !== 0 || i2 < length4) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size5 - length4;
    while (it4 !== size5 && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size5 - it4));
    var j2 = zeroes;
    while (it4 !== size5) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode41(string3) {
    var buffer2 = decodeUnsafe(string3);
    if (buffer2) {
      return buffer2;
    }
    throw new Error(`Non-${name14} character`);
  }
  return {
    encode: encode34,
    decodeUnsafe,
    decode: decode41
  };
}
var src2 = base2;
var _brrp__multiformats_scope_baseX2 = src2;
var base_x_default2 = _brrp__multiformats_scope_baseX2;

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/bases/base.js
var Encoder2 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor(name14, prefix2, baseEncode) {
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
  }
  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode(bytes2) {
    if (bytes2 instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes2)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder2 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor(name14, prefix2, baseDecode) {
    this.name = name14;
    this.prefix = prefix2;
    if (prefix2.codePointAt(0) === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = /** @type {number} */
    prefix2.codePointAt(0);
    this.baseDecode = baseDecode;
  }
  /**
   * @param {string} text
   */
  decode(text2) {
    if (typeof text2 === "string") {
      if (text2.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text2)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text2.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or(decoder3) {
    return or2(this, decoder3);
  }
};
var ComposedDecoder2 = class {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor(decoders) {
    this.decoders = decoders;
  }
  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or(decoder3) {
    return or2(this, decoder3);
  }
  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode(input10) {
    const prefix2 = (
      /** @type {Prefix} */
      input10[0]
    );
    const decoder3 = this.decoders[prefix2];
    if (decoder3) {
      return decoder3.decode(input10);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input10)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
var or2 = (left, right) => new ComposedDecoder2(
  /** @type {Decoders<L|R>} */
  {
    ...left.decoders || { [
      /** @type API.UnibaseDecoder<L> */
      left.prefix
    ]: left },
    ...right.decoders || { [
      /** @type API.UnibaseDecoder<R> */
      right.prefix
    ]: right }
  }
);
var Codec2 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor(name14, prefix2, baseEncode, baseDecode) {
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder2(name14, prefix2, baseEncode);
    this.decoder = new Decoder2(name14, prefix2, baseDecode);
  }
  /**
   * @param {Uint8Array} input
   */
  encode(input10) {
    return this.encoder.encode(input10);
  }
  /**
   * @param {string} input
   */
  decode(input10) {
    return this.decoder.decode(input10);
  }
};
var from3 = ({ name: name14, prefix: prefix2, encode: encode34, decode: decode41 }) => new Codec2(name14, prefix2, encode34, decode41);
var baseX2 = ({ prefix: prefix2, name: name14, alphabet: alphabet2 }) => {
  const { encode: encode34, decode: decode41 } = base_x_default2(alphabet2, name14);
  return from3({
    prefix: prefix2,
    name: name14,
    encode: encode34,
    /**
     * @param {string} text
     */
    decode: (text2) => coerce(decode41(text2))
  });
};
var decode10 = (string3, alphabet2, bitsPerChar, name14) => {
  const codes = {};
  for (let i = 0; i < alphabet2.length; ++i) {
    codes[alphabet2[i]] = i;
  }
  let end = string3.length;
  while (string3[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer2 = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = codes[string3[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name14} character`);
    }
    buffer2 = buffer2 << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer2 >> bits;
    }
  }
  if (bits >= bitsPerChar || 255 & buffer2 << 8 - bits) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
};
var encode6 = (data, alphabet2, bitsPerChar) => {
  const pad2 = alphabet2[alphabet2.length - 1] === "=";
  const mask2 = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer2 = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer2 = buffer2 << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet2[mask2 & buffer2 >> bits];
    }
  }
  if (bits) {
    out += alphabet2[mask2 & buffer2 << bitsPerChar - bits];
  }
  if (pad2) {
    while (out.length * bitsPerChar & 7) {
      out += "=";
    }
  }
  return out;
};
var rfc46482 = ({ name: name14, prefix: prefix2, bitsPerChar, alphabet: alphabet2 }) => {
  return from3({
    prefix: prefix2,
    name: name14,
    encode(input10) {
      return encode6(input10, alphabet2, bitsPerChar);
    },
    decode(input10) {
      return decode10(input10, alphabet2, bitsPerChar, name14);
    }
  });
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/bases/base58.js
var base58btc2 = baseX2({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr2 = baseX2({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/bases/base32.js
var base322 = rfc46482({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper2 = rfc46482({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad2 = rfc46482({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper2 = rfc46482({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex2 = rfc46482({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper2 = rfc46482({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad2 = rfc46482({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper2 = rfc46482({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z2 = rfc46482({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/cid.js
var format2 = (link5, base4) => {
  const { bytes: bytes2, version: version2 } = link5;
  switch (version2) {
    case 0:
      return toStringV02(
        bytes2,
        baseCache2(link5),
        /** @type {API.MultibaseEncoder<"z">} */
        base4 || base58btc2.encoder
      );
    default:
      return toStringV12(
        bytes2,
        baseCache2(link5),
        /** @type {API.MultibaseEncoder<Prefix>} */
        base4 || base322.encoder
      );
  }
};
var cache2 = /* @__PURE__ */ new WeakMap();
var baseCache2 = (cid) => {
  const baseCache4 = cache2.get(cid);
  if (baseCache4 == null) {
    const baseCache5 = /* @__PURE__ */ new Map();
    cache2.set(cid, baseCache5);
    return baseCache5;
  }
  return baseCache4;
};
var CID2 = class _CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   *
   */
  constructor(version2, code19, multihash, bytes2) {
    this.code = code19;
    this.version = version2;
    this.multihash = multihash;
    this.bytes = bytes2;
    this["/"] = bytes2;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0() {
    switch (this.version) {
      case 0: {
        return (
          /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */
          this
        );
      }
      case 1: {
        const { code: code19, multihash } = this;
        if (code19 !== DAG_PB_CODE2) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE2) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return (
          /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */
          _CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */
            multihash
          )
        );
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        );
      }
    }
  }
  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code19, digest: digest5 } = this.multihash;
        const multihash = create2(code19, digest5);
        return (
          /** @type {CID<Data, Format, Alg, 1>} */
          _CID.createV1(this.code, multihash)
        );
      }
      case 1: {
        return (
          /** @type {CID<Data, Format, Alg, 1>} */
          this
        );
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        );
      }
    }
  }
  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals(other) {
    return _CID.equals(this, other);
  }
  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals(self2, other) {
    const unknown2 = (
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */
      other
    );
    return unknown2 && self2.code === unknown2.code && self2.version === unknown2.version && equals4(self2.multihash, unknown2.multihash);
  }
  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString(base4) {
    return format2(this, base4);
  }
  toJSON() {
    return { "/": format2(this) };
  }
  link() {
    return this;
  }
  get [Symbol.toStringTag]() {
    return "CID";
  }
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID(input10) {
    if (input10 == null) {
      return null;
    }
    const value = (
      /** @type {any} */
      input10
    );
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version: version2, code: code19, multihash, bytes: bytes2 } = value;
      return new _CID(
        version2,
        code19,
        /** @type {API.MultihashDigest<Alg>} */
        multihash,
        bytes2 || encodeCID2(version2, code19, multihash.bytes)
      );
    } else if (value[cidSymbol2] === true) {
      const { version: version2, multihash, code: code19 } = value;
      const digest5 = (
        /** @type {API.MultihashDigest<Alg>} */
        decode9(multihash)
      );
      return _CID.create(version2, code19, digest5);
    } else {
      return null;
    }
  }
  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create(version2, code19, digest5) {
    if (typeof code19 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest5.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version2) {
      case 0: {
        if (code19 !== DAG_PB_CODE2) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE2}) block encoding`
          );
        } else {
          return new _CID(version2, code19, digest5, digest5.bytes);
        }
      }
      case 1: {
        const bytes2 = encodeCID2(version2, code19, digest5.bytes);
        return new _CID(version2, code19, digest5, bytes2);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0(digest5) {
    return _CID.create(0, DAG_PB_CODE2, digest5);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1(code19, digest5) {
    return _CID.create(1, code19, digest5);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode(bytes2) {
    const [cid, remainder] = _CID.decodeFirst(bytes2);
    if (remainder.length) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst(bytes2) {
    const specs = _CID.inspectBytes(bytes2);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce(
      bytes2.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest5 = new Digest3(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid = specs.version === 0 ? _CID.createV0(
      /** @type {API.MultihashDigest<API.SHA_256>} */
      digest5
    ) : _CID.createV1(specs.codec, digest5);
    return [
      /** @type {CID<T, C, A, V>} */
      cid,
      bytes2.subarray(specs.size)
    ];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes(initialBytes) {
    let offset2 = 0;
    const next = () => {
      const [i, length4] = decode8(initialBytes.subarray(offset2));
      offset2 += length4;
      return i;
    };
    let version2 = (
      /** @type {V} */
      next()
    );
    let codec = (
      /** @type {C} */
      DAG_PB_CODE2
    );
    if (
      /** @type {number} */
      version2 === 18
    ) {
      version2 = /** @type {V} */
      0;
      offset2 = 0;
    } else {
      codec = /** @type {C} */
      next();
    }
    if (version2 !== 0 && version2 !== 1) {
      throw new RangeError(`Invalid CID version ${version2}`);
    }
    const prefixSize = offset2;
    const multihashCode = (
      /** @type {A} */
      next()
    );
    const digestSize = next();
    const size5 = offset2 + digestSize;
    const multihashSize = size5 - prefixSize;
    return { version: version2, codec, multihashCode, digestSize, multihashSize, size: size5 };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse(source, base4) {
    const [prefix2, bytes2] = parseCIDtoBytes2(source, base4);
    const cid = _CID.decode(bytes2);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache2(cid).set(prefix2, source);
    return cid;
  }
};
var parseCIDtoBytes2 = (source, base4) => {
  switch (source[0]) {
    case "Q": {
      const decoder3 = base4 || base58btc2;
      return [
        /** @type {Prefix} */
        base58btc2.prefix,
        decoder3.decode(`${base58btc2.prefix}${source}`)
      ];
    }
    case base58btc2.prefix: {
      const decoder3 = base4 || base58btc2;
      return [
        /** @type {Prefix} */
        base58btc2.prefix,
        decoder3.decode(source)
      ];
    }
    case base322.prefix: {
      const decoder3 = base4 || base322;
      return [
        /** @type {Prefix} */
        base322.prefix,
        decoder3.decode(source)
      ];
    }
    default: {
      if (base4 == null) {
        throw Error(
          "To parse non base32 or base58btc encoded CID multibase decoder must be provided"
        );
      }
      return [
        /** @type {Prefix} */
        source[0],
        base4.decode(source)
      ];
    }
  }
};
var toStringV02 = (bytes2, cache5, base4) => {
  const { prefix: prefix2 } = base4;
  if (prefix2 !== base58btc2.prefix) {
    throw Error(`Cannot string encode V0 in ${base4.name} encoding`);
  }
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2).slice(1);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
};
var toStringV12 = (bytes2, cache5, base4) => {
  const { prefix: prefix2 } = base4;
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
};
var DAG_PB_CODE2 = 112;
var SHA_256_CODE2 = 18;
var encodeCID2 = (version2, code19, multihash) => {
  const codeOffset = encodingLength2(version2);
  const hashOffset = codeOffset + encodingLength2(code19);
  const bytes2 = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo2(version2, bytes2, 0);
  encodeTo2(code19, bytes2, codeOffset);
  bytes2.set(multihash, hashOffset);
  return bytes2;
};
var cidSymbol2 = Symbol.for("@ipld/js-cid/CID");

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/link.js
var DAG_PB_CODE3 = 112;
var createLegacy = (digest5) => CID2.create(0, DAG_PB_CODE3, digest5);
var create3 = (code19, digest5) => CID2.create(1, code19, digest5);
var isLink = (value) => {
  if (value == null) {
    return false;
  }
  const withSlash = (
    /** @type {{'/'?: Uint8Array, bytes: Uint8Array}} */
    value
  );
  if (withSlash["/"] != null && withSlash["/"] === withSlash.bytes) {
    return true;
  }
  const withAsCID = (
    /** @type {{'asCID'?: unknown}} */
    value
  );
  if (withAsCID.asCID === value) {
    return true;
  }
  return false;
};
var parse = (source, base4) => CID2.parse(source, base4);

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/proof.js
function truncatedHash(payload) {
  const { digest: digest5 } = sha256_exports.digest(payload);
  return truncate(digest5);
}
var computeNode = (left, right) => {
  const payload = new Uint8Array(left.length + right.length);
  payload.set(left, 0);
  payload.set(right, left.length);
  return truncatedHash(payload);
};
function truncate(node) {
  node[NODE_SIZE - 1] &= 63;
  return node;
}

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/zero-comm.js
var MAX_LEVEL = 64;
var ZeroComm = class {
  constructor() {
    this.bytes = new Uint8Array(MAX_LEVEL * NODE_SIZE);
    this.bytes.set(empty(), 0);
    this.node = empty();
    this.length = NODE_SIZE;
  }
  /**
   * @param {number} start
   * @param {number} end
   */
  slice(start, end) {
    while (this.length < end) {
      this.node = computeNode(this.node, this.node);
      this.bytes.set(this.node, this.length);
      this.length += NODE_SIZE;
    }
    return this.bytes.subarray(start, end);
  }
};
var ZERO_COMM = new ZeroComm();
var fromLevel = (level) => {
  if (level < 0 || level >= MAX_LEVEL) {
    throw new Error(
      `Only levels between 0 and ${MAX_LEVEL - 1} inclusive are available`
    );
  }
  return ZERO_COMM.slice(NODE_SIZE * level, NODE_SIZE * (level + 1));
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/piece/tree.js
var MAX_LEAF_COUNT = 2 ** 32 - 1;
var split = (source) => {
  const count = source.length / NODE_SIZE;
  const chunks = new Array(count);
  for (let n = 0; n < count; n++) {
    const offset2 = n * NODE_SIZE;
    const chunk = source.subarray(offset2, offset2 + NODE_SIZE);
    chunks[n] = chunk;
  }
  return chunks;
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/fr32.js
function toZeroPaddedSize(payloadSize) {
  const size5 = Math.max(payloadSize, MIN_PAYLOAD_SIZE);
  const highestBit = Math.floor(Math.log2(size5));
  const bound = Math.ceil(FR_RATIO * 2 ** (highestBit + 1));
  return size5 <= bound ? bound : Math.ceil(FR_RATIO * 2 ** (highestBit + 2));
}
var toPieceSize = (size5) => toZeroPaddedSize(size5) / FR_RATIO;
var pad = (source, output = new Uint8Array(toPieceSize(source.length))) => {
  const size5 = toZeroPaddedSize(source.byteLength);
  const quadCount = size5 / IN_BYTES_PER_QUAD;
  for (let n = 0; n < quadCount; n++) {
    const readOffset = n * IN_BYTES_PER_QUAD;
    const writeOffset = n * OUT_BYTES_PER_QUAD;
    output.set(source.subarray(readOffset, readOffset + 32), writeOffset);
    output[writeOffset + 31] &= 63;
    for (let i = 32; i < 64; i++) {
      output[writeOffset + i] = source[readOffset + i] << 2 | source[readOffset + i - 1] >> 6;
    }
    output[writeOffset + 63] &= 63;
    for (let i = 64; i < 96; i++) {
      output[writeOffset + i] = source[readOffset + i] << 4 | source[readOffset + i - 1] >> 4;
    }
    output[writeOffset + 95] &= 63;
    for (let i = 96; i < 127; i++) {
      output[writeOffset + i] = source[readOffset + i] << 6 | source[readOffset + i - 1] >> 2;
    }
    output[writeOffset + 127] = source[readOffset + 126] >> 2;
  }
  return output;
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/uint64.js
var log2Floor = (n) => {
  let result = 0n;
  while (n >>= 1n) result++;
  return Number(result);
};
var log2Ceil = (n) => n <= 1n ? 0 : log2Floor(BigInt(n) - 1n) + 1;

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/piece/size/padded.js
var fromHeight = (height2) => {
  const quads = 2n ** BigInt(height2 - 2);
  return quads * PADDED_BYTES_PER_QUAD;
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/piece/size/unpadded.js
var unpadded_exports = {};
__export(unpadded_exports, {
  fromPiece: () => fromPiece,
  toExpanded: () => toExpanded,
  toHeight: () => toHeight,
  toPadded: () => toPadded,
  toPadding: () => toPadding,
  toWidth: () => toWidth
});
var fromPiece = ({ height: height2, padding: padding2 }) => fromHeight(height2) - padding2;
var toPadding = (size5) => toPadded(size5) - size5;
var toPadded = (size5) => toQauds(size5) * PADDED_BYTES_PER_QUAD;
var toExpanded = (size5) => toQauds(size5) * EXPANDED_BYTES_PER_QUAD;
var toWidth = (size5) => toQauds(size5) * LEAFS_PER_QUAD;
var toHeight = (size5) => log2Ceil(toWidth(size5));
var toQauds = (size5) => {
  const quadCount = (size5 + PADDED_BYTES_PER_QUAD - 1n) / PADDED_BYTES_PER_QUAD;
  return 2n ** BigInt(log2Ceil(quadCount));
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/piece/size/expanded.js
var fromHeight2 = (height2) => fromWidth(2n ** BigInt(height2));
var fromWidth = (width) => width * EXPANDED_BYTES_PER_NODE;

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/digest.js
var digest_exports3 = {};
__export(digest_exports3, {
  HEIGHT_SIZE: () => HEIGHT_SIZE,
  MAX_DIGEST_SIZE: () => MAX_DIGEST_SIZE,
  MAX_HEIGHT: () => MAX_HEIGHT,
  MAX_PAYLOAD_SIZE: () => MAX_PAYLOAD_SIZE,
  MAX_SIZE: () => MAX_SIZE,
  ROOT_SIZE: () => ROOT_SIZE,
  TAG_SIZE: () => TAG_SIZE,
  code: () => code4,
  fromBytes: () => fromBytes,
  fromPiece: () => fromPiece2,
  height: () => height,
  name: () => name3,
  padding: () => padding,
  root: () => root,
  toBytes: () => toBytes
});

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/hashes/hasher.js
var from4 = ({ name: name14, code: code19, encode: encode34 }) => new Hasher(name14, code19, encode34);
var Hasher = class {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor(name14, code19, encode34) {
    this.name = name14;
    this.code = code19;
    this.encode = encode34;
  }
  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest(input10) {
    if (input10 instanceof Uint8Array) {
      const result = this.encode(input10);
      return result instanceof Uint8Array ? create2(this.code, result) : result.then((digest5) => create2(this.code, digest5));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/digest.js
var name3 = (
  /** @type {const} */
  "fr32-sha2-256-trunc254-padded-binary-tree"
);
var code4 = 4113;
var MAX_PADDING_SIZE = 9;
var HEIGHT_SIZE = 1;
var ROOT_SIZE = sha256_exports.size;
var MAX_DIGEST_SIZE = MAX_PADDING_SIZE + HEIGHT_SIZE + sha256_exports.size;
var TAG_SIZE = varint_exports2.encodingLength(code4);
var MAX_SIZE = TAG_SIZE + varint_exports2.encodingLength(MAX_DIGEST_SIZE) + MAX_DIGEST_SIZE;
var MAX_HEIGHT = 255;
var MAX_PAYLOAD_SIZE = fromHeight2(MAX_HEIGHT) * BigInt(IN_BITS_FR) / BigInt(OUT_BITS_FR);
var fromPiece2 = ({ padding: padding2, height: height2, root: root2 }) => {
  const paddingLength = varint_exports2.encodingLength(Number(padding2));
  const size5 = paddingLength + HEIGHT_SIZE + ROOT_SIZE;
  const sizeLength = varint_exports2.encodingLength(size5);
  const multihashLength = TAG_SIZE + sizeLength + size5;
  let offset2 = 0;
  const bytes2 = new Uint8Array(multihashLength);
  varint_exports2.encodeTo(code4, bytes2, offset2);
  offset2 += TAG_SIZE;
  varint_exports2.encodeTo(size5, bytes2, offset2);
  offset2 += sizeLength;
  varint_exports2.encodeTo(Number(padding2), bytes2, offset2);
  offset2 += paddingLength;
  bytes2[offset2] = height2;
  offset2 += HEIGHT_SIZE;
  bytes2.set(root2, offset2);
  return new Digest4(bytes2);
};
var fromBytes = (bytes2) => new Digest4(bytes2);
var toBytes = ({ digest: digest5 }) => {
  const SIZE_BYTE_LENGTH = varint_exports2.encodingLength(digest5.length);
  const prefixByteLength = SIZE_BYTE_LENGTH + TAG_SIZE;
  if (digest5.byteOffset >= prefixByteLength) {
    const bytes3 = new Uint8Array(
      digest5.buffer,
      digest5.byteOffset - prefixByteLength,
      digest5.byteOffset + digest5.length
    );
    const [tag2, offset2] = varint_exports2.decode(bytes3);
    if (tag2 === code4 && varint_exports2.decode(bytes3, offset2)[0] === digest5.length) {
      return bytes3;
    }
  }
  const bytes2 = new Uint8Array(digest5.length + prefixByteLength);
  varint_exports2.encodeTo(code4, bytes2);
  varint_exports2.encodeTo(digest5.length, bytes2, TAG_SIZE);
  bytes2.set(digest5, prefixByteLength);
  return bytes2;
};
var height = ({ digest: digest5 }) => {
  const [, offset2] = varint_exports2.decode(digest5);
  return digest5[offset2];
};
var padding = ({ digest: digest5 }) => {
  const [padding2] = varint_exports2.decode(digest5);
  return BigInt(padding2);
};
var root = ({ digest: digest5 }) => {
  const [, offset2] = varint_exports2.decode(digest5);
  return digest5.subarray(
    offset2 + HEIGHT_SIZE,
    offset2 + HEIGHT_SIZE + sha256_exports.size
  );
};
var Digest4 = class {
  /**
   * @param {Uint8Array} bytes
   */
  constructor(bytes2) {
    this.bytes = bytes2;
    const [tag2] = varint_exports2.decode(bytes2);
    if (tag2 !== code4) {
      throw new RangeError(`Expected multihash with code ${code4}`);
    }
    let offset2 = TAG_SIZE;
    const [size5, length4] = varint_exports2.decode(bytes2, offset2);
    offset2 += length4;
    const digest5 = bytes2.subarray(offset2);
    if (digest5.length !== size5) {
      throw new RangeError(
        `Invalid multihash size expected ${offset2 + size5} bytes, got ${bytes2.length} bytes`
      );
    }
    this.digest = digest5;
  }
  get name() {
    return name3;
  }
  get code() {
    return code4;
  }
  get size() {
    return this.digest.length;
  }
  get padding() {
    return padding(this);
  }
  get height() {
    return height(this);
  }
  get root() {
    return root(this);
  }
};

// ../../node_modules/.pnpm/@web3-storage+data-segment@5.1.0/node_modules/@web3-storage/data-segment/src/multihash.js
var name4 = (
  /** @type {const} */
  "fr32-sha2-256-trunc254-padded-binary-tree"
);
var code5 = 4113;
var MAX_HEIGHT2 = 255;
var MAX_PAYLOAD_SIZE2 = fromHeight2(MAX_HEIGHT2) * BigInt(IN_BITS_FR) / BigInt(OUT_BITS_FR);
var digest2 = (payload) => {
  const hasher = new Hasher2();
  hasher.write(payload);
  return hasher.digest();
};
var create4 = () => new Hasher2();
var Hasher2 = class {
  constructor() {
    this.bytesWritten = 0n;
    this.buffer = new Uint8Array(IN_BYTES_PER_QUAD);
    this.offset = 0;
    this.layers = [[]];
  }
  /**
   * Return the total number of bytes written into the hasher. Calling
   * {@link reset} will reset the hasher and the count will be reset to 0.
   *
   * @returns {bigint}
   */
  count() {
    return this.bytesWritten;
  }
  /**
   * Computes the digest of all the data that has been written into this hasher.
   * This method does not have side-effects, meaning that you can continue
   * writing and call this method again to compute digest of all the data
   * written from the very beginning.
   */
  digest() {
    const bytes2 = new Uint8Array(MAX_SIZE);
    const count = this.digestInto(bytes2, 0, true);
    return fromBytes(bytes2.subarray(0, count));
  }
  /**
   * Computes the digest and writes into the given buffer. You can provide
   * optional `byteOffset` to write digest at that offset in the buffer. By
   * default the multihash prefix will be written into the buffer, but you can
   * opt-out by passing `false` as the `asMultihash` argument.
   *
   * @param {Uint8Array} output
   * @param {number} [byteOffset]
   * @param {boolean} asMultihash
   */
  digestInto(output, byteOffset = 0, asMultihash = true) {
    const { buffer: buffer2, layers, offset: offset2, bytesWritten } = this;
    let [leaves, ...nodes] = layers;
    if (offset2 > 0 || bytesWritten === 0n) {
      leaves = [...leaves, ...split(pad(buffer2.fill(0, offset2)))];
    }
    const tree2 = build([leaves, ...nodes]);
    const height2 = tree2.length - 1;
    const [root2] = tree2[height2];
    const padding2 = Number(unpadded_exports.toPadding(this.bytesWritten));
    const paddingLength = varint_exports2.encodingLength(
      /** @type {number & bigint} */
      padding2
    );
    let endOffset = byteOffset;
    if (asMultihash) {
      varint_exports2.encodeTo(code5, output, endOffset);
      endOffset += TAG_SIZE;
      const size5 = paddingLength + HEIGHT_SIZE + ROOT_SIZE;
      const sizeLength = varint_exports2.encodingLength(size5);
      varint_exports2.encodeTo(size5, output, endOffset);
      endOffset += sizeLength;
    }
    varint_exports2.encodeTo(padding2, output, endOffset);
    endOffset += paddingLength;
    output[endOffset] = height2;
    endOffset += 1;
    output.set(root2, endOffset);
    endOffset += root2.length;
    return endOffset - byteOffset;
  }
  /**
   * @param {Uint8Array} bytes
   */
  write(bytes2) {
    const { buffer: buffer2, offset: offset2, layers } = this;
    const leaves = layers[0];
    const { length: length4 } = bytes2;
    if (length4 === 0) {
      return this;
    } else if (this.bytesWritten + BigInt(length4) > MAX_PAYLOAD_SIZE2) {
      throw new RangeError(
        `Writing ${length4} bytes exceeds max payload size of ${MAX_PAYLOAD_SIZE2}`
      );
    } else if (offset2 + length4 < buffer2.length) {
      buffer2.set(bytes2, offset2);
      this.offset += length4;
      this.bytesWritten += BigInt(length4);
      return this;
    } else {
      const bytesRequired = buffer2.length - offset2;
      buffer2.set(bytes2.subarray(0, bytesRequired), offset2);
      leaves.push(...split(pad(buffer2)));
      let readOffset = bytesRequired;
      while (readOffset + IN_BYTES_PER_QUAD < length4) {
        const quad = bytes2.subarray(readOffset, readOffset + IN_BYTES_PER_QUAD);
        leaves.push(...split(pad(quad)));
        readOffset += IN_BYTES_PER_QUAD;
      }
      this.buffer.set(bytes2.subarray(readOffset), 0);
      this.offset = length4 - readOffset;
      this.bytesWritten += BigInt(length4);
      prune(this.layers);
      return this;
    }
  }
  /**
   * Resets this hasher to its initial state so it could be recycled as new
   * instance.
   */
  reset() {
    this.offset = 0;
    this.bytesWritten = 0n;
    this.layers.length = 1;
    this.layers[0].length = 0;
    return this;
  }
  /* c8 ignore next 3 */
  dispose() {
    this.reset();
  }
  get code() {
    return code5;
  }
  get name() {
    return name4;
  }
};
var prune = (layers) => flush(layers, false);
var build = (layers) => flush([...layers], true);
var flush = (layers, build3) => {
  let level = 0;
  while (level < layers.length) {
    let next = layers[level + 1];
    const layer = layers[level];
    if (build3 && layer.length % 2 > 0 && next) {
      layer.push(fromLevel(level));
    }
    level += 1;
    next = next ? build3 ? [...next] : next : [];
    let index2 = 0;
    while (index2 + 1 < layer.length) {
      const node = computeNode(layer[index2], layer[index2 + 1]);
      delete layer[index2];
      delete layer[index2 + 1];
      next.push(node);
      index2 += 2;
    }
    if (next.length) {
      layers[level] = next;
    }
    layer.splice(0, index2);
  }
  return layers;
};

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/storefront.js
var storefront_exports = {};
__export(storefront_exports, {
  connection: () => connection,
  filecoinAccept: () => filecoinAccept2,
  filecoinInfo: () => filecoinInfo2,
  filecoinOffer: () => filecoinOffer2,
  filecoinSubmit: () => filecoinSubmit2
});

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/delegation.js
var delegation_exports = {};
__export(delegation_exports, {
  ArchiveSchema: () => ArchiveSchema,
  Delegation: () => Delegation,
  View: () => Delegation,
  allows: () => allows,
  archive: () => archive,
  create: () => create6,
  delegate: () => delegate,
  exportDAG: () => exportDAG,
  extract: () => extract,
  importDAG: () => importDAG,
  isDelegation: () => isDelegation,
  isLink: () => isLink2,
  view: () => view2
});

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/utf8.js
var encoder = new TextEncoder();
var decoder = new TextDecoder();
var encode7 = (text2) => encoder.encode(text2);
var decode11 = (bytes2) => decoder.decode(bytes2);

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/hashes/identity.js
var code6 = 0;
var name5 = "identity";
var encode8 = coerce;
var digest3 = (input10) => create2(code6, encode8(input10));
var identity = { code: code6, name: name5, encode: encode8, digest: digest3 };

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/did.js
var DID_PREFIX = "did:";
var DID_PREFIX_SIZE = DID_PREFIX.length;
var DID_KEY_PREFIX = `did:key:`;
var DID_KEY_PREFIX_SIZE = DID_KEY_PREFIX.length;
var ED25519 = 237;
var RSA = 4613;
var P256 = 4608;
var P384 = 4609;
var P521 = 4610;
var SECP256K1 = 231;
var BLS12381G1 = 234;
var BLS12381G2 = 235;
var DID_CORE = 3357;
var METHOD_OFFSET = varint_exports2.encodingLength(DID_CORE);
var parse2 = (did2) => {
  if (!did2.startsWith(DID_PREFIX)) {
    throw new RangeError(`Invalid DID "${did2}", must start with 'did:'`);
  } else if (did2.startsWith(DID_KEY_PREFIX)) {
    const key = base58btc2.decode(did2.slice(DID_KEY_PREFIX_SIZE));
    return decode12(key);
  } else {
    const suffix = encode7(did2.slice(DID_PREFIX_SIZE));
    const bytes2 = new Uint8Array(suffix.byteLength + METHOD_OFFSET);
    varint_exports2.encodeTo(DID_CORE, bytes2);
    bytes2.set(suffix, METHOD_OFFSET);
    return new DID(bytes2);
  }
};
var format3 = (id) => id.did();
var from5 = (principal) => {
  if (principal instanceof DID) {
    return principal;
  } else if (principal instanceof Uint8Array) {
    return decode12(principal);
  } else if (typeof principal === "string") {
    return parse2(principal);
  } else {
    return parse2(principal.did());
  }
};
var decode12 = (bytes2) => {
  const [code19] = varint_exports2.decode(bytes2);
  const { buffer: buffer2, byteOffset, byteLength } = bytes2;
  switch (code19) {
    case P256:
      if (bytes2.length > 35) {
        throw new RangeError(`Only p256-pub compressed is supported.`);
      }
    case ED25519:
    case RSA:
    case P384:
    case P521:
    case BLS12381G1:
    case BLS12381G2:
    case SECP256K1:
      return (
        /** @type {UCAN.PrincipalView<any>} */
        new DIDKey(buffer2, byteOffset, byteLength)
      );
    case DID_CORE:
      return new DID(buffer2, byteOffset, byteLength);
    default:
      throw new RangeError(
        `Unsupported DID encoding, unknown multicode 0x${code19.toString(16)}.`
      );
  }
};
var encode9 = (principal) => parse2(principal.did());
var DID = class extends Uint8Array {
  /**
   * @returns {ID}
   */
  did() {
    const bytes2 = new Uint8Array(this.buffer, this.byteOffset + METHOD_OFFSET);
    return (
      /** @type {ID} */
      `did:${decode11(bytes2)}`
    );
  }
  toJSON() {
    return this.did();
  }
};
var DIDKey = class extends DID {
  /**
   * @return {`did:key:${string}`}
   */
  did() {
    return `did:key:${base58btc2.encode(this)}`;
  }
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/codecs/raw.js
var code7 = 85;

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/signature.js
var signature_exports = {};
__export(signature_exports, {
  BLS12381G1: () => BLS12381G12,
  BLS12381G2: () => BLS12381G22,
  EIP191: () => EIP191,
  ES256: () => ES256,
  ES256K: () => ES256K,
  ES384: () => ES384,
  ES512: () => ES512,
  EdDSA: () => EdDSA,
  NON_STANDARD: () => NON_STANDARD,
  RS256: () => RS256,
  Signature: () => Signature,
  create: () => create5,
  createNamed: () => createNamed,
  createNonStandard: () => createNonStandard,
  decode: () => decode13,
  encode: () => encode10,
  format: () => format4,
  fromJSON: () => fromJSON2,
  nameCode: () => nameCode,
  parse: () => parse3,
  toJSON: () => toJSON2,
  view: () => view
});

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/bases/base64.js
var base64 = rfc46482({
  prefix: "m",
  name: "base64",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",
  bitsPerChar: 6
});
var base64pad = rfc46482({
  prefix: "M",
  name: "base64pad",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",
  bitsPerChar: 6
});
var base64url = rfc46482({
  prefix: "u",
  name: "base64url",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_",
  bitsPerChar: 6
});
var base64urlpad = rfc46482({
  prefix: "U",
  name: "base64urlpad",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=",
  bitsPerChar: 6
});

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/signature.js
var NON_STANDARD = 53248;
var ES256K = 53479;
var BLS12381G12 = 53482;
var BLS12381G22 = 53483;
var EdDSA = 53485;
var ES256 = 13636096;
var ES384 = 13636097;
var ES512 = 13636098;
var RS256 = 13636101;
var EIP191 = 53649;
var codeName = (code19) => {
  switch (code19) {
    case ES256K:
      return "ES256K";
    case BLS12381G12:
      return "BLS12381G1";
    case BLS12381G22:
      return "BLS12381G2";
    case EdDSA:
      return "EdDSA";
    case ES256:
      return "ES256";
    case ES384:
      return "ES384";
    case ES512:
      return "ES512";
    case RS256:
      return "RS256";
    case EIP191:
      return "EIP191";
    default:
      throw new RangeError(
        `Unknown signature algorithm code 0x${code19.toString(16)}`
      );
  }
};
var nameCode = (name14) => {
  switch (name14) {
    case "ES256K":
      return ES256K;
    case "BLS12381G1":
      return BLS12381G12;
    case "BLS12381G2":
      return BLS12381G22;
    case "EdDSA":
      return EdDSA;
    case "ES256":
      return ES256;
    case "ES384":
      return ES384;
    case "ES512":
      return ES512;
    case "RS256":
      return RS256;
    case "EIP191":
      return EIP191;
    default:
      return NON_STANDARD;
  }
};
var Signature = class extends Uint8Array {
  get code() {
    const [code19] = varint_exports2.decode(this);
    Object.defineProperties(this, { code: { value: code19 } });
    return (
      /** @type {A} */
      code19
    );
  }
  get size() {
    const value = size2(this);
    Object.defineProperties(this, { size: { value } });
    return value;
  }
  get algorithm() {
    const value = algorithm(this);
    Object.defineProperties(this, { algorithm: { value } });
    return value;
  }
  get raw() {
    const { buffer: buffer2, byteOffset, size: size5, code: code19 } = this;
    const codeSize = varint_exports2.encodingLength(code19);
    const rawSize = varint_exports2.encodingLength(size5);
    const value = new Uint8Array(buffer2, byteOffset + codeSize + rawSize, size5);
    Object.defineProperties(this, { raw: { value } });
    return value;
  }
  /**
   * Verify that this signature was created by the given key.
   *
   * @param {UCAN.Crypto.Verifier<A>} signer
   * @param {UCAN.ByteView<T>} payload
   */
  async verify(signer, payload) {
    try {
      if (await signer.verify(payload, this) === true) {
        return { ok: {} };
      } else {
        throw new Error("Invalid signature");
      }
    } catch (cause) {
      return { error: (
        /** @type {Error} */
        cause
      ) };
    }
  }
  toJSON() {
    return toJSON2(this);
  }
};
var algorithm = (signature) => {
  const { code: code19, raw, buffer: buffer2, byteOffset } = signature;
  if (code19 === NON_STANDARD) {
    const offset2 = raw.byteLength + varint_exports2.encodingLength(code19) + varint_exports2.encodingLength(raw.byteLength);
    const bytes2 = new Uint8Array(buffer2, byteOffset + offset2);
    return decode11(bytes2);
  } else {
    return codeName(code19);
  }
};
var size2 = (signature) => {
  const offset2 = varint_exports2.encodingLength(signature.code);
  const [size5] = varint_exports2.decode(
    new Uint8Array(signature.buffer, signature.byteOffset + offset2)
  );
  return size5;
};
var create5 = (code19, raw) => {
  const _ = codeName(code19);
  const codeSize = varint_exports2.encodingLength(code19);
  const rawSize = varint_exports2.encodingLength(raw.byteLength);
  const signature = new Signature(codeSize + rawSize + raw.byteLength);
  varint_exports2.encodeTo(code19, signature);
  varint_exports2.encodeTo(raw.byteLength, signature, codeSize);
  signature.set(raw, codeSize + rawSize);
  Object.defineProperties(signature, {
    code: { value: code19 },
    size: { value: raw.byteLength }
  });
  return signature;
};
var createNamed = (name14, raw) => {
  const code19 = nameCode(name14);
  return code19 === NON_STANDARD ? createNonStandard(name14, raw) : create5(code19, raw);
};
var createNonStandard = (name14, raw) => {
  const code19 = NON_STANDARD;
  const codeSize = varint_exports2.encodingLength(code19);
  const rawSize = varint_exports2.encodingLength(raw.byteLength);
  const nameBytes = encode7(name14);
  const signature = new Signature(
    codeSize + rawSize + raw.byteLength + nameBytes.byteLength
  );
  varint_exports2.encodeTo(code19, signature);
  varint_exports2.encodeTo(raw.byteLength, signature, codeSize);
  signature.set(raw, codeSize + rawSize);
  signature.set(nameBytes, codeSize + rawSize + raw.byteLength);
  return signature;
};
var view = (bytes2) => new Signature(bytes2.buffer, bytes2.byteOffset, bytes2.byteLength);
var decode13 = (bytes2) => {
  if (!(bytes2 instanceof Uint8Array)) {
    throw new TypeError(
      `Can only decode Uint8Array into a Signature, instead got ${JSON.stringify(
        bytes2
      )}`
    );
  }
  const signature = view(bytes2);
  const { code: code19, algorithm: algorithm2, raw } = signature;
  return signature;
};
var encode10 = (signature) => decode13(signature);
var format4 = (signature, base4) => (base4 || base64url).encode(signature);
var parse3 = (signature, base4) => (
  /** @type {UCAN.SignatureView<T, A>} */
  decode13((base4 || base64url).decode(signature))
);
var toJSON2 = (signature) => ({
  "/": { bytes: base64.baseEncode(signature) }
});
var fromJSON2 = (json) => decode13(base64.baseDecode(json["/"].bytes));

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/schema.js
var readPayload = (data) => readPayloadWith(data, {
  readPrincipal,
  readProof
});
var readJWTPayload = (data) => readPayloadWith(data, {
  readPrincipal: readStringPrincipal,
  readProof: readStringProof
});
var readPayloadWith = (data, { readPrincipal: readPrincipal2, readProof: readProof2 }) => ({
  iss: readPrincipal2(data.iss, "iss"),
  aud: readPrincipal2(data.aud, "aud"),
  att: readCapabilities(data.att, "att"),
  prf: readOptionalArray(data.prf, readProof2, "prf") || [],
  exp: readNullable(data.exp === Infinity ? null : data.exp, readInt, "exp"),
  nbf: readOptional(data.nbf, readInt, "nbf"),
  fct: readOptionalArray(data.fct, readFact, "fct") || [],
  nnc: readOptional(data.nnc, readString, "nnc")
});
var readSignature = (source) => {
  if (source instanceof Uint8Array) {
    return decode13(source);
  } else {
    throw new TypeError(
      `Can only decode Uint8Array into a Signature, instead got ${JSON.stringify(
        source
      )}`
    );
  }
};
var readInt = (input10, name14) => Number.isInteger(input10) ? (
  /** @type {number} */
  input10
) : ParseError.throw(
  `Expected ${name14} to be integer, instead got ${JSON.stringify(input10)}`
);
var readCapability = (input10, context2) => readStruct(input10, asCapability, context2);
var readCapabilities = (input10, context2) => (
  /** @type {C} */
  readArray(input10, readCapability, context2)
);
var asCapability = (input10) => (
  /** @type {C} */
  {
    ...input10,
    can: readAbility(input10.can),
    with: readResource(input10.with)
  }
);
var readAbility = (input10) => typeof input10 !== "string" ? ParseError.throw(
  `Capability has invalid 'can: ${JSON.stringify(
    input10
  )}', value must be a string`
) : input10.slice(1, -1).includes("/") ? (
  /** @type {UCAN.Ability} */
  input10.toLocaleLowerCase()
) : input10 === "*" ? input10 : ParseError.throw(
  `Capability has invalid 'can: "${input10}"', value must have at least one path segment`
);
var readResource = (input10) => typeof input10 !== "string" ? ParseError.throw(
  `Capability has invalid 'with: ${JSON.stringify(
    input10
  )}', value must be a string`
) : parseURL(input10) || ParseError.throw(
  `Capability has invalid 'with: "${input10}"', value must be a valid URI string`
);
var parseURL = (input10) => {
  try {
    new URL(input10);
    return input10;
  } catch (_) {
    return null;
  }
};
var readArray = (input10, read9, context2) => Array.isArray(input10) ? input10.map((element, n) => read9(element, `${context2}[${n}]`)) : ParseError.throw(`${context2} must be an array`);
var readOptionalArray = (input10, reader, context2) => input10 === void 0 ? input10 : readArray(input10, reader, context2);
var readStruct = (input10, reader, context2) => input10 != null && typeof input10 === "object" ? reader(input10) : ParseError.throw(
  `${context2} must be of type object, instead got ${input10}`
);
var readFact = (input10, context2) => readStruct(input10, Object, context2);
var readProof = (source, context2) => isLink(source) ? (
  /** @type {UCAN.Link} */
  source
) : fail(
  `Expected ${context2} to be IPLD link, instead got ${JSON.stringify(
    source
  )}`
);
var readStringProof = (source, context2) => parseProof(readString(source, context2));
var parseProof = (source) => {
  try {
    return parse(source);
  } catch (error3) {
    return create3(code7, identity.digest(encode7(source)));
  }
};
var readPrincipal = (input10, context2) => decode12(readBytes(input10, context2));
var readStringPrincipal = (source, context2) => parse2(readString(source, context2));
var readOptional = (source, read9, context2 = "Field") => source !== void 0 ? read9(source, context2) : void 0;
var readNullable = (source, read9, context2) => source === null ? null : read9(source, context2);
var readString = (source, context2 = "Field") => typeof source === "string" ? source : fail(`${context2} has invalid value ${source}`);
var readBytes = (source, context2) => source instanceof Uint8Array ? source : fail(
  `Expected ${context2} to be Uint8Array, instead got ${JSON.stringify(
    source
  )}`
);
var readVersion = (input10, context2) => /\d+\.\d+\.\d+/.test(
  /** @type {string} */
  input10
) ? (
  /** @type {UCAN.Version} */
  input10
) : ParseError.throw(`Invalid version '${context2}: ${JSON.stringify(input10)}'`);
var readLiteral = (input10, literal2, context2) => input10 === literal2 ? literal2 : ParseError.throw(
  `Expected ${context2} to be a ${JSON.stringify(
    literal2
  )} instead got ${JSON.stringify(input10)}`
);
var ParseError = class extends TypeError {
  get name() {
    return "ParseError";
  }
  /**
   * @param {string} message
   * @returns {never}
   */
  static throw(message) {
    throw new this(message);
  }
};
var fail = (reason) => ParseError.throw(reason);

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/json/encode.js
var JSONEncoder = class extends Array {
  constructor() {
    super();
    this.inRecursive = [];
  }
  /**
   * @param {Bl} buf
   */
  prefix(buf2) {
    const recurs = this.inRecursive[this.inRecursive.length - 1];
    if (recurs) {
      if (recurs.type === Type.array) {
        recurs.elements++;
        if (recurs.elements !== 1) {
          buf2.push([44]);
        }
      }
      if (recurs.type === Type.map) {
        recurs.elements++;
        if (recurs.elements !== 1) {
          if (recurs.elements % 2 === 1) {
            buf2.push([44]);
          } else {
            buf2.push([58]);
          }
        }
      }
    }
  }
  /**
   * @param {Bl} buf
   * @param {Token} token
   */
  [Type.uint.major](buf2, token) {
    this.prefix(buf2);
    const is2 = String(token.value);
    const isa = [];
    for (let i = 0; i < is2.length; i++) {
      isa[i] = is2.charCodeAt(i);
    }
    buf2.push(isa);
  }
  /**
   * @param {Bl} buf
   * @param {Token} token
   */
  [Type.negint.major](buf2, token) {
    this[Type.uint.major](buf2, token);
  }
  /**
   * @param {Bl} _buf
   * @param {Token} _token
   */
  [Type.bytes.major](_buf, _token) {
    throw new Error(`${encodeErrPrefix} unsupported type: Uint8Array`);
  }
  /**
   * @param {Bl} buf
   * @param {Token} token
   */
  [Type.string.major](buf2, token) {
    this.prefix(buf2);
    const byts = fromString(JSON.stringify(token.value));
    buf2.push(byts.length > 32 ? asU8A(byts) : byts);
  }
  /**
   * @param {Bl} buf
   * @param {Token} _token
   */
  [Type.array.major](buf2, _token) {
    this.prefix(buf2);
    this.inRecursive.push({ type: Type.array, elements: 0 });
    buf2.push([91]);
  }
  /**
   * @param {Bl} buf
   * @param {Token} _token
   */
  [Type.map.major](buf2, _token) {
    this.prefix(buf2);
    this.inRecursive.push({ type: Type.map, elements: 0 });
    buf2.push([123]);
  }
  /**
   * @param {Bl} _buf
   * @param {Token} _token
   */
  [Type.tag.major](_buf, _token) {
  }
  /**
   * @param {Bl} buf
   * @param {Token} token
   */
  [Type.float.major](buf2, token) {
    if (token.type.name === "break") {
      const recurs = this.inRecursive.pop();
      if (recurs) {
        if (recurs.type === Type.array) {
          buf2.push([93]);
        } else if (recurs.type === Type.map) {
          buf2.push([125]);
        } else {
          throw new Error("Unexpected recursive type; this should not happen!");
        }
        return;
      }
      throw new Error("Unexpected break; this should not happen!");
    }
    if (token.value === void 0) {
      throw new Error(`${encodeErrPrefix} unsupported type: undefined`);
    }
    this.prefix(buf2);
    if (token.type.name === "true") {
      buf2.push([116, 114, 117, 101]);
      return;
    } else if (token.type.name === "false") {
      buf2.push([102, 97, 108, 115, 101]);
      return;
    } else if (token.type.name === "null") {
      buf2.push([110, 117, 108, 108]);
      return;
    }
    const is2 = String(token.value);
    const isa = [];
    let dp = false;
    for (let i = 0; i < is2.length; i++) {
      isa[i] = is2.charCodeAt(i);
      if (!dp && (isa[i] === 46 || isa[i] === 101 || isa[i] === 69)) {
        dp = true;
      }
    }
    if (!dp) {
      isa.push(46);
      isa.push(48);
    }
    buf2.push(isa);
  }
};
function mapSorter2(e1, e2) {
  if (Array.isArray(e1[0]) || Array.isArray(e2[0])) {
    throw new Error(`${encodeErrPrefix} complex map keys are not supported`);
  }
  const keyToken1 = e1[0];
  const keyToken2 = e2[0];
  if (keyToken1.type !== Type.string || keyToken2.type !== Type.string) {
    throw new Error(`${encodeErrPrefix} non-string map keys are not supported`);
  }
  if (keyToken1 < keyToken2) {
    return -1;
  }
  if (keyToken1 > keyToken2) {
    return 1;
  }
  throw new Error(`${encodeErrPrefix} unexpected duplicate map keys, this is not supported`);
}
var defaultEncodeOptions2 = { addBreakTokens: true, mapSorter: mapSorter2 };
function encode11(data, options) {
  options = Object.assign({}, defaultEncodeOptions2, options);
  return encodeCustom(data, new JSONEncoder(), options);
}

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/json/decode.js
var Tokenizer = class {
  /**
   * @param {Uint8Array} data
   * @param {DecodeOptions} options
   */
  constructor(data, options = {}) {
    this._pos = 0;
    this.data = data;
    this.options = options;
    this.modeStack = ["value"];
    this.lastToken = "";
  }
  pos() {
    return this._pos;
  }
  /**
   * @returns {boolean}
   */
  done() {
    return this._pos >= this.data.length;
  }
  /**
   * @returns {number}
   */
  ch() {
    return this.data[this._pos];
  }
  /**
   * @returns {string}
   */
  currentMode() {
    return this.modeStack[this.modeStack.length - 1];
  }
  skipWhitespace() {
    let c = this.ch();
    while (c === 32 || c === 9 || c === 13 || c === 10) {
      c = this.data[++this._pos];
    }
  }
  /**
   * @param {number[]} str
   */
  expect(str) {
    if (this.data.length - this._pos < str.length) {
      throw new Error(`${decodeErrPrefix} unexpected end of input at position ${this._pos}`);
    }
    for (let i = 0; i < str.length; i++) {
      if (this.data[this._pos++] !== str[i]) {
        throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}, expected to find '${String.fromCharCode(...str)}'`);
      }
    }
  }
  parseNumber() {
    const startPos = this._pos;
    let negative = false;
    let float2 = false;
    const swallow = (chars) => {
      while (!this.done()) {
        const ch = this.ch();
        if (chars.includes(ch)) {
          this._pos++;
        } else {
          break;
        }
      }
    };
    if (this.ch() === 45) {
      negative = true;
      this._pos++;
    }
    if (this.ch() === 48) {
      this._pos++;
      if (this.ch() === 46) {
        this._pos++;
        float2 = true;
      } else {
        return new Token(Type.uint, 0, this._pos - startPos);
      }
    }
    swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]);
    if (negative && this._pos === startPos + 1) {
      throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}`);
    }
    if (!this.done() && this.ch() === 46) {
      if (float2) {
        throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}`);
      }
      float2 = true;
      this._pos++;
      swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]);
    }
    if (!this.done() && (this.ch() === 101 || this.ch() === 69)) {
      float2 = true;
      this._pos++;
      if (!this.done() && (this.ch() === 43 || this.ch() === 45)) {
        this._pos++;
      }
      swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]);
    }
    const numStr = String.fromCharCode.apply(null, this.data.subarray(startPos, this._pos));
    const num = parseFloat(numStr);
    if (float2) {
      return new Token(Type.float, num, this._pos - startPos);
    }
    if (this.options.allowBigInt !== true || Number.isSafeInteger(num)) {
      return new Token(num >= 0 ? Type.uint : Type.negint, num, this._pos - startPos);
    }
    return new Token(num >= 0 ? Type.uint : Type.negint, BigInt(numStr), this._pos - startPos);
  }
  /**
   * @returns {Token}
   */
  parseString() {
    if (this.ch() !== 34) {
      throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}; this shouldn't happen`);
    }
    this._pos++;
    for (let i = this._pos, l = 0; i < this.data.length && l < 65536; i++, l++) {
      const ch = this.data[i];
      if (ch === 92 || ch < 32 || ch >= 128) {
        break;
      }
      if (ch === 34) {
        const str = String.fromCharCode.apply(null, this.data.subarray(this._pos, i));
        this._pos = i + 1;
        return new Token(Type.string, str, l);
      }
    }
    const startPos = this._pos;
    const chars = [];
    const readu4 = () => {
      if (this._pos + 4 >= this.data.length) {
        throw new Error(`${decodeErrPrefix} unexpected end of unicode escape sequence at position ${this._pos}`);
      }
      let u4 = 0;
      for (let i = 0; i < 4; i++) {
        let ch = this.ch();
        if (ch >= 48 && ch <= 57) {
          ch -= 48;
        } else if (ch >= 97 && ch <= 102) {
          ch = ch - 97 + 10;
        } else if (ch >= 65 && ch <= 70) {
          ch = ch - 65 + 10;
        } else {
          throw new Error(`${decodeErrPrefix} unexpected unicode escape character at position ${this._pos}`);
        }
        u4 = u4 * 16 + ch;
        this._pos++;
      }
      return u4;
    };
    const readUtf8Char = () => {
      const firstByte = this.ch();
      let codePoint = null;
      let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;
      if (this._pos + bytesPerSequence > this.data.length) {
        throw new Error(`${decodeErrPrefix} unexpected unicode sequence at position ${this._pos}`);
      }
      let secondByte, thirdByte, fourthByte, tempCodePoint;
      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 128) {
            codePoint = firstByte;
          }
          break;
        case 2:
          secondByte = this.data[this._pos + 1];
          if ((secondByte & 192) === 128) {
            tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;
            if (tempCodePoint > 127) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 3:
          secondByte = this.data[this._pos + 1];
          thirdByte = this.data[this._pos + 2];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;
            if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {
              codePoint = tempCodePoint;
            }
          }
          break;
        case 4:
          secondByte = this.data[this._pos + 1];
          thirdByte = this.data[this._pos + 2];
          fourthByte = this.data[this._pos + 3];
          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {
            tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;
            if (tempCodePoint > 65535 && tempCodePoint < 1114112) {
              codePoint = tempCodePoint;
            }
          }
      }
      if (codePoint === null) {
        codePoint = 65533;
        bytesPerSequence = 1;
      } else if (codePoint > 65535) {
        codePoint -= 65536;
        chars.push(codePoint >>> 10 & 1023 | 55296);
        codePoint = 56320 | codePoint & 1023;
      }
      chars.push(codePoint);
      this._pos += bytesPerSequence;
    };
    while (!this.done()) {
      const ch = this.ch();
      let ch1;
      switch (ch) {
        case 92:
          this._pos++;
          if (this.done()) {
            throw new Error(`${decodeErrPrefix} unexpected string termination at position ${this._pos}`);
          }
          ch1 = this.ch();
          this._pos++;
          switch (ch1) {
            case 34:
            case 39:
            case 92:
            case 47:
              chars.push(ch1);
              break;
            case 98:
              chars.push(8);
              break;
            case 116:
              chars.push(9);
              break;
            case 110:
              chars.push(10);
              break;
            case 102:
              chars.push(12);
              break;
            case 114:
              chars.push(13);
              break;
            case 117:
              chars.push(readu4());
              break;
            default:
              throw new Error(`${decodeErrPrefix} unexpected string escape character at position ${this._pos}`);
          }
          break;
        case 34:
          this._pos++;
          return new Token(Type.string, decodeCodePointsArray(chars), this._pos - startPos);
        default:
          if (ch < 32) {
            throw new Error(`${decodeErrPrefix} invalid control character at position ${this._pos}`);
          } else if (ch < 128) {
            chars.push(ch);
            this._pos++;
          } else {
            readUtf8Char();
          }
      }
    }
    throw new Error(`${decodeErrPrefix} unexpected end of string at position ${this._pos}`);
  }
  /**
   * @returns {Token}
   */
  parseValue() {
    switch (this.ch()) {
      case 123:
        this.modeStack.push("obj-start");
        this._pos++;
        return new Token(Type.map, Infinity, 1);
      case 91:
        this.modeStack.push("array-start");
        this._pos++;
        return new Token(Type.array, Infinity, 1);
      case 34: {
        return this.parseString();
      }
      case 110:
        this.expect([110, 117, 108, 108]);
        return new Token(Type.null, null, 4);
      case 102:
        this.expect([102, 97, 108, 115, 101]);
        return new Token(Type.false, false, 5);
      case 116:
        this.expect([116, 114, 117, 101]);
        return new Token(Type.true, true, 4);
      case 45:
      case 48:
      case 49:
      case 50:
      case 51:
      case 52:
      case 53:
      case 54:
      case 55:
      case 56:
      case 57:
        return this.parseNumber();
      default:
        throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}`);
    }
  }
  /**
   * @returns {Token}
   */
  next() {
    this.skipWhitespace();
    switch (this.currentMode()) {
      case "value":
        this.modeStack.pop();
        return this.parseValue();
      case "array-value": {
        this.modeStack.pop();
        if (this.ch() === 93) {
          this._pos++;
          this.skipWhitespace();
          return new Token(Type.break, void 0, 1);
        }
        if (this.ch() !== 44) {
          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting array delimiter but found '${String.fromCharCode(this.ch())}'`);
        }
        this._pos++;
        this.modeStack.push("array-value");
        this.skipWhitespace();
        return this.parseValue();
      }
      case "array-start": {
        this.modeStack.pop();
        if (this.ch() === 93) {
          this._pos++;
          this.skipWhitespace();
          return new Token(Type.break, void 0, 1);
        }
        this.modeStack.push("array-value");
        this.skipWhitespace();
        return this.parseValue();
      }
      case "obj-key":
        if (this.ch() === 125) {
          this.modeStack.pop();
          this._pos++;
          this.skipWhitespace();
          return new Token(Type.break, void 0, 1);
        }
        if (this.ch() !== 44) {
          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting object delimiter but found '${String.fromCharCode(this.ch())}'`);
        }
        this._pos++;
        this.skipWhitespace();
      case "obj-start": {
        this.modeStack.pop();
        if (this.ch() === 125) {
          this._pos++;
          this.skipWhitespace();
          return new Token(Type.break, void 0, 1);
        }
        const token = this.parseString();
        this.skipWhitespace();
        if (this.ch() !== 58) {
          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting key/value delimiter ':' but found '${String.fromCharCode(this.ch())}'`);
        }
        this._pos++;
        this.modeStack.push("obj-value");
        return token;
      }
      case "obj-value": {
        this.modeStack.pop();
        this.modeStack.push("obj-key");
        this.skipWhitespace();
        return this.parseValue();
      }
      default:
        throw new Error(`${decodeErrPrefix} unexpected parse state at position ${this._pos}; this shouldn't happen`);
    }
  }
};
function decode14(data, options) {
  options = Object.assign({ tokenizer: new Tokenizer(data, options) }, options);
  return decode(data, options);
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/hashes/hasher.js
function from6({ name: name14, code: code19, encode: encode34 }) {
  return new Hasher3(name14, code19, encode34);
}
var Hasher3 = class {
  constructor(name14, code19, encode34) {
    __publicField(this, "name");
    __publicField(this, "code");
    __publicField(this, "encode");
    this.name = name14;
    this.code = code19;
    this.encode = encode34;
  }
  digest(input10) {
    if (input10 instanceof Uint8Array) {
      const result = this.encode(input10);
      return result instanceof Uint8Array ? create(this.code, result) : result.then((digest5) => create(this.code, digest5));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base64.js
var base64_exports = {};
__export(base64_exports, {
  base64: () => base642,
  base64pad: () => base64pad2,
  base64url: () => base64url2,
  base64urlpad: () => base64urlpad2
});
var base642 = rfc4648({
  prefix: "m",
  name: "base64",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",
  bitsPerChar: 6
});
var base64pad2 = rfc4648({
  prefix: "M",
  name: "base64pad",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",
  bitsPerChar: 6
});
var base64url2 = rfc4648({
  prefix: "u",
  name: "base64url",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_",
  bitsPerChar: 6
});
var base64urlpad2 = rfc4648({
  prefix: "U",
  name: "base64urlpad",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=",
  bitsPerChar: 6
});

// ../../node_modules/.pnpm/@ipld+dag-json@10.2.2/node_modules/@ipld/dag-json/src/index.js
function toByteView2(buf2) {
  if (buf2 instanceof ArrayBuffer) {
    return new Uint8Array(buf2, 0, buf2.byteLength);
  }
  return buf2;
}
function cidEncoder2(obj) {
  if (obj.asCID !== obj && obj["/"] !== obj.bytes) {
    return null;
  }
  const cid = CID.asCID(obj);
  if (!cid) {
    return null;
  }
  const cidString = cid.toString();
  return [
    new Token(Type.map, Infinity, 1),
    new Token(Type.string, "/", 1),
    // key
    new Token(Type.string, cidString, cidString.length),
    // value
    new Token(Type.break, void 0, 1)
  ];
}
function bytesEncoder(bytes2) {
  const bytesString = base642.encode(bytes2).slice(1);
  return [
    new Token(Type.map, Infinity, 1),
    new Token(Type.string, "/", 1),
    // key
    new Token(Type.map, Infinity, 1),
    // value
    new Token(Type.string, "bytes", 5),
    // inner key
    new Token(Type.string, bytesString, bytesString.length),
    // inner value
    new Token(Type.break, void 0, 1),
    new Token(Type.break, void 0, 1)
  ];
}
function taBytesEncoder(obj) {
  return bytesEncoder(new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength));
}
function abBytesEncoder(ab) {
  return bytesEncoder(new Uint8Array(ab));
}
function undefinedEncoder2() {
  throw new Error("`undefined` is not supported by the IPLD Data Model and cannot be encoded");
}
function numberEncoder2(num) {
  if (Number.isNaN(num)) {
    throw new Error("`NaN` is not supported by the IPLD Data Model and cannot be encoded");
  }
  if (num === Infinity || num === -Infinity) {
    throw new Error("`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded");
  }
  return null;
}
var encodeOptions2 = {
  typeEncoders: {
    Object: cidEncoder2,
    Buffer: bytesEncoder,
    Uint8Array: bytesEncoder,
    Int8Array: taBytesEncoder,
    Uint16Array: taBytesEncoder,
    Int16Array: taBytesEncoder,
    Uint32Array: taBytesEncoder,
    Int32Array: taBytesEncoder,
    Float32Array: taBytesEncoder,
    Float64Array: taBytesEncoder,
    Uint8ClampedArray: taBytesEncoder,
    BigInt64Array: taBytesEncoder,
    BigUint64Array: taBytesEncoder,
    DataView: taBytesEncoder,
    ArrayBuffer: abBytesEncoder,
    undefined: undefinedEncoder2,
    number: numberEncoder2
  }
};
var DagJsonTokenizer = class extends Tokenizer {
  /**
   * @param {Uint8Array} data
   * @param {object} [options]
   */
  constructor(data, options) {
    super(data, options);
    this.tokenBuffer = [];
  }
  /**
   * @returns {boolean}
   */
  done() {
    return this.tokenBuffer.length === 0 && super.done();
  }
  /**
   * @returns {Token}
   */
  _next() {
    if (this.tokenBuffer.length > 0) {
      return this.tokenBuffer.pop();
    }
    return super.next();
  }
  /**
   * Implements rules outlined in https://github.com/ipld/specs/pull/356
   *
   * @returns {Token}
   */
  next() {
    const token = this._next();
    if (token.type === Type.map) {
      const keyToken = this._next();
      if (keyToken.type === Type.string && keyToken.value === "/") {
        const valueToken = this._next();
        if (valueToken.type === Type.string) {
          const breakToken = this._next();
          if (breakToken.type !== Type.break) {
            throw new Error("Invalid encoded CID form");
          }
          this.tokenBuffer.push(valueToken);
          return new Token(Type.tag, 42, 0);
        }
        if (valueToken.type === Type.map) {
          const innerKeyToken = this._next();
          if (innerKeyToken.type === Type.string && innerKeyToken.value === "bytes") {
            const innerValueToken = this._next();
            if (innerValueToken.type === Type.string) {
              for (let i = 0; i < 2; i++) {
                const breakToken = this._next();
                if (breakToken.type !== Type.break) {
                  throw new Error("Invalid encoded Bytes form");
                }
              }
              const bytes2 = base642.decode(`m${innerValueToken.value}`);
              return new Token(Type.bytes, bytes2, innerValueToken.value.length);
            }
            this.tokenBuffer.push(innerValueToken);
          }
          this.tokenBuffer.push(innerKeyToken);
        }
        this.tokenBuffer.push(valueToken);
      }
      this.tokenBuffer.push(keyToken);
    }
    return token;
  }
};
var decodeOptions2 = {
  allowIndefinite: false,
  allowUndefined: false,
  allowNaN: false,
  allowInfinity: false,
  allowBigInt: true,
  // this will lead to BigInt for ints outside of
  // safe-integer range, which may surprise users
  strict: true,
  useMaps: false,
  rejectDuplicateMapKeys: true,
  /** @type {import('cborg').TagDecoder[]} */
  tags: []
};
decodeOptions2.tags[42] = CID.parse;
var encode12 = (node) => encode11(node, encodeOptions2);
var decode15 = (data) => {
  const buf2 = toByteView2(data);
  const options = Object.assign(decodeOptions2, { tokenizer: new DagJsonTokenizer(buf2, decodeOptions2) });
  return decode14(buf2, options);
};
var utf8Decoder = new TextDecoder();
var utf8Encoder = new TextEncoder();

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/formatter.js
var format5 = (model) => {
  const header = formatHeader(model.v, model.s.algorithm);
  const payload = formatPayload(model);
  const signature = formatSignature(model.s);
  return (
    /** @type {UCAN.JWT<C>} */
    `${header}.${payload}.${signature}`
  );
};
var formatSignPayload = (payload, version2, alg) => `${formatHeader(version2, alg)}.${formatPayload(payload)}`;
var formatHeader = (version2, alg) => base64url.baseEncode(encodeHeader(version2, alg));
var formatPayload = (data) => base64url.baseEncode(encodePayload(data));
var formatSignature = (signature) => base64url.baseEncode(signature.raw);
var encodeHeader = (v, alg) => encode12({
  alg,
  ucv: v,
  typ: "JWT"
});
var encodePayload = (data) => encode12({
  iss: format3(data.iss),
  aud: format3(data.aud),
  att: data.att,
  exp: data.exp,
  prf: data.prf.map(encodeProof),
  // leave out optionals and empty fields
  ...data.fct.length > 0 && { fct: data.fct },
  ...data.nnc && { nnc: data.nnc },
  ...data.nbf && { nbf: data.nbf }
});
var encodeProof = (proof) => (
  /** @type {UCAN.ToString<UCAN.Link>} */
  proof.toString()
);

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/view.js
var toJSON3 = (data) => JSON.parse(decode11(encode12(data)));
var View = class {
  /**
   * @param {UCAN.UCAN<C>} model
   */
  constructor(model) {
    this.model = model;
  }
  get version() {
    return this.model.v;
  }
  get issuer() {
    return from5(this.model.iss);
  }
  get audience() {
    return from5(this.model.aud);
  }
  /**
   * @returns {C}
   */
  get capabilities() {
    return this.model.att;
  }
  /**
   * @returns {number}
   */
  get expiration() {
    const { exp } = this.model;
    return exp === null ? Infinity : exp;
  }
  /**
   * @returns {undefined|number}
   */
  get notBefore() {
    return this.model.nbf;
  }
  /**
   * @returns {undefined|string}
   */
  get nonce() {
    return this.model.nnc;
  }
  /**
   * @returns {UCAN.Fact[]}
   */
  get facts() {
    return this.model.fct;
  }
  /**
   * @returns {UCAN.Link[]}
   */
  get proofs() {
    return this.model.prf;
  }
  get signature() {
    return this.model.s;
  }
  // compatibility with UCAN.UCAN
  get jwt() {
    return this.model.jwt;
  }
  get s() {
    return this.model.s;
  }
  get v() {
    return this.model.v;
  }
  get iss() {
    return this.model.iss;
  }
  get aud() {
    return this.model.aud;
  }
  get att() {
    return this.model.att;
  }
  get exp() {
    return this.model.exp;
  }
  get nbf() {
    return this.model.nbf;
  }
  get nnc() {
    return this.model.nnc;
  }
  get fct() {
    return this.model.fct;
  }
  get prf() {
    return this.model.prf;
  }
  /**
   * @returns {UCAN.ToJSON<UCAN.UCAN<C>, UCAN.UCANJSON<this>>}
   */
  toJSON() {
    const { v, iss, aud, s, att, prf, exp, fct, nnc, nbf } = this.model;
    return {
      iss,
      aud,
      v,
      s,
      exp,
      ...toJSON3({
        att,
        prf,
        ...fct.length > 0 && { fct }
      }),
      ...nnc != null && { nnc },
      ...nbf && { nbf }
    };
  }
};

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/codec/cbor.js
var code8 = code3;
var from7 = (model) => new CBORView(model);
var encode13 = (model) => {
  const { fct, nnc, nbf, ...payload } = readPayload(model);
  return (
    /** @type {Uint8Array} */
    encode4({
      // leave out optionals unless they are set
      ...fct.length > 0 && { fct },
      ...nnc != null && { nnc },
      ...nbf && { nbf },
      ...payload,
      // add version and signature
      v: readVersion(model.v, "v"),
      s: encodeSignature(model.s, "s")
    })
  );
};
var encodeSignature = (signature, context2) => {
  try {
    return encode10(signature);
  } catch (cause) {
    throw new Error(
      `Expected signature ${context2}, instead got ${JSON.stringify(signature)}`,
      // @ts-expect-error - types don't know about second arg
      { cause }
    );
  }
};
var decode16 = (bytes2) => {
  const model = decode6(bytes2);
  return new CBORView({
    ...readPayload(model),
    v: readVersion(model.v, "v"),
    s: readSignature(model.s)
  });
};
var CBORView = class extends View {
  get code() {
    return code8;
  }
  format() {
    return format5(this.model);
  }
  encode() {
    return encode13(this.model);
  }
};

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/parser.js
var parse4 = (jwt) => {
  const segments = jwt.split(".");
  const [header, payload, signature] = segments.length === 3 ? segments : fail(
    `Can't parse UCAN: ${jwt}: Expected JWT format: 3 dot-separated base64url-encoded values.`
  );
  const { ucv, alg } = parseHeader(header);
  return {
    ...parsePayload(payload),
    v: ucv,
    s: createNamed(alg, base64url.baseDecode(signature))
  };
};
var parseHeader = (header) => {
  const { ucv, alg, typ } = decode15(base64url.baseDecode(header));
  return {
    typ: readLiteral(typ, "JWT", "typ"),
    ucv: readVersion(ucv, "ucv"),
    alg: readString(alg, "alg")
  };
};
var parsePayload = (source) => {
  const payload = decode15(base64url.baseDecode(source));
  return readJWTPayload(payload);
};

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/codec/jwt.js
var decode17 = (bytes2) => {
  const jwt = (
    /** @type {UCAN.JWT<C>} */
    decode11(bytes2)
  );
  return new JWTView({ ...parse4(jwt), jwt });
};
var encode14 = ({ jwt }) => encode7(jwt);
var format6 = ({ jwt }) => jwt;
var JWTView = class extends View {
  /**
   * @param {UCAN.FromJWT<C>} model
   */
  constructor(model) {
    super(model);
    this.model = model;
  }
  get code() {
    return code7;
  }
  format() {
    return format6(this.model);
  }
  encode() {
    return encode14(this.model);
  }
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/hashes/sha2-browser.js
var sha = (name14) => (
  /**
   * @param {Uint8Array} data
   */
  async (data) => new Uint8Array(await crypto.subtle.digest(name14, data))
);
var sha2562 = from4({
  name: "sha2-256",
  code: 18,
  encode: sha("SHA-256")
});
var sha512 = from4({
  name: "sha2-512",
  code: 19,
  encode: sha("SHA-512")
});

// ../../node_modules/.pnpm/@ipld+dag-ucan@3.4.0/node_modules/@ipld/dag-ucan/src/lib.js
var VERSION = "0.9.1";
var defaultHasher = sha2562;
var decode18 = (bytes2) => {
  try {
    return decode16(bytes2);
  } catch (_) {
    return decode17(
      /** @type {UCAN.ByteView<UCAN.FromJWT<C>>} */
      bytes2
    );
  }
};
var write = async (ucan2, { hasher = defaultHasher } = {}) => {
  const [code19, bytes2] = ucan2.jwt ? [code7, encode14(ucan2)] : [code8, encode13(ucan2)];
  const digest5 = await hasher.digest(bytes2);
  return {
    bytes: bytes2,
    cid: create3(code19, digest5),
    data: ucan2
  };
};
var issue = async ({
  issuer,
  audience,
  capabilities,
  lifetimeInSeconds = 30,
  expiration = now() + lifetimeInSeconds,
  notBefore,
  facts = [],
  proofs: proofs2 = [],
  nonce
}) => {
  const v = VERSION;
  const data = readPayload({
    iss: parse2(issuer.did()),
    aud: parse2(audience.did()),
    att: capabilities,
    fct: facts,
    exp: expiration,
    nbf: notBefore,
    prf: proofs2,
    nnc: nonce
  });
  const payload = encodeSignaturePayload(data, v, issuer.signatureAlgorithm);
  return from7({
    ...data,
    v,
    s: await issuer.sign(payload)
  });
};
var encodeSignaturePayload = (payload, version2, algorithm2) => encode7(formatSignPayload(payload, version2, algorithm2));
var now = () => Math.floor(Date.now() / 1e3);

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/cbor.js
var cbor_exports3 = {};
__export(cbor_exports3, {
  code: () => code3,
  contentType: () => contentType,
  decode: () => decode6,
  encode: () => encode15,
  link: () => link,
  name: () => name2,
  write: () => write2
});
var contentType = "application/vnd.ipld.dag-cbor";
var prepare = (data, seen) => {
  if (seen.has(data)) {
    throw new TypeError("Can not encode circular structure");
  }
  if (data === void 0 && seen.size === 0) {
    return null;
  }
  if (data === null) {
    return null;
  }
  if (typeof data === "symbol" && seen.size === 0) {
    return null;
  }
  if (isLink(data)) {
    return data;
  }
  if (ArrayBuffer.isView(data)) {
    return data;
  }
  if (Array.isArray(data)) {
    seen.add(data);
    const items = [];
    for (const item of data) {
      items.push(
        item === void 0 || typeof item === "symbol" ? null : prepare(item, seen)
      );
    }
    return items;
  }
  if (typeof /** @type {{toJSON?:unknown}} */
  data.toJSON === "function") {
    seen.add(data);
    const json = (
      /** @type {{toJSON():unknown}} */
      data.toJSON()
    );
    return prepare(json, seen);
  }
  if (typeof data === "object") {
    seen.add(data);
    const object = {};
    for (const [key, value] of Object.entries(data)) {
      if (value !== void 0 && typeof value !== "symbol") {
        object[key] = prepare(value, new Set(seen));
      }
    }
    return object;
  }
  return data;
};
var encode15 = (data) => (
  /** @type {CBOR.ByteView<T>} */
  encode4(prepare(data, /* @__PURE__ */ new Set()))
);
var link = async (bytes2, { hasher = sha2562 } = {}) => {
  return (
    /** @type {API.Link<T, typeof CBOR.code>} */
    create3(code3, await hasher.digest(bytes2))
  );
};
var write2 = async (data, options) => {
  const bytes2 = encode15(data);
  const cid = await link(bytes2, options);
  return { cid, bytes: bytes2 };
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/dag.js
var iterate = function* (value) {
  if (value && typeof value === "object" && "iterateIPLDBlocks" in value && typeof value.iterateIPLDBlocks === "function") {
    yield* value.iterateIPLDBlocks();
  }
};
var createStore = (blocks = []) => {
  const store2 = /* @__PURE__ */ new Map();
  addEveryInto(blocks, store2);
  return store2;
};
var EMBED_CODE = identity.code;
var get = (cid, store2, fallback) => {
  if (cid.multihash.code === EMBED_CODE) {
    return { cid, bytes: cid.multihash.digest };
  }
  const block = (
    /** @type {API.Block<U, Format, Alg, V>|undefined} */
    store2.get(`${cid}`)
  );
  return block ? block : fallback === void 0 ? notFound(cid) : fallback;
};
var notFound = (link5) => {
  throw new Error(`Block for the ${link5} is not found`);
};
var writeInto = async (source, store2, options = {}) => {
  const codec = (
    /** @type {MF.BlockEncoder<C, U>} */
    options.codec || cbor_exports3
  );
  const hasher = (
    /** @type {MF.MultihashHasher<A>} */
    options.hasher || sha2562
  );
  const bytes2 = codec.encode(source);
  const digest5 = await hasher.digest(bytes2);
  const link5 = create3(codec.code, digest5);
  store2.set(
    /** @type {API.ToString<typeof link>} */
    link5.toString(),
    {
      bytes: bytes2,
      cid: link5
    }
  );
  return { bytes: bytes2, cid: link5, data: source };
};
var addInto = ({ cid, bytes: bytes2 }, store2) => {
  store2.set(
    /** @type {API.ToString<typeof cid>} */
    cid.toString(),
    {
      bytes: bytes2,
      cid
    }
  );
  return { bytes: bytes2, cid };
};
var addEveryInto = (source, store2) => {
  for (const block of source) {
    addInto(block, store2);
  }
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/car.js
var car_exports = {};
__export(car_exports, {
  code: () => code9,
  contentType: () => contentType2,
  createWriter: () => createWriter2,
  decode: () => decode19,
  encode: () => encode16,
  link: () => link2,
  name: () => name6,
  write: () => write3
});

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/decoder-common.js
var import_varint3 = __toESM(require_varint(), 1);
var CIDV0_BYTES = {
  SHA2_256: 18,
  LENGTH: 32,
  DAG_PB: 112
};
var V2_HEADER_LENGTH = (
  /* characteristics */
  16 + 8 + 8 + 8
);
function decodeVarint(bytes2, seeker) {
  if (!bytes2.length) {
    throw new Error("Unexpected end of data");
  }
  const i = import_varint3.default.decode(bytes2);
  seeker.seek(
    /** @type {number} */
    import_varint3.default.decode.bytes
  );
  return i;
}
function decodeV2Header(bytes2) {
  const dv = new DataView(bytes2.buffer, bytes2.byteOffset, bytes2.byteLength);
  let offset2 = 0;
  const header = {
    version: 2,
    /** @type {[bigint, bigint]} */
    characteristics: [
      dv.getBigUint64(offset2, true),
      dv.getBigUint64(offset2 += 8, true)
    ],
    dataOffset: Number(dv.getBigUint64(offset2 += 8, true)),
    dataSize: Number(dv.getBigUint64(offset2 += 8, true)),
    indexOffset: Number(dv.getBigUint64(offset2 += 8, true))
  };
  return header;
}
function getMultihashLength(bytes2) {
  import_varint3.default.decode(bytes2);
  const codeLength = (
    /** @type {number} */
    import_varint3.default.decode.bytes
  );
  const length4 = import_varint3.default.decode(bytes2.subarray(import_varint3.default.decode.bytes));
  const lengthLength = (
    /** @type {number} */
    import_varint3.default.decode.bytes
  );
  const mhLength = codeLength + lengthLength + length4;
  return mhLength;
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/header-validator.js
var Kinds = {
  Null: (
    /** @returns {undefined|null} */
    (obj) => obj === null ? obj : void 0
  ),
  Int: (
    /** @returns {undefined|number} */
    (obj) => Number.isInteger(obj) ? obj : void 0
  ),
  Float: (
    /** @returns {undefined|number} */
    (obj) => typeof obj === "number" && Number.isFinite(obj) ? obj : void 0
  ),
  String: (
    /** @returns {undefined|string} */
    (obj) => typeof obj === "string" ? obj : void 0
  ),
  Bool: (
    /** @returns {undefined|boolean} */
    (obj) => typeof obj === "boolean" ? obj : void 0
  ),
  Bytes: (
    /** @returns {undefined|Uint8Array} */
    (obj) => obj instanceof Uint8Array ? obj : void 0
  ),
  Link: (
    /** @returns {undefined|object} */
    (obj) => obj !== null && typeof obj === "object" && obj.asCID === obj ? obj : void 0
  ),
  List: (
    /** @returns {undefined|Array<any>} */
    (obj) => Array.isArray(obj) ? obj : void 0
  ),
  Map: (
    /** @returns {undefined|object} */
    (obj) => obj !== null && typeof obj === "object" && obj.asCID !== obj && !Array.isArray(obj) && !(obj instanceof Uint8Array) ? obj : void 0
  )
};
var Types = {
  "CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)": Kinds.Link,
  "CarV1HeaderOrV2Pragma > roots (anon)": (
    /** @returns {undefined|any} */
    (obj) => {
      if (Kinds.List(obj) === void 0) {
        return void 0;
      }
      for (let i = 0; i < obj.length; i++) {
        let v = obj[i];
        v = Types["CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)"](v);
        if (v === void 0) {
          return void 0;
        }
        if (v !== obj[i]) {
          const ret = obj.slice(0, i);
          for (let j = i; j < obj.length; j++) {
            let v2 = obj[j];
            v2 = Types["CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)"](v2);
            if (v2 === void 0) {
              return void 0;
            }
            ret.push(v2);
          }
          return ret;
        }
      }
      return obj;
    }
  ),
  Int: Kinds.Int,
  CarV1HeaderOrV2Pragma: (
    /** @returns {undefined|any} */
    (obj) => {
      if (Kinds.Map(obj) === void 0) {
        return void 0;
      }
      const entries3 = Object.entries(obj);
      let ret = obj;
      let requiredCount = 1;
      for (let i = 0; i < entries3.length; i++) {
        const [key, value] = entries3[i];
        switch (key) {
          case "roots":
            {
              const v = Types["CarV1HeaderOrV2Pragma > roots (anon)"](obj[key]);
              if (v === void 0) {
                return void 0;
              }
              if (v !== value || ret !== obj) {
                if (ret === obj) {
                  ret = {};
                  for (let j = 0; j < i; j++) {
                    ret[entries3[j][0]] = entries3[j][1];
                  }
                }
                ret.roots = v;
              }
            }
            break;
          case "version":
            {
              requiredCount--;
              const v = Types.Int(obj[key]);
              if (v === void 0) {
                return void 0;
              }
              if (v !== value || ret !== obj) {
                if (ret === obj) {
                  ret = {};
                  for (let j = 0; j < i; j++) {
                    ret[entries3[j][0]] = entries3[j][1];
                  }
                }
                ret.version = v;
              }
            }
            break;
          default:
            return void 0;
        }
      }
      if (requiredCount > 0) {
        return void 0;
      }
      return ret;
    }
  )
};
var Reprs = {
  "CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)": Kinds.Link,
  "CarV1HeaderOrV2Pragma > roots (anon)": (
    /** @returns {undefined|any} */
    (obj) => {
      if (Kinds.List(obj) === void 0) {
        return void 0;
      }
      for (let i = 0; i < obj.length; i++) {
        let v = obj[i];
        v = Reprs["CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)"](v);
        if (v === void 0) {
          return void 0;
        }
        if (v !== obj[i]) {
          const ret = obj.slice(0, i);
          for (let j = i; j < obj.length; j++) {
            let v2 = obj[j];
            v2 = Reprs["CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)"](v2);
            if (v2 === void 0) {
              return void 0;
            }
            ret.push(v2);
          }
          return ret;
        }
      }
      return obj;
    }
  ),
  Int: Kinds.Int,
  CarV1HeaderOrV2Pragma: (
    /** @returns {undefined|any} */
    (obj) => {
      if (Kinds.Map(obj) === void 0) {
        return void 0;
      }
      const entries3 = Object.entries(obj);
      let ret = obj;
      let requiredCount = 1;
      for (let i = 0; i < entries3.length; i++) {
        const [key, value] = entries3[i];
        switch (key) {
          case "roots":
            {
              const v = Reprs["CarV1HeaderOrV2Pragma > roots (anon)"](value);
              if (v === void 0) {
                return void 0;
              }
              if (v !== value || ret !== obj) {
                if (ret === obj) {
                  ret = {};
                  for (let j = 0; j < i; j++) {
                    ret[entries3[j][0]] = entries3[j][1];
                  }
                }
                ret.roots = v;
              }
            }
            break;
          case "version":
            {
              requiredCount--;
              const v = Reprs.Int(value);
              if (v === void 0) {
                return void 0;
              }
              if (v !== value || ret !== obj) {
                if (ret === obj) {
                  ret = {};
                  for (let j = 0; j < i; j++) {
                    ret[entries3[j][0]] = entries3[j][1];
                  }
                }
                ret.version = v;
              }
            }
            break;
          default:
            return void 0;
        }
      }
      if (requiredCount > 0) {
        return void 0;
      }
      return ret;
    }
  )
};
var CarV1HeaderOrV2Pragma = {
  toTyped: Types.CarV1HeaderOrV2Pragma,
  toRepresentation: Reprs.CarV1HeaderOrV2Pragma
};

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/buffer-decoder.js
function readHeader(reader, strictVersion) {
  const length4 = decodeVarint(reader.upTo(8), reader);
  if (length4 === 0) {
    throw new Error("Invalid CAR header (zero length)");
  }
  const header = reader.exactly(length4, true);
  const block = decode6(header);
  if (CarV1HeaderOrV2Pragma.toTyped(block) === void 0) {
    throw new Error("Invalid CAR header format");
  }
  if (block.version !== 1 && block.version !== 2 || strictVersion !== void 0 && block.version !== strictVersion) {
    throw new Error(`Invalid CAR version: ${block.version}${strictVersion !== void 0 ? ` (expected ${strictVersion})` : ""}`);
  }
  if (block.version === 1) {
    if (!Array.isArray(block.roots)) {
      throw new Error("Invalid CAR header format");
    }
    return block;
  }
  if (block.roots !== void 0) {
    throw new Error("Invalid CAR header format");
  }
  const v2Header = decodeV2Header(reader.exactly(V2_HEADER_LENGTH, true));
  reader.seek(v2Header.dataOffset - reader.pos);
  const v1Header = readHeader(reader, 1);
  return Object.assign(v1Header, v2Header);
}
function readCid(reader) {
  const first = reader.exactly(2, false);
  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {
    const bytes3 = reader.exactly(34, true);
    const multihash2 = decode5(bytes3);
    return CID.create(0, CIDV0_BYTES.DAG_PB, multihash2);
  }
  const version2 = decodeVarint(reader.upTo(8), reader);
  if (version2 !== 1) {
    throw new Error(`Unexpected CID version (${version2})`);
  }
  const codec = decodeVarint(reader.upTo(8), reader);
  const bytes2 = reader.exactly(getMultihashLength(reader.upTo(8)), true);
  const multihash = decode5(bytes2);
  return CID.create(version2, codec, multihash);
}
function readBlockHead(reader) {
  const start = reader.pos;
  let length4 = decodeVarint(reader.upTo(8), reader);
  if (length4 === 0) {
    throw new Error("Invalid CAR section (zero length)");
  }
  length4 += reader.pos - start;
  const cid = readCid(reader);
  const blockLength2 = length4 - Number(reader.pos - start);
  return { cid, length: length4, blockLength: blockLength2 };
}
function fromBytes2(bytes2) {
  let reader = bytesReader(bytes2);
  const header = readHeader(reader);
  if (header.version === 2) {
    const v1length = reader.pos - header.dataOffset;
    reader = limitReader(reader, header.dataSize - v1length);
  }
  const blocks = [];
  while (reader.upTo(8).length > 0) {
    const { cid, blockLength: blockLength2 } = readBlockHead(reader);
    blocks.push({ cid, bytes: reader.exactly(blockLength2, true) });
  }
  return {
    header,
    blocks
  };
}
function bytesReader(bytes2) {
  let pos = 0;
  return {
    upTo(length4) {
      return bytes2.subarray(pos, pos + Math.min(length4, bytes2.length - pos));
    },
    exactly(length4, seek = false) {
      if (length4 > bytes2.length - pos) {
        throw new Error("Unexpected end of data");
      }
      const out = bytes2.subarray(pos, pos + length4);
      if (seek) {
        pos += length4;
      }
      return out;
    },
    seek(length4) {
      pos += length4;
    },
    get pos() {
      return pos;
    }
  };
}
function limitReader(reader, byteLimit) {
  let bytesRead = 0;
  return {
    upTo(length4) {
      let bytes2 = reader.upTo(length4);
      if (bytes2.length + bytesRead > byteLimit) {
        bytes2 = bytes2.subarray(0, byteLimit - bytesRead);
      }
      return bytes2;
    },
    exactly(length4, seek = false) {
      const bytes2 = reader.exactly(length4, seek);
      if (bytes2.length + bytesRead > byteLimit) {
        throw new Error("Unexpected end of data");
      }
      if (seek) {
        bytesRead += length4;
      }
      return bytes2;
    },
    seek(length4) {
      bytesRead += length4;
      reader.seek(length4);
    },
    get pos() {
      return reader.pos;
    }
  };
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/buffer-reader-browser.js
var CarBufferReader = class _CarBufferReader {
  /**
   * @constructs CarBufferReader
   * @param {CarHeader|CarV2Header} header
   * @param {Block[]} blocks
   */
  constructor(header, blocks) {
    this._header = header;
    this._blocks = blocks;
    this._cids = void 0;
  }
  /**
   * @property version
   * @memberof CarBufferReader
   * @instance
   */
  get version() {
    return this._header.version;
  }
  /**
   * Get the list of roots defined by the CAR referenced by this reader. May be
   * zero or more `CID`s.
   *
   * @function
   * @memberof CarBufferReader
   * @instance
   * @returns {CID[]}
   */
  getRoots() {
    return this._header.roots;
  }
  /**
   * Check whether a given `CID` exists within the CAR referenced by this
   * reader.
   *
   * @function
   * @memberof CarBufferReader
   * @instance
   * @param {CID} key
   * @returns {boolean}
   */
  has(key) {
    return this._blocks.some((b) => b.cid.equals(key));
  }
  /**
   * Fetch a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) from the CAR
   * referenced by this reader matching the provided `CID`. In the case where
   * the provided `CID` doesn't exist within the CAR, `undefined` will be
   * returned.
   *
   * @function
   * @memberof CarBufferReader
   * @instance
   * @param {CID} key
   * @returns {Block | undefined}
   */
  get(key) {
    return this._blocks.find((b) => b.cid.equals(key));
  }
  /**
   * Returns a `Block[]` of the `Block`s (`{ cid:CID, bytes:Uint8Array }` pairs) contained within
   * the CAR referenced by this reader.
   *
   * @function
   * @memberof CarBufferReader
   * @instance
   * @returns {Block[]}
   */
  blocks() {
    return this._blocks;
  }
  /**
   * Returns a `CID[]` of the `CID`s contained within the CAR referenced by this reader.
   *
   * @function
   * @memberof CarBufferReader
   * @instance
   * @returns {CID[]}
   */
  cids() {
    if (!this._cids) {
      this._cids = this._blocks.map((b) => b.cid);
    }
    return this._cids;
  }
  /**
   * Instantiate a {@link CarBufferReader} from a `Uint8Array` blob. This performs a
   * decode fully in memory and maintains the decoded state in memory for full
   * access to the data via the `CarReader` API.
   *
   * @static
   * @memberof CarBufferReader
   * @param {Uint8Array} bytes
   * @returns {CarBufferReader}
   */
  static fromBytes(bytes2) {
    if (!(bytes2 instanceof Uint8Array)) {
      throw new TypeError("fromBytes() requires a Uint8Array");
    }
    const { header, blocks } = fromBytes2(bytes2);
    return new _CarBufferReader(header, blocks);
  }
};

// ../../node_modules/.pnpm/cborg@4.2.3/node_modules/cborg/lib/length.js
var cborEncoders2 = makeCborEncoders();
var defaultEncodeOptions3 = {
  float64: false,
  quickEncodeToken
};
function tokensToLength(tokens, encoders = cborEncoders2, options = defaultEncodeOptions3) {
  if (Array.isArray(tokens)) {
    let len = 0;
    for (const token of tokens) {
      len += tokensToLength(token, encoders, options);
    }
    return len;
  } else {
    const encoder3 = encoders[tokens.type.major];
    if (encoder3.encodedSize === void 0 || typeof encoder3.encodedSize !== "function") {
      throw new Error(`Encoder for ${tokens.type.name} does not have an encodedSize()`);
    }
    return encoder3.encodedSize(tokens, options);
  }
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/buffer-writer.js
var import_varint4 = __toESM(require_varint(), 1);
var CarBufferWriter = class {
  /**
   * @param {Uint8Array} bytes
   * @param {number} headerSize
   */
  constructor(bytes2, headerSize) {
    this.bytes = bytes2;
    this.byteOffset = headerSize;
    this.roots = [];
    this.headerSize = headerSize;
  }
  /**
   * Add a root to this writer, to be used to create a header when the CAR is
   * finalized with {@link CarBufferWriter.close `close()`}
   *
   * @param {CID} root
   * @param {{resize?:boolean}} [options]
   * @returns {CarBufferWriter}
   */
  addRoot(root2, options) {
    addRoot(this, root2, options);
    return this;
  }
  /**
   * Write a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) to the archive.
   * Throws if there is not enough capacity.
   *
   * @param {Block} block - A `{ cid:CID, bytes:Uint8Array }` pair.
   * @returns {CarBufferWriter}
   */
  write(block) {
    addBlock(this, block);
    return this;
  }
  /**
   * Finalize the CAR and return it as a `Uint8Array`.
   *
   * @param {object} [options]
   * @param {boolean} [options.resize]
   * @returns {Uint8Array}
   */
  close(options) {
    return close(this, options);
  }
};
var addRoot = (writer, root2, options = {}) => {
  const { resize = false } = options;
  const { bytes: bytes2, headerSize, byteOffset, roots } = writer;
  writer.roots.push(root2);
  const size5 = headerLength(writer);
  if (size5 > headerSize) {
    if (size5 - headerSize + byteOffset < bytes2.byteLength) {
      if (resize) {
        resizeHeader(writer, size5);
      } else {
        roots.pop();
        throw new RangeError(`Header of size ${headerSize} has no capacity for new root ${root2}.
  However there is a space in the buffer and you could call addRoot(root, { resize: root }) to resize header to make a space for this root.`);
      }
    } else {
      roots.pop();
      throw new RangeError(`Buffer has no capacity for a new root ${root2}`);
    }
  }
};
var blockLength = ({ cid, bytes: bytes2 }) => {
  const size5 = cid.bytes.byteLength + bytes2.byteLength;
  return import_varint4.default.encodingLength(size5) + size5;
};
var addBlock = (writer, { cid, bytes: bytes2 }) => {
  const byteLength = cid.bytes.byteLength + bytes2.byteLength;
  const size5 = import_varint4.default.encode(byteLength);
  if (writer.byteOffset + size5.length + byteLength > writer.bytes.byteLength) {
    throw new RangeError("Buffer has no capacity for this block");
  } else {
    writeBytes(writer, size5);
    writeBytes(writer, cid.bytes);
    writeBytes(writer, bytes2);
  }
};
var close = (writer, options = {}) => {
  const { resize = false } = options;
  const { roots, bytes: bytes2, byteOffset, headerSize } = writer;
  const headerBytes = encode4({ version: 1, roots });
  const varintBytes = import_varint4.default.encode(headerBytes.length);
  const size5 = varintBytes.length + headerBytes.byteLength;
  const offset2 = headerSize - size5;
  if (offset2 === 0) {
    writeHeader(writer, varintBytes, headerBytes);
    return bytes2.subarray(0, byteOffset);
  } else if (resize) {
    resizeHeader(writer, size5);
    writeHeader(writer, varintBytes, headerBytes);
    return bytes2.subarray(0, writer.byteOffset);
  } else {
    throw new RangeError(`Header size was overestimated.
You can use close({ resize: true }) to resize header`);
  }
};
var resizeHeader = (writer, byteLength) => {
  const { bytes: bytes2, headerSize } = writer;
  bytes2.set(bytes2.subarray(headerSize, writer.byteOffset), byteLength);
  writer.byteOffset += byteLength - headerSize;
  writer.headerSize = byteLength;
};
var writeBytes = (writer, bytes2) => {
  writer.bytes.set(bytes2, writer.byteOffset);
  writer.byteOffset += bytes2.length;
};
var writeHeader = ({ bytes: bytes2 }, varint8, header) => {
  bytes2.set(varint8);
  bytes2.set(header, varint8.length);
};
var headerPreludeTokens = [
  new Token(Type.map, 2),
  new Token(Type.string, "version"),
  new Token(Type.uint, 1),
  new Token(Type.string, "roots")
];
var CID_TAG = new Token(Type.tag, 42);
var calculateHeaderLength = (rootLengths) => {
  const tokens = [...headerPreludeTokens];
  tokens.push(new Token(Type.array, rootLengths.length));
  for (const rootLength of rootLengths) {
    tokens.push(CID_TAG);
    tokens.push(new Token(Type.bytes, { length: rootLength + 1 }));
  }
  const length4 = tokensToLength(tokens);
  return import_varint4.default.encodingLength(length4) + length4;
};
var headerLength = ({ roots }) => calculateHeaderLength(roots.map((cid) => cid.bytes.byteLength));
var createWriter = (buffer2, options = {}) => {
  const {
    roots = [],
    byteOffset = 0,
    byteLength = buffer2.byteLength,
    headerSize = headerLength({ roots })
  } = options;
  const bytes2 = new Uint8Array(buffer2, byteOffset, byteLength);
  const writer = new CarBufferWriter(bytes2, headerSize);
  for (const root2 of roots) {
    writer.addRoot(root2);
  }
  return writer;
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/car.js
var contentType2 = "application/vnd.ipld.car";
var name6 = "CAR";
var code9 = 514;
var Writer = class {
  /**
   * @param {API.IPLDBlock[]} blocks
   * @param {number} byteLength
   */
  constructor(blocks = [], byteLength = 0) {
    this.written = /* @__PURE__ */ new Set();
    this.blocks = blocks;
    this.byteLength = byteLength;
  }
  /**
   * @param {API.IPLDBlock[]} blocks
   */
  write(...blocks) {
    for (const block of blocks) {
      const id = block.cid.toString(base322);
      if (!this.written.has(id)) {
        this.blocks.push(block);
        this.byteLength += blockLength(
          /** @type {any} */
          block
        );
        this.written.add(id);
      }
    }
    return this;
  }
  /**
   * @param {API.IPLDBlock[]} rootBlocks
   */
  flush(...rootBlocks) {
    const roots = [];
    for (const block of rootBlocks.reverse()) {
      const id = block.cid.toString(base322);
      if (!this.written.has(id)) {
        this.blocks.unshift(block);
        this.byteLength += blockLength({
          cid: (
            /** @type {CarBufferWriter.CID} */
            block.cid
          ),
          bytes: block.bytes
        });
        this.written.add(id);
      }
      roots.unshift(
        /** @type {CarBufferWriter.CID} */
        block.cid
      );
    }
    this.byteLength += headerLength({ roots });
    const buffer2 = new ArrayBuffer(this.byteLength);
    const writer = createWriter(buffer2, { roots });
    for (
      const block of
      /** @type {CarBufferWriter.Block[]} */
      this.blocks
    ) {
      writer.write(block);
    }
    return writer.close();
  }
};
var createWriter2 = () => new Writer();
var encode16 = ({ roots = [], blocks }) => {
  const writer = new Writer();
  if (blocks) {
    writer.write(...blocks.values());
  }
  return writer.flush(...roots);
};
var decode19 = (bytes2) => {
  const reader = CarBufferReader.fromBytes(bytes2);
  const roots = [];
  const blocks = /* @__PURE__ */ new Map();
  for (const root2 of reader.getRoots()) {
    const block = (
      /** @type {API.IPLDBlock} */
      reader.get(root2)
    );
    if (block) {
      roots.push(block);
    }
  }
  for (const block of reader.blocks()) {
    blocks.set(block.cid.toString(), block);
  }
  return { roots, blocks };
};
var link2 = async (bytes2, { hasher = sha2562 } = {}) => {
  return (
    /** @type {API.Link<T, typeof code, typeof hasher.code>} */
    create3(code9, await hasher.digest(bytes2))
  );
};
var write3 = async (data, options) => {
  const bytes2 = encode16(data);
  const cid = await link2(bytes2, options);
  return { bytes: bytes2, cid };
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema.js
var schema_exports3 = {};
__export(schema_exports3, {
  API: () => API,
  Bytes: () => Bytes,
  DID: () => did_exports2,
  Link: () => link_exports2,
  Text: () => text_exports,
  URI: () => uri_exports,
  and: () => and,
  array: () => array,
  boolean: () => boolean,
  bytes: () => bytes,
  dictionary: () => dictionary,
  did: () => match3,
  endsWith: () => endsWith,
  enum: () => createEnum,
  error: () => error2,
  float: () => float,
  greaterThan: () => greaterThan,
  integer: () => integer,
  intersection: () => intersection,
  lessThan: () => lessThan,
  link: () => match2,
  literal: () => literal,
  memberError: () => memberError,
  never: () => never,
  nullable: () => nullable,
  number: () => number,
  ok: () => ok,
  optional: () => optional,
  or: () => or3,
  refine: () => refine,
  startsWith: () => startsWith,
  string: () => string,
  struct: () => struct,
  text: () => match4,
  toString: () => toString3,
  tuple: () => tuple,
  typeError: () => typeError,
  uint64: () => uint64,
  unknown: () => unknown,
  uri: () => match,
  variant: () => variant
});

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/uri.js
var uri_exports = {};
__export(uri_exports, {
  from: () => from9,
  match: () => match,
  read: () => read3,
  uri: () => uri
});

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/result.js
var ok = (value) => {
  if (value == null) {
    throw new TypeError(`ok(${value}) is not allowed, consider ok({}) instead`);
  } else {
    return { ok: value };
  }
};
var error = (cause) => {
  if (cause == null) {
    throw new TypeError(
      `error(${cause}) is not allowed, consider passing an error instead`
    );
  } else {
    return { error: cause };
  }
};
var panic = (message) => {
  throw new Failure(message);
};
var fail2 = (message) => ({ error: new Failure(message) });
var Failure = class extends Error {
  describe() {
    return this.toString();
  }
  get message() {
    return this.describe();
  }
  toJSON() {
    const { name: name14, message, stack } = this;
    return { name: name14, message, stack };
  }
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/schema.js
var API = class {
  /**
   * @param {Settings} settings
   */
  constructor(settings) {
    this.settings = settings;
  }
  toString() {
    return `new ${this.constructor.name}()`;
  }
  /**
   * @abstract
   * @param {I} input
   * @param {Settings} settings
   * @returns {Schema.ReadResult<T>}
   */
  /* c8 ignore next 3 */
  readWith(input10, settings) {
    throw new Error(`Abstract method readWith must be implemented by subclass`);
  }
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<T>}
   */
  read(input10) {
    return this.readWith(input10, this.settings);
  }
  /**
   * @param {unknown} value
   * @returns {value is T}
   */
  is(value) {
    return !this.read(
      /** @type {I} */
      value
    )?.error;
  }
  /**
   * @param {unknown} value
   * @return {T}
   */
  from(value) {
    const result = this.read(
      /** @type {I} */
      value
    );
    if (result.error) {
      throw result.error;
    } else {
      return result.ok;
    }
  }
  /**
   * @returns {Schema.Schema<T|undefined, I>}
   */
  optional() {
    return optional(this);
  }
  /**
   * @returns {Schema.Schema<T|null, I>}
   */
  nullable() {
    return nullable(this);
  }
  /**
   * @returns {Schema.Schema<T[], I>}
   */
  array() {
    return array(this);
  }
  /**
   * @template U
   * @param {Schema.Reader<U, I>} schema
   * @returns {Schema.Schema<T | U, I>}
   */
  or(schema5) {
    return or3(this, schema5);
  }
  /**
   * @template U
   * @param {Schema.Reader<U, I>} schema
   * @returns {Schema.Schema<T & U, I>}
   */
  and(schema5) {
    return and(this, schema5);
  }
  /**
   * @template {T} U
   * @param {Schema.Reader<U, T>} schema
   * @returns {Schema.Schema<U, I>}
   */
  refine(schema5) {
    return refine(this, schema5);
  }
  /**
   * @template {string} Kind
   * @param {Kind} [kind]
   * @returns {Schema.Schema<Schema.Branded<T, Kind>, I>}
   */
  brand(kind) {
    return (
      /** @type {Schema.Schema<Schema.Branded<T, Kind>, I>} */
      this
    );
  }
  /**
   * @param {Schema.NotUndefined<T>} value
   * @returns {Schema.DefaultSchema<Schema.NotUndefined<T>, I>}
   */
  default(value) {
    const fallback = this.from(value);
    if (fallback === void 0) {
      throw new Error(`Value of type undefined is not a valid default`);
    }
    const schema5 = new Default({
      reader: (
        /** @type {Schema.Reader<T, I>} */
        this
      ),
      value: (
        /** @type {Schema.NotUndefined<T>} */
        fallback
      )
    });
    return (
      /** @type {Schema.DefaultSchema<Schema.NotUndefined<T>, I>} */
      schema5
    );
  }
};
var Never = class extends API {
  toString() {
    return "never()";
  }
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<never>}
   */
  read(input10) {
    return typeError({ expect: "never", actual: input10 });
  }
};
var never = () => new Never();
var Unknown = class extends API {
  /**
   * @param {I} input
   */
  read(input10) {
    return (
      /** @type {Schema.ReadResult<unknown>}*/
      { ok: input10 }
    );
  }
  toString() {
    return "unknown()";
  }
};
var unknown = () => new Unknown();
var Nullable = class extends API {
  /**
   * @param {I} input
   * @param {Schema.Reader<O, I>} reader
   */
  readWith(input10, reader) {
    const result = reader.read(input10);
    if (result.error) {
      return input10 === null ? { ok: null } : {
        error: new UnionError({
          causes: [
            result.error,
            typeError({ expect: "null", actual: input10 }).error
          ]
        })
      };
    } else {
      return result;
    }
  }
  toString() {
    return `${this.settings}.nullable()`;
  }
};
var nullable = (schema5) => new Nullable(schema5);
var Optional = class extends API {
  optional() {
    return this;
  }
  /**
   * @param {I} input
   * @param {Schema.Reader<O, I>} reader
   * @returns {Schema.ReadResult<O|undefined>}
   */
  readWith(input10, reader) {
    const result = reader.read(input10);
    return result.error && input10 === void 0 ? { ok: void 0 } : result;
  }
  toString() {
    return `${this.settings}.optional()`;
  }
};
var Default = class extends API {
  /**
   * @returns {Schema.DefaultSchema<O & Schema.NotUndefined<O>, I>}
   */
  optional() {
    return (
      /** @type {Schema.DefaultSchema<O & Schema.NotUndefined<O>, I>} */
      this
    );
  }
  /**
   * @param {I} input
   * @param {object} options
   * @param {Schema.Reader<O|undefined, I>} options.reader
   * @param {O} options.value
   * @returns {Schema.ReadResult<O>}
   */
  readWith(input10, { reader, value }) {
    if (input10 === void 0) {
      return (
        /** @type {Schema.ReadResult<O>} */
        { ok: value }
      );
    } else {
      const result = reader.read(input10);
      return result.error ? result : result.ok !== void 0 ? (
        // We just checked that result.ok is not undefined but still needs
        // reassurance
        /** @type {Schema.ReadResult<O>} */
        result
      ) : { ok: value };
    }
  }
  toString() {
    return `${this.settings.reader}.default(${JSON.stringify(
      this.settings.value
    )})`;
  }
  get value() {
    return this.settings.value;
  }
};
var optional = (schema5) => new Optional(schema5);
var ArrayOf = class extends API {
  /**
   * @param {I} input
   * @param {Schema.Reader<O, I>} schema
   */
  readWith(input10, schema5) {
    if (!Array.isArray(input10)) {
      return typeError({ expect: "array", actual: input10 });
    }
    const results = [];
    for (const [index2, value] of input10.entries()) {
      const result = schema5.read(value);
      if (result.error) {
        return memberError({ at: index2, cause: result.error });
      } else {
        results.push(result.ok);
      }
    }
    return { ok: results };
  }
  get element() {
    return this.settings;
  }
  toString() {
    return `array(${this.element})`;
  }
};
var array = (schema5) => new ArrayOf(schema5);
var Tuple = class extends API {
  /**
   * @param {I} input
   * @param {U} shape
   * @returns {Schema.ReadResult<Schema.InferTuple<U>>}
   */
  readWith(input10, shape) {
    if (!Array.isArray(input10)) {
      return typeError({ expect: "array", actual: input10 });
    }
    if (input10.length !== this.shape.length) {
      return error2(`Array must contain exactly ${this.shape.length} elements`);
    }
    const results = [];
    for (const [index2, reader] of shape.entries()) {
      const result = reader.read(input10[index2]);
      if (result.error) {
        return memberError({ at: index2, cause: result.error });
      } else {
        results[index2] = result.ok;
      }
    }
    return { ok: (
      /** @type {Schema.InferTuple<U>} */
      results
    ) };
  }
  /** @type {U} */
  get shape() {
    return this.settings;
  }
  toString() {
    return `tuple([${this.shape.map((reader) => reader.toString()).join(", ")}])`;
  }
};
var tuple = (shape) => new Tuple(shape);
var Dictionary = class _Dictionary extends API {
  /**
   * @param {I} input
   * @param {object} schema
   * @param {Schema.Reader<K, string>} schema.key
   * @param {Schema.Reader<V, I>} schema.value
   */
  readWith(input10, { key, value }) {
    if (typeof input10 != "object" || input10 === null || Array.isArray(input10)) {
      return typeError({
        expect: "dictionary",
        actual: input10
      });
    }
    const dict = (
      /** @type {Schema.Dictionary<K, V>} */
      {}
    );
    for (const [k, v] of Object.entries(input10)) {
      const keyResult = key.read(k);
      if (keyResult.error) {
        return memberError({ at: k, cause: keyResult.error });
      }
      const valueResult = value.read(v);
      if (valueResult.error) {
        return memberError({ at: k, cause: valueResult.error });
      }
      if (valueResult.ok !== void 0) {
        dict[keyResult.ok] = valueResult.ok;
      }
    }
    return { ok: dict };
  }
  get key() {
    return this.settings.key;
  }
  get value() {
    return this.settings.value;
  }
  partial() {
    const { key, value } = this.settings;
    return new _Dictionary({
      key,
      value: optional(value)
    });
  }
  toString() {
    return `dictionary(${this.settings})`;
  }
};
var dictionary = ({ value, key }) => new Dictionary({
  value,
  key: key || /** @type {Schema.Reader<K, string>} */
  string()
});
var Enum = class extends API {
  /**
   * @param {I} input
   * @param {{type:string, variants:Set<T[number]>}} settings
   * @returns {Schema.ReadResult<T[number]>}
   */
  readWith(input10, { variants, type: type2 }) {
    if (variants.has(input10)) {
      return (
        /** @type {Schema.ReadResult<T[number]>} */
        { ok: input10 }
      );
    } else {
      return typeError({ expect: type2, actual: input10 });
    }
  }
  toString() {
    return this.settings.type;
  }
};
var createEnum = (variants) => new Enum({
  type: variants.join("|"),
  variants: new Set(variants)
});
var Union = class extends API {
  /**
   * @param {I} input
   * @param {U} variants
   */
  readWith(input10, variants) {
    const causes = [];
    for (const reader of variants) {
      const result = reader.read(input10);
      if (result.error) {
        causes.push(result.error);
      } else {
        return (
          /** @type {Schema.ReadResult<Schema.InferUnion<U>>} */
          result
        );
      }
    }
    return { error: new UnionError({ causes }) };
  }
  get variants() {
    return this.settings;
  }
  toString() {
    return `union([${this.variants.map((type2) => type2.toString()).join(", ")}])`;
  }
};
var union = (variants) => new Union(variants);
var or3 = (left, right) => union([left, right]);
var Intersection = class extends API {
  /**
   * @param {I} input
   * @param {U} schemas
   * @returns {Schema.ReadResult<Schema.InferIntersection<U>>}
   */
  readWith(input10, schemas) {
    const causes = [];
    for (const schema5 of schemas) {
      const result = schema5.read(input10);
      if (result.error) {
        causes.push(result.error);
      }
    }
    return causes.length > 0 ? { error: new IntersectionError({ causes }) } : (
      /** @type {Schema.ReadResult<Schema.InferIntersection<U>>} */
      {
        ok: input10
      }
    );
  }
  toString() {
    return `intersection([${this.settings.map((type2) => type2.toString()).join(",")}])`;
  }
};
var intersection = (variants) => new Intersection(variants);
var and = (left, right) => intersection([left, right]);
var Boolean2 = class extends API {
  /**
   * @param {I} input
   */
  readWith(input10) {
    switch (input10) {
      case true:
      case false:
        return { ok: (
          /** @type {boolean} */
          input10
        ) };
      default:
        return typeError({
          expect: "boolean",
          actual: input10
        });
    }
  }
  toString() {
    return `boolean()`;
  }
};
var anyBoolean = new Boolean2();
var boolean = () => anyBoolean;
var UnknownNumber = class extends API {
  /**
   * @param {number} n
   */
  greaterThan(n) {
    return this.refine(greaterThan(n));
  }
  /**
   * @param {number} n
   */
  lessThan(n) {
    return this.refine(lessThan(n));
  }
  /**
   * @template {O} U
   * @param {Schema.Reader<U, O>} schema
   * @returns {Schema.NumberSchema<U, I>}
   */
  refine(schema5) {
    return new RefinedNumber({ base: this, schema: schema5 });
  }
};
var AnyNumber = class extends UnknownNumber {
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<number>}
   */
  readWith(input10) {
    return typeof input10 === "number" ? { ok: input10 } : typeError({ expect: "number", actual: input10 });
  }
  toString() {
    return `number()`;
  }
};
var anyNumber = new AnyNumber();
var number = () => anyNumber;
var RefinedNumber = class extends UnknownNumber {
  /**
   * @param {I} input
   * @param {{base:Schema.Reader<T, I>, schema:Schema.Reader<O, T>}} settings
   * @returns {Schema.ReadResult<O>}
   */
  readWith(input10, { base: base4, schema: schema5 }) {
    const result = base4.read(input10);
    return result.error ? result : schema5.read(result.ok);
  }
  toString() {
    return `${this.settings.base}.refine(${this.settings.schema})`;
  }
};
var LessThan = class extends API {
  /**
   * @param {T} input
   * @param {number} number
   * @returns {Schema.ReadResult<T>}
   */
  readWith(input10, number2) {
    if (input10 < number2) {
      return { ok: input10 };
    } else {
      return error2(`Expected ${input10} < ${number2}`);
    }
  }
  toString() {
    return `lessThan(${this.settings})`;
  }
};
var lessThan = (n) => new LessThan(n);
var GreaterThan = class extends API {
  /**
   * @param {T} input
   * @param {number} number
   * @returns {Schema.ReadResult<T>}
   */
  readWith(input10, number2) {
    if (input10 > number2) {
      return { ok: input10 };
    } else {
      return error2(`Expected ${input10} > ${number2}`);
    }
  }
  toString() {
    return `greaterThan(${this.settings})`;
  }
};
var greaterThan = (n) => new GreaterThan(n);
var Integer = {
  /**
   * @param {number} input
   * @returns {Schema.ReadResult<Schema.Integer>}
   */
  read(input10) {
    return Number.isInteger(input10) ? { ok: (
      /** @type {Schema.Integer} */
      input10
    ) } : typeError({
      expect: "integer",
      actual: input10
    });
  },
  toString() {
    return `Integer`;
  }
};
var anyInteger = anyNumber.refine(Integer);
var integer = () => anyInteger;
var MAX_UINT64 = 2n ** 64n - 1n;
var Uint64Schema = class extends API {
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<O>}
   */
  read(input10) {
    switch (typeof input10) {
      case "bigint":
        return input10 > MAX_UINT64 ? error2(`Integer is too big for uint64, ${input10} > ${MAX_UINT64}`) : input10 < 0 ? error2(
          `Negative integer can not be represented as uint64, ${input10} < ${0}`
        ) : { ok: (
          /** @type {I & O} */
          input10
        ) };
      case "number":
        return !Number.isInteger(input10) ? typeError({
          expect: "uint64",
          actual: input10
        }) : input10 < 0 ? error2(
          `Negative integer can not be represented as uint64, ${input10} < ${0}`
        ) : { ok: (
          /** @type {O} */
          BigInt(input10)
        ) };
      default:
        return typeError({
          expect: "uint64",
          actual: input10
        });
    }
  }
  toString() {
    return `uint64`;
  }
};
var Uint64 = new Uint64Schema();
var uint64 = () => Uint64;
var Float = {
  /**
   * @param {number} number
   * @returns {Schema.ReadResult<Schema.Float>}
   */
  read(number2) {
    return Number.isFinite(number2) ? { ok: (
      /** @type {Schema.Float} */
      number2
    ) } : typeError({
      expect: "Float",
      actual: number2
    });
  },
  toString() {
    return "Float";
  }
};
var anyFloat = anyNumber.refine(Float);
var float = () => anyFloat;
var UnknownString = class extends API {
  /**
   * @template {O|unknown} U
   * @param {Schema.Reader<U, O>} schema
   * @returns {Schema.StringSchema<O & U, I>}
   */
  refine(schema5) {
    const other = (
      /** @type {Schema.Reader<U, O>} */
      schema5
    );
    const rest = new RefinedString({
      base: this,
      schema: other
    });
    return (
      /** @type {Schema.StringSchema<O & U, I>} */
      rest
    );
  }
  /**
   * @template {string} Prefix
   * @param {Prefix} prefix
   */
  startsWith(prefix2) {
    return this.refine(startsWith(prefix2));
  }
  /**
   * @template {string} Suffix
   * @param {Suffix} suffix
   */
  endsWith(suffix) {
    return this.refine(endsWith(suffix));
  }
  toString() {
    return `string()`;
  }
};
var RefinedString = class extends UnknownString {
  /**
   * @param {I} input
   * @param {{base:Schema.Reader<T, I>, schema:Schema.Reader<O, T>}} settings
   * @returns {Schema.ReadResult<T & O>}
   */
  readWith(input10, { base: base4, schema: schema5 }) {
    const result = base4.read(input10);
    return result.error ? result : (
      /** @type {Schema.ReadResult<T & O>} */
      schema5.read(result.ok)
    );
  }
  toString() {
    return `${this.settings.base}.refine(${this.settings.schema})`;
  }
};
var AnyString = class extends UnknownString {
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<string>}
   */
  readWith(input10) {
    return typeof input10 === "string" ? { ok: input10 } : typeError({ expect: "string", actual: input10 });
  }
};
var anyString = new AnyString();
var string = () => anyString;
var BytesSchema = class extends API {
  /**
   * @param {I} input
   * @returns {Schema.ReadResult<Uint8Array>}
   */
  readWith(input10) {
    if (input10 instanceof Uint8Array) {
      return { ok: input10 };
    } else {
      return typeError({ expect: "Uint8Array", actual: input10 });
    }
  }
};
var Bytes = new BytesSchema();
var bytes = () => Bytes;
var StartsWith = class extends API {
  /**
   * @param {Body} input
   * @param {Prefix} prefix
   */
  readWith(input10, prefix2) {
    const result = input10.startsWith(prefix2) ? (
      /** @type {Schema.ReadResult<Body & `${Prefix}${Body}`>} */
      {
        ok: input10
      }
    ) : error2(`Expect string to start with "${prefix2}" instead got "${input10}"`);
    return result;
  }
  get prefix() {
    return this.settings;
  }
  toString() {
    return `startsWith("${this.prefix}")`;
  }
};
var startsWith = (prefix2) => new StartsWith(prefix2);
var EndsWith = class extends API {
  /**
   * @param {Body} input
   * @param {Suffix} suffix
   */
  readWith(input10, suffix) {
    return input10.endsWith(suffix) ? (
      /** @type {Schema.ReadResult<Body & `${Body}${Suffix}`>} */
      {
        ok: input10
      }
    ) : error2(`Expect string to end with "${suffix}" instead got "${input10}"`);
  }
  get suffix() {
    return this.settings;
  }
  toString() {
    return `endsWith("${this.suffix}")`;
  }
};
var endsWith = (suffix) => new EndsWith(suffix);
var Refine = class extends API {
  /**
   * @param {I} input
   * @param {{ base: Schema.Reader<T, I>, schema: Schema.Reader<U, T> }} settings
   */
  readWith(input10, { base: base4, schema: schema5 }) {
    const result = base4.read(input10);
    return result.error ? result : schema5.read(result.ok);
  }
  toString() {
    return `${this.settings.base}.refine(${this.settings.schema})`;
  }
};
var refine = (base4, schema5) => new Refine({ base: base4, schema: schema5 });
var Literal = class extends API {
  /**
   * @param {I} input
   * @param {T} expect
   * @returns {Schema.ReadResult<T>}
   */
  readWith(input10, expect) {
    return input10 !== /** @type {unknown} */
    expect ? { error: new LiteralError({ expect, actual: input10 }) } : { ok: expect };
  }
  get value() {
    return (
      /** @type {Exclude<T, undefined>} */
      this.settings
    );
  }
  /**
   * @template {Schema.NotUndefined<T>} U
   * @param {U} value
   */
  default(value = (
    /** @type {U} */
    this.value
  )) {
    return super.default(value);
  }
  toString() {
    return `literal(${toString3(this.value)})`;
  }
};
var literal = (value) => new Literal(value);
var Struct = class _Struct extends API {
  /**
   * @param {I} input
   * @param {U} shape
   * @returns {Schema.ReadResult<Schema.InferStruct<U>>}
   */
  readWith(input10, shape) {
    if (typeof input10 != "object" || input10 === null || Array.isArray(input10)) {
      return typeError({
        expect: "object",
        actual: input10
      });
    }
    const source = (
      /** @type {{[K in keyof U]: unknown}} */
      input10
    );
    const struct2 = (
      /** @type {{[K in keyof U]: Schema.Infer<U[K]>}} */
      {}
    );
    const entries3 = (
      /** @type {{[K in keyof U]: [K & string, U[K]]}[keyof U][]} */
      Object.entries(shape)
    );
    for (const [at2, reader] of entries3) {
      const result = reader.read(source[at2]);
      if (result.error) {
        return memberError({ at: at2, cause: result.error });
      } else if (result.ok !== void 0) {
        struct2[at2] = /** @type {Schema.Infer<U[typeof at]>} */
        result.ok;
      }
    }
    return { ok: struct2 };
  }
  /**
   * @returns {Schema.MapRepresentation<Partial<Schema.InferStruct<U>>> & Schema.StructSchema}
   */
  partial() {
    return new _Struct(
      Object.fromEntries(
        Object.entries(this.shape).map(([key, value]) => [key, optional(value)])
      )
    );
  }
  /** @type {U} */
  get shape() {
    return this.settings;
  }
  toString() {
    return [
      `struct({ `,
      ...Object.entries(this.shape).map(([key, schema5]) => `${key}: ${schema5}`).join(", "),
      ` })`
    ].join("");
  }
  /**
   * @param {Schema.InferStructSource<U>} data
   */
  create(data) {
    return this.from(data || {});
  }
  /**
   * @template {{[key:string]: Schema.Reader}} E
   * @param {E} extension
   * @returns {Schema.StructSchema<U & E, I>}
   */
  extend(extension) {
    return new _Struct({ ...this.shape, ...extension });
  }
};
var struct = (fields) => {
  const shape = (
    /** @type {{[K in keyof U]: Schema.Reader<unknown, unknown>}} */
    {}
  );
  const entries3 = Object.entries(fields);
  for (const [key, field] of entries3) {
    switch (typeof field) {
      case "number":
      case "string":
      case "boolean":
        shape[key] = literal(field);
        break;
      case "object":
        shape[key] = field === null ? literal(null) : field;
        break;
      default:
        throw new Error(
          `Invalid struct field "${key}", expected schema or literal, instead got ${typeof field}`
        );
    }
  }
  return new Struct(
    /** @type {V} */
    shape
  );
};
var Variant = class extends API {
  /**
   * @param {I} input
   * @param {U} variants
   * @returns {Schema.ReadResult<Schema.InferVariant<U>>}
   */
  readWith(input10, variants) {
    if (typeof input10 != "object" || input10 === null || Array.isArray(input10)) {
      return typeError({
        expect: "object",
        actual: input10
      });
    }
    const keys2 = (
      /** @type {Array<keyof input & keyof variants & string>} */
      Object.keys(input10)
    );
    const [key] = keys2.length === 1 ? keys2 : [];
    const reader = key ? variants[key] : void 0;
    if (reader) {
      const result = reader.read(input10[key]);
      return result.error ? memberError({ at: key, cause: result.error }) : { ok: (
        /** @type {Schema.InferVariant<U>} */
        { [key]: result.ok }
      ) };
    } else if (variants._) {
      const result = variants._.read(input10);
      return result.error ? result : { ok: (
        /** @type {Schema.InferVariant<U>} */
        { _: result.ok }
      ) };
    } else if (key) {
      return error2(
        `Expected an object with one of the these keys: ${Object.keys(variants).sort().join(", ")} instead got object with key ${key}`
      );
    } else {
      return error2(
        "Expected an object with a single key instead got object with keys " + keys2.sort().join(", ")
      );
    }
  }
  /**
   * @template [E=never]
   * @param {I} input
   * @param {E} [fallback]
   */
  match(input10, fallback) {
    const result = this.read(input10);
    if (result.error) {
      if (fallback !== void 0) {
        return [null, fallback];
      } else {
        throw result.error;
      }
    } else {
      const [key] = Object.keys(result.ok);
      const value = result.ok[key];
      return (
        /** @type {any} */
        [key, value]
      );
    }
  }
  /**
   * @template {Schema.InferVariant<U>} O
   * @param {O} source
   * @returns {O}
   */
  create(source) {
    return (
      /** @type {O} */
      this.from(source)
    );
  }
};
var variant = (variants) => new Variant(variants);
var error2 = (message) => ({ error: new SchemaError(message) });
var SchemaError = class extends Failure {
  get name() {
    return "SchemaError";
  }
  /* c8 ignore next 3 */
  describe() {
    return this.name;
  }
};
var TypeError2 = class extends SchemaError {
  /**
   * @param {{expect:string, actual:unknown}} data
   */
  constructor({ expect, actual }) {
    super();
    this.expect = expect;
    this.actual = actual;
  }
  get name() {
    return "TypeError";
  }
  describe() {
    return `Expected value of type ${this.expect} instead got ${toString3(
      this.actual
    )}`;
  }
};
var typeError = (data) => ({ error: new TypeError2(data) });
var toString3 = (value) => {
  const type2 = typeof value;
  switch (type2) {
    case "boolean":
    case "string":
      return JSON.stringify(value);
    case "bigint":
      return `${value}n`;
    case "number":
    case "symbol":
    case "undefined":
      return String(value);
    case "object":
      return value === null ? "null" : Array.isArray(value) ? "array" : Symbol.toStringTag in /** @type {object} */
      value ? value[Symbol.toStringTag] : "object";
    default:
      return type2;
  }
};
var LiteralError = class extends SchemaError {
  /**
   * @param {{
   * expect:string|number|boolean|null
   * actual:unknown
   * }} data
   */
  constructor({ expect, actual }) {
    super();
    this.expect = expect;
    this.actual = actual;
  }
  get name() {
    return "LiteralError";
  }
  describe() {
    return `Expected literal ${toString3(this.expect)} instead got ${toString3(
      this.actual
    )}`;
  }
};
var ElementError = class extends SchemaError {
  /**
   * @param {{at:number, cause:Schema.Error}} data
   */
  constructor({ at: at2, cause }) {
    super();
    this.at = at2;
    this.cause = cause;
  }
  get name() {
    return "ElementError";
  }
  describe() {
    return [
      `Array contains invalid element at ${this.at}:`,
      li(this.cause.message)
    ].join("\n");
  }
};
var FieldError = class extends SchemaError {
  /**
   * @param {{at:string, cause:Schema.Error}} data
   */
  constructor({ at: at2, cause }) {
    super();
    this.at = at2;
    this.cause = cause;
  }
  get name() {
    return "FieldError";
  }
  describe() {
    return [
      `Object contains invalid field "${this.at}":`,
      li(this.cause.message)
    ].join("\n");
  }
};
var memberError = ({ at: at2, cause }) => typeof at2 === "string" ? { error: new FieldError({ at: at2, cause }) } : { error: new ElementError({ at: at2, cause }) };
var UnionError = class extends SchemaError {
  /**
   * @param {{causes: Schema.Error[]}} data
   */
  constructor({ causes }) {
    super();
    this.causes = causes;
  }
  get name() {
    return "UnionError";
  }
  describe() {
    const { causes } = this;
    return [
      `Value does not match any type of the union:`,
      ...causes.map((cause) => li(cause.message))
    ].join("\n");
  }
};
var IntersectionError = class extends SchemaError {
  /**
   * @param {{causes: Schema.Error[]}} data
   */
  constructor({ causes }) {
    super();
    this.causes = causes;
  }
  get name() {
    return "IntersectionError";
  }
  describe() {
    const { causes } = this;
    return [
      `Value does not match following types of the intersection:`,
      ...causes.map((cause) => li(cause.message))
    ].join("\n");
  }
};
var indent = (message, indent3 = "  ") => `${indent3}${message.split("\n").join(`
${indent3}`)}`;
var li = (message) => indent(`- ${message}`);

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/uri.js
var URISchema = class extends API {
  /**
   * @param {unknown} input
   * @param {Partial<O>} options
   * @returns {Schema.ReadResult<API.URI<O['protocol']>>}
   */
  readWith(input10, { protocol } = {}) {
    if (typeof input10 !== "string" && !(input10 instanceof URL)) {
      return error2(
        `Expected URI but got ${input10 === null ? "null" : typeof input10}`
      );
    }
    try {
      const url = new URL(String(input10));
      if (protocol != null && url.protocol !== protocol) {
        return error2(`Expected ${protocol} URI instead got ${url.href}`);
      } else {
        return { ok: (
          /** @type {API.URI<O['protocol']>} */
          url.href
        ) };
      }
    } catch (_) {
      return error2(`Invalid URI`);
    }
  }
};
var schema = new URISchema({});
var uri = () => schema;
var read3 = (input10) => schema.read(input10);
var match = (options) => new URISchema(options);
var from9 = (input10) => (
  /** @type {API.URI<`${Scheme}:`>} */
  schema.from(input10)
);

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/link.js
var link_exports2 = {};
__export(link_exports2, {
  create: () => create3,
  createLegacy: () => createLegacy,
  isLink: () => isLink,
  link: () => link3,
  match: () => match2,
  optional: () => optional2,
  parse: () => parse,
  read: () => read4,
  schema: () => schema2
});
var LinkSchema = class extends API {
  /**
   *
   * @param {unknown} cid
   * @param {Settings<Code, Alg, Version>} settings
   * @returns {Schema.ReadResult<API.Link<unknown, Code, Alg, Version>>}
   */
  readWith(cid, { code: code19, multihash = {}, version: version2 }) {
    if (cid == null) {
      return error2(`Expected link but got ${cid} instead`);
    } else {
      if (!isLink(cid)) {
        return error2(`Expected link to be a CID instead of ${cid}`);
      } else {
        if (code19 != null && cid.code !== code19) {
          return error2(
            `Expected link to be CID with 0x${code19.toString(16)} codec`
          );
        }
        if (multihash.code != null && cid.multihash.code !== multihash.code)
          return error2(
            `Expected link to be CID with 0x${multihash.code.toString(
              16
            )} hashing algorithm`
          );
        if (version2 != null && cid.version !== version2) {
          return error2(
            `Expected link to be CID version ${version2} instead of ${cid.version}`
          );
        }
        const [expectDigest, actualDigest] = multihash.digest != null ? [
          base322.baseEncode(multihash.digest),
          base322.baseEncode(cid.multihash.digest)
        ] : ["", ""];
        if (expectDigest !== actualDigest) {
          return error2(
            `Expected link with "${expectDigest}" hash digest instead of "${actualDigest}"`
          );
        }
        return {
          ok: (
            /** @type {API.Link<unknown, any, any, any>} */
            cid
          )
        };
      }
    }
  }
};
var schema2 = new LinkSchema({});
var link3 = () => schema2;
var match2 = (options = {}) => new LinkSchema(options);
var read4 = (input10) => schema2.read(input10);
var optional2 = () => schema2.optional();

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/did.js
var did_exports2 = {};
__export(did_exports2, {
  did: () => did,
  from: () => from10,
  match: () => match3,
  read: () => read5
});
var DIDSchema = class extends API {
  /**
   * @param {string} source
   * @param {void|Method} method
   */
  readWith(source, method) {
    const prefix2 = method ? `did:${method}:` : `did:`;
    if (!source.startsWith(prefix2)) {
      return error2(`Expected a ${prefix2} but got "${source}" instead`);
    } else {
      return { ok: (
        /** @type {API.DID<Method>} */
        source
      ) };
    }
  }
};
var schema3 = string().refine(new DIDSchema());
var did = () => schema3;
var read5 = (input10) => schema3.read(input10);
var match3 = (options = {}) => (
  /** @type {Schema.Schema<API.DID<Method> & API.URI<"did:">>} */
  string().refine(new DIDSchema(options.method))
);
var from10 = (input10) => match3({}).from(input10);

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/schema/text.js
var text_exports = {};
__export(text_exports, {
  match: () => match4,
  read: () => read6,
  text: () => text
});
var schema4 = string();
var match4 = (options) => options ? schema4.refine(new Match(options.pattern)) : schema4;
var text = match4;
var read6 = (input10) => schema4.read(input10);
var Match = class extends API {
  /**
   * @param {string} source
   * @param {RegExp} pattern
   */
  readWith(source, pattern) {
    if (!pattern.test(source)) {
      return error2(
        `Expected to match ${pattern} but got "${source}" instead`
      );
    } else {
      return { ok: source };
    }
  }
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/delegation.js
var isLink2 = isLink;
var isDelegation = (proof) => !isLink(proof);
var allows = (...delegations) => {
  let allow = {};
  for (const delegation of delegations) {
    for (const { with: uri2, can, nb } of iterateCapabilities(delegation)) {
      const resource = allow[uri2] || (allow[uri2] = {});
      const abilities = resource[can] || (resource[can] = []);
      abilities.push({ ...nb });
    }
  }
  return (
    /** @type {API.InferAllowedFromDelegations<T>} */
    allow
  );
};
var iterateCapabilities = function* ({ issuer, capabilities, proofs: proofs2 }) {
  for (const own of capabilities) {
    if (own.with === "ucan:*") {
      yield {
        ...own,
        with: issuer.did()
      };
      for (const proof of proofs2) {
        if (isDelegation(proof)) {
          for (const capability2 of iterateCapabilities(proof)) {
            const can = matchAbility(capability2.can, own.can);
            if (can) {
              yield {
                ...capability2,
                can,
                // We do not know capability semantics so it is impossible
                // for us to eliminate capabilities that do not satisfy imposed
                // caveats (`own.nb`). Therefore we optimistically assume that
                // `own.nb` further constraints `capability.nb` and do a shallow
                // merge of the two. As a result we may include capabilities
                // that during validation will be considered invalid due to
                // constraint violations. While that is not ideal validator
                // will treat them as if they were omitted and therefore it
                // is a reasonable compromise.
                nb: { ...capability2.nb, ...Object(own.nb) }
              };
            }
          }
        }
      }
    } else {
      yield own;
    }
  }
};
var matchAbility = (provided, claimed) => {
  if (provided === "*") {
    return claimed;
  }
  if (claimed === "*") {
    return provided;
  }
  if (claimed.endsWith("/*") && provided.startsWith(claimed.slice(0, -1))) {
    return provided;
  }
  if (provided.endsWith("/*") && claimed.startsWith(provided.slice(0, -1))) {
    return claimed;
  }
  if (provided === claimed) {
    return provided;
  }
  return null;
};
var Delegation = class {
  /**
   * @param {API.UCANBlock<C>} root
   * @param {DAG.BlockStore} [blocks]
   */
  constructor(root2, blocks = /* @__PURE__ */ new Map()) {
    this.root = root2;
    this.blocks = blocks;
    Object.defineProperties(this, {
      blocks: {
        enumerable: false
      }
    });
  }
  /**
   * @returns {API.AttachedLinkSet}
   */
  get attachedLinks() {
    const _attachedLinks = /* @__PURE__ */ new Set();
    const ucanView = this.data;
    for (const capability2 of ucanView.capabilities) {
      const links3 = getLinksFromObject(capability2);
      for (const link5 of links3) {
        _attachedLinks.add(`${link5}`);
      }
    }
    for (const fact of ucanView.facts) {
      if (isLink(fact)) {
        _attachedLinks.add(`${fact}`);
      } else {
        const links3 = Object.values(fact).filter((e) => isLink(e));
        for (const link5 of links3) {
          _attachedLinks.add(`${link5}`);
        }
      }
    }
    return _attachedLinks;
  }
  get version() {
    return this.data.version;
  }
  get signature() {
    return this.data.signature;
  }
  get cid() {
    return this.root.cid;
  }
  link() {
    return this.root.cid;
  }
  get asCID() {
    return this.cid;
  }
  get bytes() {
    return this.root.bytes;
  }
  get data() {
    const data = decode20(this.root);
    Object.defineProperties(this, { data: { value: data, enumerable: false } });
    return data;
  }
  /**
   * Attach a block to the delegation DAG so it would be included in the
   * block iterator.
   *  You can only attach blocks that are referenced from the `capabilities`
   * or `facts`.
   *
   * @param {API.Block} block
   */
  attach(block) {
    if (!this.attachedLinks.has(`${block.cid.link()}`)) {
      throw new Error(`given block with ${block.cid} is not an attached link`);
    }
    this.blocks.set(`${block.cid}`, block);
  }
  export() {
    return exportDAG(this.root, this.blocks, this.attachedLinks);
  }
  /**
   * @returns {API.Await<API.Result<Uint8Array, Error>>}
   */
  archive() {
    return archive(this);
  }
  iterateIPLDBlocks() {
    return exportDAG(this.root, this.blocks, this.attachedLinks);
  }
  /**
   * @type {API.Proof[]}
   */
  get proofs() {
    return proofs(this);
  }
  /**
   * @type {API.Principal}
   */
  get issuer() {
    return this.data.issuer;
  }
  /**
   * @type {API.Principal}
   */
  get audience() {
    return this.data.audience;
  }
  /**
   * @returns {C}
   */
  get capabilities() {
    return (
      /** @type {C} */
      this.data.capabilities
    );
  }
  /**
   * @returns {number}
   */
  get expiration() {
    return this.data.expiration;
  }
  /**
   * @returns {undefined|number}
   */
  get notBefore() {
    return this.data.notBefore;
  }
  /**
   * @returns {undefined|string}
   */
  get nonce() {
    return this.data.nonce;
  }
  /**
   * @returns {API.Fact[]}
   */
  get facts() {
    return this.data.facts;
  }
  /**
   * Iterate over the proofs
   *
   * @returns {IterableIterator<API.Delegation>}
   */
  iterate() {
    return it(this);
  }
  delegate() {
    return this;
  }
  buildIPLDView() {
    return this;
  }
  /**
   * @returns {API.DelegationJSON<this>}
   */
  toJSON() {
    return (
      /** @type {any} */
      {
        ...this.data.toJSON(),
        "/": this.cid.toString(),
        prf: this.proofs.map(
          (proof) => isDelegation(proof) ? proof : { "/": proof.toString() }
        )
      }
    );
  }
};
var archive = async (delegation) => {
  try {
    const store2 = /* @__PURE__ */ new Map();
    for (const block of delegation.iterateIPLDBlocks()) {
      store2.set(`${block.cid}`, block);
    }
    const variant2 = await write2({
      [`ucan@${delegation.version}`]: delegation.root.cid
    });
    store2.set(`${variant2.cid}`, variant2);
    const bytes2 = encode16({
      roots: [variant2],
      blocks: store2
    });
    return ok(bytes2);
  } catch (cause) {
    return error(
      /** @type {Error} */
      cause
    );
  }
};
var ArchiveSchema = variant({
  "ucan@0.9.1": (
    /** @type {Schema.Schema<API.UCANLink>} */
    match2({ version: 1 })
  )
});
var extract = async (archive3) => {
  try {
    const { roots, blocks } = decode19(archive3);
    const [root2] = roots;
    if (root2 == null) {
      return error2("CAR archive does not contain a root block");
    }
    const { bytes: bytes2 } = root2;
    const variant2 = decode6(bytes2);
    const [, link5] = ArchiveSchema.match(variant2);
    return ok(view2({ root: link5, blocks }));
  } catch (cause) {
    return error(
      /** @type {Error} */
      cause
    );
  }
};
var it = function* (delegation) {
  for (const proof of delegation.proofs) {
    if (isDelegation(proof)) {
      yield* it(proof);
      yield proof;
    }
  }
};
var decodeCache = /* @__PURE__ */ new WeakMap();
var decode20 = ({ bytes: bytes2 }) => {
  const data = decodeCache.get(bytes2);
  if (!data) {
    const data2 = decode18(bytes2);
    decodeCache.set(bytes2, data2);
    return data2;
  }
  return data;
};
var delegate = async ({ issuer, audience, proofs: proofs2 = [], attachedBlocks = /* @__PURE__ */ new Map(), ...input10 }, options) => {
  const links3 = [];
  const blocks = /* @__PURE__ */ new Map();
  for (const proof of proofs2) {
    if (!isDelegation(proof)) {
      links3.push(proof);
    } else {
      links3.push(proof.cid);
      for (const block of proof.export()) {
        blocks.set(block.cid.toString(), block);
      }
    }
  }
  const data = await issue({
    ...input10,
    issuer,
    audience,
    proofs: links3
  });
  const { cid, bytes: bytes2 } = await write(data, options);
  decodeCache.set(cid, data);
  const delegation = new Delegation({ cid, bytes: bytes2 }, blocks);
  Object.defineProperties(delegation, { proofs: { value: proofs2 } });
  for (const block of attachedBlocks.values()) {
    delegation.attach(block);
  }
  return delegation;
};
var exportDAG = function* (root2, blocks, attachedLinks) {
  for (const link5 of decode20(root2).proofs) {
    const root3 = (
      /** @type {UCAN.Block} */
      blocks.get(`${link5}`)
    );
    if (root3) {
      yield* exportSubDAG(root3, blocks);
    }
  }
  for (const link5 of attachedLinks.values()) {
    const block = blocks.get(link5);
    if (block) {
      yield block;
    }
  }
  yield root2;
};
var exportSubDAG = function* (root2, blocks) {
  for (const link5 of decode20(root2).proofs) {
    const root3 = (
      /** @type {UCAN.Block} */
      blocks.get(`${link5}`)
    );
    if (root3) {
      yield* exportSubDAG(root3, blocks);
    }
  }
  yield root2;
};
var importDAG = (dag) => {
  let entries3 = [];
  for (const block of dag) {
    entries3.push([block.cid.toString(), block]);
  }
  const last = entries3.pop();
  if (!last) {
    throw new RangeError("Empty DAG can not be turned into a delegation");
  } else {
    const [, root2] = last;
    return new Delegation(
      /** @type {API.UCANBlock<C>} */
      root2,
      new Map(entries3)
    );
  }
};
var create6 = ({ root: root2, blocks }) => new Delegation(root2, blocks);
var view2 = ({ root: root2, blocks }, fallback) => {
  const block = get(root2, blocks, null);
  if (block == null) {
    return fallback !== void 0 ? fallback : notFound(root2);
  }
  return create6({ root: block, blocks });
};
var proofs = (delegation) => {
  const proofs2 = [];
  const { root: root2, blocks } = delegation;
  for (const link5 of decode20(root2).proofs) {
    const root3 = (
      /** @type {UCAN.Block} */
      blocks.get(link5.toString())
    );
    proofs2.push(root3 ? create6({ root: root3, blocks }) : link5);
  }
  Object.defineProperty(delegation, "proofs", { value: proofs2 });
  return proofs2;
};
function getLinksFromObject(obj) {
  const links3 = [];
  function recurse(obj2) {
    for (const key in obj2) {
      const value = obj2[key];
      if (isLink(value)) {
        links3.push(value);
      } else if (value && typeof value === "object") {
        recurse(value);
      }
    }
  }
  recurse(obj);
  return links3;
}

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/invocation.js
var invocation_exports = {};
__export(invocation_exports, {
  Invocation: () => Invocation,
  create: () => create7,
  invoke: () => invoke,
  isInvocation: () => isInvocation,
  view: () => view3
});
var isInvocation = (value) => isDelegation(value);
var invoke = (options) => new IssuedInvocation(options);
var create7 = ({ root: root2, blocks }) => new Invocation(root2, blocks);
var view3 = ({ root: root2, blocks }, fallback) => {
  const block = get(root2, blocks, null);
  if (block == null) {
    return fallback !== void 0 ? fallback : notFound(root2);
  }
  return (
    /** @type {API.Invocation<C>} */
    create7({ root: block, blocks })
  );
};
var IssuedInvocation = class {
  /**
   * @param {API.InvocationOptions<Capability>} data
   */
  constructor({
    issuer,
    audience,
    capability: capability2,
    proofs: proofs2 = [],
    expiration,
    lifetimeInSeconds,
    notBefore,
    nonce,
    facts = []
  }) {
    this.issuer = issuer;
    this.audience = audience;
    this.proofs = proofs2;
    this.capabilities = [capability2];
    this.expiration = expiration;
    this.lifetimeInSeconds = lifetimeInSeconds;
    this.notBefore = notBefore;
    this.nonce = nonce;
    this.facts = facts;
    this.attachedBlocks = /* @__PURE__ */ new Map();
  }
  /**
   * @param {API.Block} block
   */
  attach(block) {
    this.attachedBlocks.set(`${block.cid}`, block);
  }
  delegate() {
    return delegate(this);
  }
  buildIPLDView() {
    return delegate(this);
  }
  /**
   * @template {API.InvocationService<Capability>} Service
   * @param {API.ConnectionView<Service>} connection
   * @returns {Promise<API.InferReceipt<Capability, Service>>}
   */
  async execute(connection6) {
    const invocation = this;
    const [result] = await connection6.execute(invocation);
    return result;
  }
};
var Invocation = class extends Delegation {
};

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/message.js
var message_exports = {};
__export(message_exports, {
  MessageSchema: () => MessageSchema,
  build: () => build2,
  view: () => view5
});

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/receipt.js
var receipt_exports = {};
__export(receipt_exports, {
  issue: () => issue2,
  view: () => view4
});
var view4 = ({ root: root2, blocks }, fallback) => {
  const block = get(root2, blocks, null);
  if (block == null) {
    return fallback !== void 0 ? fallback : notFound(root2);
  }
  const data = decode6(block.bytes);
  return new Receipt({ root: { ...block, data }, store: blocks });
};
var Receipt = class {
  /**
   * @param {object} input
   * @param {Required<API.Block<API.ReceiptModel<Ok, Error, Ran>>>} input.root
   * @param {DAG.BlockStore} input.store
   * @param {API.Meta} [input.meta]
   * @param {Ran|ReturnType<Ran['link']>} [input.ran]
   * @param {API.EffectsModel} [input.fx]
   * @param {API.SignatureView<API.OutcomeModel<Ok, Error, Ran>, SigAlg>} [input.signature]
   * @param {API.UCAN.Principal} [input.issuer]
   * @param {API.Proof[]} [input.proofs]
   */
  constructor({ root: root2, store: store2, ran, issuer, signature, proofs: proofs2 }) {
    this.store = store2;
    this.root = root2;
    this._ran = ran;
    this._fx = void 0;
    this._signature = signature;
    this._proofs = proofs2;
    this._issuer = issuer;
  }
  /**
   * @returns {Ran|ReturnType<Ran['link']>}
   */
  get ran() {
    const ran = this._ran;
    if (!ran) {
      const ran2 = (
        /** @type {Ran} */
        view3(
          {
            root: this.root.data.ocm.ran,
            blocks: this.store
          },
          this.root.data.ocm.ran
        )
      );
      this._ran = ran2;
      return ran2;
    } else {
      return ran;
    }
  }
  get proofs() {
    const proofs2 = this._proofs;
    if (proofs2) {
      return proofs2;
    } else {
      const { store: store2, root: root2 } = this;
      const { prf } = root2.data.ocm;
      const proofs3 = [];
      if (prf) {
        for (const link5 of prf) {
          const proof = view2({ root: link5, blocks: store2 }, link5);
          proofs3.push(proof);
        }
      }
      this._proofs = proofs3;
      return proofs3;
    }
  }
  link() {
    return this.root.cid;
  }
  get meta() {
    return this.root.data.ocm.meta;
  }
  get issuer() {
    const issuer = this._issuer;
    if (issuer) {
      return issuer;
    } else {
      const { iss } = this.root.data.ocm;
      if (iss) {
        const issuer2 = parse2(iss);
        this._issuer = issuer2;
        return issuer2;
      }
    }
  }
  get out() {
    return this.root.data.ocm.out;
  }
  get fx() {
    let fx = this._fx;
    if (!fx) {
      const { store: blocks } = this;
      const { fork: fork5, join: join2 } = this.root.data.ocm.fx;
      fx = {
        fork: fork5.map((root2) => view3({ root: root2, blocks }, root2))
      };
      if (join2) {
        fx.join = view3({ root: join2, blocks }, join2);
      }
      this._fx = fx;
    }
    return fx;
  }
  get signature() {
    const signature = this._signature;
    if (signature) {
      return signature;
    } else {
      const signature2 = (
        /** @type {API.SignatureView<API.OutcomeModel<Ok, Error, Ran>, SigAlg>} */
        view(this.root.data.sig)
      );
      this._signature = signature2;
      return signature2;
    }
  }
  /**
   * @param {API.Crypto.Verifier} signingPrincipal
   */
  verifySignature(signingPrincipal) {
    return this.signature.verify(
      signingPrincipal,
      encode15(this.root.data.ocm)
    );
  }
  buildIPLDView() {
    return this;
  }
  *iterateIPLDBlocks() {
    const { ran, fx, proofs: proofs2, root: root2 } = this;
    yield* iterate(ran);
    for (const fork5 of fx.fork) {
      yield* iterate(fork5);
    }
    if (fx.join) {
      yield* iterate(fx.join);
    }
    for (const proof of proofs2) {
      yield* iterate(proof);
    }
    yield root2;
  }
};
var ReceptBuilder = class {
  /**
   * @param {object} options
   * @param {API.Signer<API.DID, SigAlg>} options.issuer
   * @param {Ran|ReturnType<Ran['link']>} options.ran
   * @param {API.Result<Ok, Error>} options.result
   * @param {API.Effects} [options.fx]
   * @param {API.Proof[]} [options.proofs]
   * @param {Record<string, unknown>} [options.meta]
   */
  constructor({ issuer, result, ran, fx = NOFX, proofs: proofs2 = [], meta = {} }) {
    this.issuer = issuer;
    this.result = result;
    this.ran = ran;
    this.fx = fx;
    this.proofs = proofs2;
    this.meta = meta;
  }
  async buildIPLDView({ hasher = sha2562, codec = cbor_exports3 } = {}) {
    const store2 = createStore();
    addEveryInto(iterate(this.ran), store2);
    const prf = [];
    for (const proof of this.proofs) {
      addEveryInto(iterate(proof), store2);
      prf.push(proof.link());
    }
    const fx = { fork: [] };
    for (const fork5 of this.fx.fork) {
      addEveryInto(iterate(fork5), store2);
      fx.fork.push(fork5.link());
    }
    if (this.fx.join) {
      addEveryInto(iterate(this.fx.join), store2);
      fx.join = this.fx.join.link();
    }
    const outcome = {
      ran: (
        /** @type {ReturnType<Ran['link']>} */
        this.ran.link()
      ),
      out: this.result,
      fx,
      meta: this.meta,
      iss: this.issuer.did(),
      prf
    };
    const signature = await this.issuer.sign(encode15(outcome));
    const model = {
      ocm: outcome,
      sig: signature
    };
    const root2 = await writeInto(model, store2, {
      hasher,
      codec
    });
    return new Receipt({
      root: root2,
      store: store2,
      signature,
      proofs: this.proofs,
      ran: this.ran
    });
  }
};
var NOFX = Object.freeze({ fork: Object.freeze([]) });
var issue2 = (options) => new ReceptBuilder(options).buildIPLDView();

// ../../node_modules/.pnpm/@ucanto+core@10.0.1/node_modules/@ucanto/core/src/message.js
var MessageSchema = variant({
  "ucanto/message@7.0.0": struct({
    execute: match2().array().optional(),
    delegate: dictionary({
      key: string(),
      value: (
        /** @type {API.Reader<API.Link<API.ReceiptModel>>} */
        match2()
      )
    }).array().optional()
  })
});
var build2 = ({ invocations, receipts }) => new MessageBuilder({ invocations, receipts }).buildIPLDView();
var view5 = ({ root: root2, store: store2 }, fallback) => {
  const block = get(root2, store2, null);
  if (block === null) {
    return fallback !== void 0 ? fallback : notFound(root2);
  }
  const data = cbor_exports3.decode(block.bytes);
  const [branch, value] = MessageSchema.match(data, fallback);
  switch (branch) {
    case "ucanto/message@7.0.0":
      return new Message({ root: { ...block, data }, store: store2 });
    default:
      return value;
  }
};
var MessageBuilder = class {
  /**
   * @param {object} source
   * @param {I} [source.invocations]
   * @param {R} [source.receipts]
   */
  constructor({ invocations, receipts }) {
    this.invocations = invocations;
    this.receipts = receipts;
  }
  /**
   *
   * @param {API.BuildOptions} [options]
   * @returns {Promise<Message<{ In: API.InferInvocations<I>, Out: R }>>}
   */
  async buildIPLDView(options) {
    const store2 = /* @__PURE__ */ new Map();
    const { invocations, ...executeField } = await writeInvocations(
      this.invocations || [],
      store2
    );
    const { receipts, ...receiptsField } = await writeReceipts(
      this.receipts || [],
      store2
    );
    const root2 = await writeInto(
      /** @type {API.AgentMessageModel<{ In: API.InferInvocations<I>, Out: R }>} */
      {
        "ucanto/message@7.0.0": {
          ...executeField,
          ...receiptsField
        }
      },
      store2,
      options
    );
    return new Message({ root: root2, store: store2 }, { receipts, invocations });
  }
};
var writeInvocations = async (run, store2) => {
  const invocations = [];
  const execute2 = [];
  for (const invocation of run) {
    const view6 = await invocation.buildIPLDView();
    execute2.push(view6.link());
    invocations.push(view6);
    for (const block of view6.iterateIPLDBlocks()) {
      store2.set(`${block.cid}`, block);
    }
  }
  return { invocations, ...execute2.length > 0 ? { execute: execute2 } : {} };
};
var writeReceipts = async (source, store2) => {
  if (source.length === 0) {
    return {};
  }
  const receipts = /* @__PURE__ */ new Map();
  const report = {};
  for (const [n, receipt] of source.entries()) {
    const view6 = await receipt.buildIPLDView();
    for (const block of view6.iterateIPLDBlocks()) {
      store2.set(`${block.cid}`, block);
    }
    const key = `${view6.ran.link()}`;
    if (!(key in report)) {
      report[key] = view6.root.cid;
      receipts.set(key, view6);
    } else {
      receipts.set(`${key}@${n}`, view6);
    }
  }
  return { receipts, report };
};
var Message = class {
  /**
   * @param {object} source
   * @param {Required<API.Block<API.AgentMessageModel<T>>>} source.root
   * @param {DAG.BlockStore} source.store
   * @param {object} build
   * @param {API.Invocation[]} [build.invocations]
   * @param {Map<string, API.Receipt>} [build.receipts]
   */
  constructor({ root: root2, store: store2 }, { invocations, receipts } = {}) {
    this.root = root2;
    this.store = store2;
    this._invocations = invocations;
    this._receipts = receipts;
  }
  *iterateIPLDBlocks() {
    for (const invocation of this.invocations) {
      yield* invocation.iterateIPLDBlocks();
    }
    for (const receipt of this.receipts.values()) {
      yield* receipt.iterateIPLDBlocks();
    }
    yield this.root;
  }
  /**
   * @template [E=never]
   * @param {API.Link} link
   * @param {E} [fallback]
   * @returns {API.Receipt|E}
   */
  get(link5, fallback) {
    const receipts = this.root.data["ucanto/message@7.0.0"].report || {};
    const receipt = receipts[`${link5}`];
    if (receipt) {
      return view4({ root: receipt, blocks: this.store });
    } else {
      return fallback !== void 0 ? fallback : panic(`Message does not include receipt for ${link5}`);
    }
  }
  get invocationLinks() {
    return this.root.data["ucanto/message@7.0.0"].execute || [];
  }
  get invocations() {
    let invocations = this._invocations;
    if (!invocations) {
      invocations = this.invocationLinks.map((link5) => {
        return invocation_exports.view({ root: link5, blocks: this.store });
      });
    }
    return invocations;
  }
  get receipts() {
    let receipts = this._receipts;
    if (!receipts) {
      receipts = /* @__PURE__ */ new Map();
      const report = this.root.data["ucanto/message@7.0.0"].report || {};
      for (const [key, link5] of Object.entries(report)) {
        const receipt = view4({ root: link5, blocks: this.store });
        receipts.set(`${receipt.ran.link()}`, receipt);
      }
    }
    return receipts;
  }
};

// ../../node_modules/.pnpm/@ucanto+client@9.0.1/node_modules/@ucanto/client/src/connection.js
var connect = (options) => new Connection(options);
var Connection = class {
  /**
   * @param {API.ConnectionOptions<T>} options
   */
  constructor(options) {
    this.id = options.id;
    this.options = options;
    this.codec = options.codec;
    this.channel = options.channel;
    this.hasher = options.hasher || sha2562;
  }
  /**
   * Execute invocations.
   *
   * @template {API.Capability} C
   * @template {API.Tuple<API.ServiceInvocation<C, T>>} I
   * @param {I} invocations
   * @returns {Promise<API.InferReceipts<I, T>>}
   */
  async execute(...invocations) {
    return execute(invocations, this);
  }
};
var execute = async (invocations, connection6) => {
  const input10 = await message_exports.build({ invocations });
  const request = await connection6.codec.encode(input10, connection6);
  const response = await connection6.channel.request(request);
  try {
    const output = await connection6.codec.decode(response);
    const receipts = input10.invocationLinks.map((link5) => output.get(link5));
    return (
      /** @type {API.InferReceipts<I, T>} */
      receipts
    );
  } catch (error3) {
    const { message, name: name14 = "Error", ...cause } = (
      /** @type {Error} */
      error3
    );
    const receipts = [];
    for await (const ran of input10.invocationLinks) {
      const receipt = await receipt_exports.issue({
        ran,
        result: { error: { ...cause, name: name14, message } },
        // @ts-expect-error - we can not really sign a receipt without having
        // an access to a signer which client does not have. In the future
        // we will change client API requiring a signer to be passed in but
        // for now we just use a dummy signer.
        issuer: {
          did() {
            return connection6.id.did();
          },
          sign() {
            return signature_exports.createNonStandard("", new Uint8Array());
          }
        }
      });
      receipts.push(receipt);
    }
    return (
      /** @type {API.InferReceipts<I, T>} */
      receipts
    );
  }
};

// ../../node_modules/.pnpm/@ucanto+client@9.0.1/node_modules/@ucanto/client/src/lib.js
var delegate2 = delegation_exports.delegate;

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/car.js
var car_exports2 = {};
__export(car_exports2, {
  codec: () => car_exports,
  contentType: () => contentType5,
  inbound: () => inbound2,
  outbound: () => outbound2,
  request: () => request_exports,
  response: () => response_exports
});

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/car/request.js
var request_exports = {};
__export(request_exports, {
  codec: () => car_exports,
  contentType: () => contentType3,
  decode: () => decode22,
  encode: () => encode17
});
var contentType3 = car_exports.contentType;
var HEADERS = Object.freeze({
  "content-type": contentType3,
  // We will signal that we want to receive a CAR file in the response
  accept: contentType3
});
var encode17 = (message, options) => {
  const blocks = /* @__PURE__ */ new Map();
  for (const block of message.iterateIPLDBlocks()) {
    blocks.set(`${block.cid}`, block);
  }
  const body = car_exports.encode({
    roots: [message.root],
    blocks
  });
  return {
    headers: options?.headers || { ...HEADERS },
    body
  };
};
var decode22 = async ({ headers, body }) => {
  const { roots, blocks } = car_exports.decode(
    /** @type {Uint8Array} */
    body
  );
  const message = message_exports.view({ root: roots[0].cid, store: blocks });
  return (
    /** @type {Message} */
    message
  );
};

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/car/response.js
var response_exports = {};
__export(response_exports, {
  codec: () => car_exports,
  contentType: () => contentType4,
  decode: () => decode23,
  encode: () => encode18
});
var contentType4 = car_exports.contentType;
var HEADERS2 = Object.freeze({
  "content-type": contentType4
});
var encode18 = (message, options) => {
  const blocks = /* @__PURE__ */ new Map();
  for (const block of message.iterateIPLDBlocks()) {
    blocks.set(`${block.cid}`, block);
  }
  const body = car_exports.encode({
    roots: [message.root],
    blocks
  });
  return {
    headers: { ...HEADERS2 },
    body
  };
};
var decode23 = async ({ headers, body }) => {
  const { roots, blocks } = car_exports.decode(
    /** @type {Uint8Array} */
    body
  );
  const message = message_exports.view({ root: roots[0].cid, store: blocks });
  return (
    /** @type {Message} */
    message
  );
};

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/codec.js
var inbound = (source) => new Inbound(source);
var Inbound = class {
  /**
   * @param {API.HTTPRequest} request
   * @returns {API.Result<API.InboundAcceptCodec, API.HTTPError>} transport
   */
  accept({ headers }) {
    const contentType9 = headers["content-type"] || headers["Content-Type"];
    const decoder3 = this.decoders[contentType9];
    if (!decoder3) {
      return {
        error: {
          status: 415,
          message: `The server cannot process the request because the payload format is not supported. Please check the content-type header and try again with a supported media type.`,
          headers: {
            accept: Object.keys(this.decoders).join(", ")
          }
        }
      };
    }
    const accept2 = parseAcceptHeader(headers.accept || headers.Accept || "*/*");
    for (const { category, type: type2 } of accept2) {
      for (const encoder3 of this.encoders) {
        const select2 = (category === "*" || category === encoder3.category) && (type2 === "*" || type2 === encoder3.type);
        if (select2) {
          return { ok: { ...encoder3, decoder: decoder3 } };
        }
      }
    }
    return {
      error: {
        status: 406,
        message: `The requested resource cannot be served in the requested content type. Please specify a supported content type using the Accept header.`,
        headers: {
          accept: formatAcceptHeader(Object.values(this.encoders))
        }
      }
    };
  }
  /**
   * @param {object} source
   * @param {Record<string, API.Transport.RequestDecoder>} source.decoders
   * @param {Record<string, API.Transport.ResponseEncoder>} source.encoders
   */
  constructor({ decoders = {}, encoders = {} }) {
    this.decoders = decoders;
    if (Object.keys(decoders).length === 0) {
      throw new Error("At least one decoder MUST be provided");
    }
    this.encoders = Object.entries(encoders).map(([mediaType, encoder3]) => {
      return { ...parseMediaType(mediaType), encoder: encoder3 };
    }).sort((a, b) => b.preference - a.preference);
    if (this.encoders.length === 0) {
      throw new Error("At least one encoder MUST be provided");
    }
  }
};
var outbound = (source) => new Outbound(source);
var Outbound = class {
  /**
   * @param {object} source
   * @param {Record<string, API.Transport.RequestEncoder>} source.encoders
   * @param {Record<string, API.Transport.ResponseDecoder>} source.decoders
   */
  constructor({ decoders = {}, encoders = {} }) {
    this.decoders = decoders;
    if (Object.keys(decoders).length === 0) {
      throw new Error("At least one decoder MUST be provided");
    }
    this.encoders = Object.entries(encoders).map(([mediaType, encoder3]) => {
      return { ...parseMediaType(mediaType), encoder: encoder3 };
    }).sort((a, b) => b.preference - a.preference);
    this.acceptType = formatAcceptHeader(this.encoders);
    if (this.encoders.length === 0) {
      throw new Error("At least one encoder MUST be provided");
    }
    this.encoder = this.encoders[0].encoder;
  }
  /**
   * @template {API.AgentMessage} Message
   * @param {Message} message
   */
  encode(message) {
    return this.encoder.encode(message, {
      accept: this.acceptType
    });
  }
  /**
   * @template {API.AgentMessage} Message
   * @param {API.HTTPResponse<Message>} response
   * @returns {API.Await<Message>}
   */
  decode(response) {
    const { headers } = response;
    const contentType9 = headers["content-type"] || headers["Content-Type"];
    const decoder3 = this.decoders[contentType9] || this.decoders["*/*"];
    switch (response.status) {
      case 415:
      case 406:
        throw Object.assign(
          new RangeError(new TextDecoder().decode(response.body)),
          {
            status: response.status,
            headers: response.headers
          }
        );
    }
    if (!decoder3) {
      throw Object.assign(
        TypeError(
          `Can not decode response with content-type '${contentType9}' because no matching transport decoder is configured.`
        ),
        {
          error: true
        }
      );
    }
    return decoder3.decode(response);
  }
};
var parseMediaType = (source) => {
  const [mediaType = "*/*", mediaRange = ""] = source.trim().split(";");
  const [category = "*", type2 = "*"] = mediaType.split("/");
  const params = new URLSearchParams(mediaRange);
  const preference = parseFloat(params.get("q") || "0");
  return {
    category,
    type: type2,
    /* c8 ignore next */
    preference: isNaN(preference) ? 0 : preference
  };
};
var formatMediaType = ({ category, type: type2, preference }) => (
  /** @type {MediaType}  */
  `${category}/${type2}${preference ? `;q=${preference}` : ""}`
);
var parseAcceptHeader = (source) => source.split(",").map(parseMediaType).sort((a, b) => b.preference - a.preference);
var formatAcceptHeader = (source) => source.map(formatMediaType).join(", ");

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/car.js
var contentType5 = car_exports.contentType;
var inbound2 = inbound({
  decoders: {
    [contentType3]: request_exports
  },
  encoders: {
    [contentType4]: response_exports
  }
});
var outbound2 = outbound({
  encoders: {
    [contentType3]: request_exports
  },
  decoders: {
    [contentType4]: response_exports
  }
});

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/http.js
var http_exports = {};
__export(http_exports, {
  open: () => open
});
var open = ({ url, method = "POST", fetch }) => {
  if (!fetch) {
    if (typeof globalThis.fetch !== "undefined") {
      fetch = globalThis.fetch.bind(globalThis);
    } else {
      throw new TypeError(
        `ucanto HTTP transport got undefined \`fetch\`. Try passing in a \`fetch\` implementation explicitly.`
      );
    }
  }
  return new Channel({ url, method, fetch });
};
var Channel = class {
  /**
   * @param {object} options
   * @param {URL} options.url
   * @param {Fetcher} options.fetch
   * @param {string} [options.method]
   */
  constructor({ url, fetch, method }) {
    this.fetch = fetch;
    this.method = method;
    this.url = url;
  }
  /**
   * @template {API.Tuple<API.ServiceInvocation<API.Capability, S>>} I
   * @param {API.HTTPRequest<API.AgentMessage<{ In: API.InferInvocations<I>, Out: API.Tuple<API.Receipt> }>>} request
   * @returns {Promise<API.HTTPResponse<API.AgentMessage<{ Out: API.InferReceipts<I, S>, In: API.Tuple<API.Invocation> }>>>}
   */
  async request({ headers, body }) {
    const response = await this.fetch(this.url.href, {
      headers,
      body,
      method: this.method
    });
    const buffer2 = response.ok ? await response.arrayBuffer() : HTTPError.throw(`HTTP Request failed. ${this.method} ${this.url.href} \u2192 ${response.status}`, response);
    return {
      headers: response.headers.entries ? Object.fromEntries(response.headers.entries()) : (
        /* c8 ignore next */
        {}
      ),
      body: new Uint8Array(buffer2)
    };
  }
};
var HTTPError = class extends Error {
  /**
   * @param {string} message
   * @param {Options} options
   * @returns {never}
   */
  static throw(message, options) {
    throw new this(message, options);
  }
  /**
   * @param {string} message
   * @param {Options} options
   */
  constructor(message, { url, status = 500, statusText = "Server error" }) {
    super(message);
    this.name = "HTTPError";
    this.url = url;
    this.status = status;
    this.statusText = statusText;
  }
};

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/utf8.js
var encoder2 = new TextEncoder();
var decoder2 = new TextDecoder();

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/legacy/response.js
var response_exports2 = {};
__export(response_exports2, {
  contentType: () => contentType6,
  encode: () => encode19
});
var contentType6 = "application/cbor";
var HEADERS3 = Object.freeze({
  "content-type": contentType6
});
var encode19 = (message, options) => {
  const legacyResults = [];
  for (const receipt of message.receipts.values()) {
    const result = receipt.out;
    if (result.ok) {
      legacyResults.push(result.ok);
    } else {
      legacyResults.push({
        ...result.error,
        error: true
      });
    }
  }
  const body = encode15(legacyResults);
  return (
    /** @type {API.HTTPResponse<Message>} */
    {
      headers: HEADERS3,
      body
    }
  );
};

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/legacy/request.js
var request_exports2 = {};
__export(request_exports2, {
  contentType: () => contentType7,
  decode: () => decode24
});
var contentType7 = "application/car";
var decode24 = async ({ body }) => {
  const { roots, blocks } = decode19(
    /** @type {Uint8Array} */
    body
  );
  const run = [];
  for (const { cid } of roots) {
    const invocation = invocation_exports.view({
      root: (
        /** @type {API.Link} */
        cid
      ),
      blocks
    });
    run.push(invocation);
  }
  const message = await message_exports.build({
    invocations: (
      /** @type {API.Tuple<API.IssuedInvocation>} */
      run
    )
  });
  return (
    /** @type {Message} */
    message
  );
};

// ../../node_modules/.pnpm/@ucanto+transport@9.1.1/node_modules/@ucanto/transport/src/legacy.js
var { contentType: contentType8 } = request_exports2;
var inbound3 = inbound({
  decoders: {
    [contentType8]: request_exports2,
    [contentType5]: request_exports
  },
  encoders: {
    // Here we configure encoders such that if accept header is `*/*` (which is
    // the default if omitted) we will encode the response in CBOR. If
    // `application/vnd.ipld.car` is set we will encode the response in current
    // format.
    // Here we exploit the fact that legacy clients do not send an accept header
    // and therefore will get response in legacy format. New clients on the other
    // hand will send `application/vnd.ipld.car` and consequently get response
    // in current format.
    "*/*;q=0.1": response_exports2,
    [contentType5]: response_exports
  }
});

// ../../node_modules/.pnpm/@ucanto+validator@9.0.2/node_modules/@ucanto/validator/src/util.js
var the = (value) => value;
var entries = (object) => (
  /** @type {any} */
  Object.entries(object)
);
var combine = ([first, ...rest]) => {
  const results = first.map((value) => [value]);
  for (const values2 of rest) {
    const tuples = results.splice(0);
    for (const value of values2) {
      for (const tuple2 of tuples) {
        results.push([...tuple2, value]);
      }
    }
  }
  return results;
};
var intersection2 = (left, right) => {
  const [result, other] = left.length < right.length ? [new Set(left), new Set(right)] : [new Set(right), new Set(left)];
  for (const item of result) {
    if (!other.has(item)) {
      result.delete(item);
    }
  }
  return [...result];
};

// ../../node_modules/.pnpm/@ucanto+validator@9.0.2/node_modules/@ucanto/validator/src/error.js
var EscalatedCapability = class extends Failure {
  /**
   * @param {API.ParsedCapability} claimed
   * @param {object} delegated
   * @param {API.Failure} cause
   */
  constructor(claimed, delegated, cause) {
    super();
    this.claimed = claimed;
    this.delegated = delegated;
    this.cause = cause;
    this.name = the("EscalatedCapability");
  }
  describe() {
    return `Constraint violation: ${this.cause.message}`;
  }
};
var DelegationError = class extends Failure {
  /**
   * @param {(API.InvalidCapability | API.EscalatedDelegation | API.DelegationError)[]} causes
   * @param {object} context
   */
  constructor(causes, context2) {
    super();
    this.name = the("InvalidClaim");
    this.causes = causes;
    this.context = context2;
  }
  describe() {
    return [
      `Can not derive ${this.context} from delegated capabilities:`,
      ...this.causes.map((cause) => li2(cause.message))
    ].join("\n");
  }
  /**
   * @type {API.InvalidCapability | API.EscalatedDelegation | API.DelegationError}
   */
  get cause() {
    if (this.causes.length !== 1) {
      return this;
    } else {
      const [cause] = this.causes;
      const value = cause.name === "InvalidClaim" ? cause.cause : cause;
      Object.defineProperties(this, { cause: { value } });
      return value;
    }
  }
};
var MalformedCapability = class extends Failure {
  /**
   * @param {API.Capability} capability
   * @param {API.Failure} cause
   */
  constructor(capability2, cause) {
    super();
    this.name = the("MalformedCapability");
    this.capability = capability2;
    this.cause = cause;
  }
  describe() {
    return [
      `Encountered malformed '${this.capability.can}' capability: ${format7(
        this.capability
      )}`,
      li2(this.cause.message)
    ].join("\n");
  }
};
var UnknownCapability = class extends Failure {
  /**
   * @param {API.Capability} capability
   */
  constructor(capability2) {
    super();
    this.name = the("UnknownCapability");
    this.capability = capability2;
  }
  /* c8 ignore next 3 */
  describe() {
    return `Encountered unknown capability: ${format7(this.capability)}`;
  }
};
var format7 = (capability2, space) => JSON.stringify(
  capability2,
  (_key, value) => {
    if (isLink(value)) {
      return value.toString();
    } else {
      return value;
    }
  },
  space
);
var indent2 = (message, indent3 = "  ") => `${indent3}${message.split("\n").join(`
${indent3}`)}`;
var li2 = (message) => indent2(`- ${message}`);

// ../../node_modules/.pnpm/@ucanto+validator@9.0.2/node_modules/@ucanto/validator/src/capability.js
var capability = ({
  derives = defaultDerives,
  nb = defaultNBSchema,
  ...etc
}) => new Capability({ derives, nb, ...etc });
var defaultNBSchema = (
  /** @type {Schema.MapRepresentation<any>} */
  schema_exports3.struct({})
);
var or4 = (left, right) => new Or(left, right);
var and2 = (...selectors) => new And(selectors);
var derive = ({ from: from19, to, derives }) => new Derive(from19, to, derives);
var View2 = class {
  /**
   * @param {API.Source} source
   * @returns {API.MatchResult<M>}
   */
  /* c8 ignore next 3 */
  match(source) {
    return { error: new UnknownCapability(source.capability) };
  }
  /**
   * @param {API.Source[]} capabilities
   * @returns {API.Select<M>}
   */
  select(capabilities) {
    return select(this, capabilities);
  }
  /**
   * @template {API.ParsedCapability} U
   * @param {object} source
   * @param {API.TheCapabilityParser<API.DirectMatch<U>>} source.to
   * @param {API.Derives<U, API.InferDeriveProof<M['value']>>} source.derives
   * @returns {API.TheCapabilityParser<API.DerivedMatch<U, M>>}
   */
  derive({ derives, to }) {
    return derive({ derives, to, from: this });
  }
};
var Unit = class extends View2 {
  /**
   * @template {API.Match} W
   * @param {API.MatchSelector<W>} other
   * @returns {API.CapabilityParser<M | W>}
   */
  or(other) {
    return or4(this, other);
  }
  /**
   * @template {API.Match} W
   * @param {API.CapabilityParser<W>} other
   * @returns {API.CapabilitiesParser<[M, W]>}
   */
  and(other) {
    return and2(
      /** @type {API.CapabilityParser<M>} */
      this,
      other
    );
  }
};
var Capability = class extends Unit {
  /**
   * @param {Required<Descriptor<A, R, C>>} descriptor
   */
  constructor(descriptor) {
    super();
    this.descriptor = descriptor;
    this.schema = schema_exports3.struct({
      can: schema_exports3.literal(descriptor.can),
      with: descriptor.with,
      nb: descriptor.nb
    });
  }
  /**
   * @param {API.InferCreateOptions<R, C>} options
   */
  create(options) {
    const { descriptor, can } = this;
    const decoders = descriptor.nb;
    const data = (
      /** @type {C} */
      options.nb || {}
    );
    const resource = descriptor.with.read(options.with);
    if (resource.error) {
      throw Object.assign(
        new Error(`Invalid 'with' - ${resource.error.message}`),
        {
          cause: resource
        }
      );
    }
    const nb = descriptor.nb.read(data);
    if (nb.error) {
      throw Object.assign(new Error(`Invalid 'nb' - ${nb.error.message}`), {
        cause: nb
      });
    }
    return createCapability({ can, with: resource.ok, nb: nb.ok });
  }
  /**
   * @param {API.InferInvokeOptions<R, C>} options
   */
  invoke({ with: with_, nb, ...options }) {
    return invoke({
      ...options,
      capability: this.create(
        /** @type {API.InferCreateOptions<R, C>} */
        { with: with_, nb }
      )
    });
  }
  /**
   * @param {API.InferDelegationOptions<R, C>} options
   * @returns {Promise<API.Delegation<[API.InferDelegatedCapability<API.ParsedCapability<A, R, C>>]>>}
   */
  async delegate({ nb: input10 = {}, with: with_, ...options }) {
    const { descriptor, can } = this;
    const readers = descriptor.nb;
    const resource = descriptor.with.read(with_);
    if (resource.error) {
      throw Object.assign(
        new Error(`Invalid 'with' - ${resource.error.message}`),
        {
          cause: resource
        }
      );
    }
    const nb = descriptor.nb.partial().read(input10);
    if (nb.error) {
      throw Object.assign(new Error(`Invalid 'nb' - ${nb.error.message}`), {
        cause: nb
      });
    }
    return delegate({
      capabilities: [createCapability({ can, with: resource.ok, nb: nb.ok })],
      ...options
    });
  }
  get can() {
    return this.descriptor.can;
  }
  /**
   * @param {API.Source} source
   * @returns {API.MatchResult<API.DirectMatch<API.ParsedCapability<A, R, C>>>}
   */
  match(source) {
    const result = parseCapability(this.descriptor, source);
    return result.error ? result : { ok: new Match2(source, result.ok, this.descriptor) };
  }
  toString() {
    return JSON.stringify({ can: this.descriptor.can });
  }
};
var createCapability = ({ can, with: with_, nb }) => (
  /** @type {API.InferCapability<T>} */
  {
    can,
    with: with_,
    ...isEmpty(nb) ? {} : { nb }
  }
);
var isEmpty = (object) => {
  for (const _ in object) {
    return false;
  }
  return true;
};
var Or = class extends Unit {
  /**
   * @param {API.Matcher<M>} left
   * @param {API.Matcher<W>} right
   */
  constructor(left, right) {
    super();
    this.left = left;
    this.right = right;
  }
  /**
   * @param {API.Source} capability
   * @return {API.MatchResult<M|W>}
   */
  match(capability2) {
    const left = this.left.match(capability2);
    if (left.error) {
      const right = this.right.match(capability2);
      if (right.error) {
        return right.error.name === "MalformedCapability" ? (
          //
          right
        ) : (
          //
          left
        );
      } else {
        return right;
      }
    } else {
      return left;
    }
  }
  toString() {
    return `${this.left.toString()}|${this.right.toString()}`;
  }
};
var And = class _And extends View2 {
  /**
   * @param {Selectors} selectors
   */
  constructor(selectors) {
    super();
    this.selectors = selectors;
  }
  /**
   * @param {API.Source} capability
   * @returns {API.MatchResult<API.Amplify<API.InferMembers<Selectors>>>}
   */
  match(capability2) {
    const group2 = [];
    for (const selector of this.selectors) {
      const result = selector.match(capability2);
      if (result.error) {
        return result;
      } else {
        group2.push(result.ok);
      }
    }
    return {
      ok: new AndMatch(
        /** @type {API.InferMembers<Selectors>} */
        group2
      )
    };
  }
  /**
   * @param {API.Source[]} capabilities
   */
  select(capabilities) {
    return selectGroup(this, capabilities);
  }
  /**
   * @template E
   * @template {API.Match} X
   * @param {API.MatchSelector<API.Match<E, X>>} other
   * @returns {API.CapabilitiesParser<[...API.InferMembers<Selectors>, API.Match<E, X>]>}
   */
  and(other) {
    return new _And([...this.selectors, other]);
  }
  toString() {
    return `[${this.selectors.map(String).join(", ")}]`;
  }
};
var Derive = class extends Unit {
  /**
   * @param {API.MatchSelector<M>} from
   * @param {API.TheCapabilityParser<API.DirectMatch<T>>} to
   * @param {API.Derives<T, API.InferDeriveProof<M['value']>>} derives
   */
  constructor(from19, to, derives) {
    super();
    this.from = from19;
    this.to = to;
    this.derives = derives;
  }
  /**
   * @type {typeof this.to['create']}
   */
  create(options) {
    return this.to.create(options);
  }
  /**
   * @type {typeof this.to['invoke']}
   */
  invoke(options) {
    return this.to.invoke(options);
  }
  /**
   * @type {typeof this.to['delegate']}
   */
  delegate(options) {
    return this.to.delegate(options);
  }
  get can() {
    return this.to.can;
  }
  /**
   * @param {API.Source} capability
   * @returns {API.MatchResult<API.DerivedMatch<T, M>>}
   */
  match(capability2) {
    const match5 = this.to.match(capability2);
    if (match5.error) {
      return match5;
    } else {
      return { ok: new DerivedMatch(match5.ok, this.from, this.derives) };
    }
  }
  toString() {
    return this.to.toString();
  }
};
var Match2 = class _Match {
  /**
   * @param {API.Source} source
   * @param {API.ParsedCapability<A, R, C>} value
   * @param {Required<Descriptor<A, R, C>>} descriptor
   */
  constructor(source, value, descriptor) {
    this.source = [source];
    this.value = value;
    this.descriptor = descriptor;
  }
  get can() {
    return this.value.can;
  }
  get proofs() {
    const proofs2 = [this.source[0].delegation];
    Object.defineProperties(this, {
      proofs: { value: proofs2 }
    });
    return proofs2;
  }
  /**
   * @param {API.CanIssue} context
   * @returns {API.DirectMatch<API.ParsedCapability<A, R, C>>|null}
   */
  prune(context2) {
    if (context2.canIssue(this.value, this.source[0].delegation.issuer.did())) {
      return null;
    } else {
      return this;
    }
  }
  /**
   * @param {API.Source[]} capabilities
   * @returns {API.Select<API.DirectMatch<API.ParsedCapability<A, R, C>>>}
   */
  select(capabilities) {
    const unknown2 = [];
    const errors = [];
    const matches = [];
    for (const capability2 of capabilities) {
      const result = resolveCapability(this.descriptor, this.value, capability2);
      if (result.ok) {
        const claim = this.descriptor.derives(this.value, result.ok);
        if (claim.error) {
          errors.push(
            new DelegationError(
              [new EscalatedCapability(this.value, result.ok, claim.error)],
              this
            )
          );
        } else {
          matches.push(new _Match(capability2, result.ok, this.descriptor));
        }
      } else {
        switch (result.error.name) {
          case "UnknownCapability":
            unknown2.push(result.error.capability);
            break;
          case "MalformedCapability":
          default:
            errors.push(new DelegationError([result.error], this));
        }
      }
    }
    return { matches, unknown: unknown2, errors };
  }
  toString() {
    const { nb } = this.value;
    return JSON.stringify({
      can: this.descriptor.can,
      with: this.value.with,
      nb: nb && Object.keys(nb).length > 0 ? nb : void 0
    });
  }
};
var DerivedMatch = class _DerivedMatch {
  /**
   * @param {API.DirectMatch<T>} selected
   * @param {API.MatchSelector<M>} from
   * @param {API.Derives<T, API.InferDeriveProof<M['value']>>} derives
   */
  constructor(selected, from19, derives) {
    this.selected = selected;
    this.from = from19;
    this.derives = derives;
  }
  get can() {
    return this.value.can;
  }
  get source() {
    return this.selected.source;
  }
  get proofs() {
    const proofs2 = [];
    for (const { delegation } of this.selected.source) {
      proofs2.push(delegation);
    }
    Object.defineProperties(this, { proofs: { value: proofs2 } });
    return proofs2;
  }
  get value() {
    return this.selected.value;
  }
  /**
   * @param {API.CanIssue} context
   */
  prune(context2) {
    const selected = (
      /** @type {API.DirectMatch<T>|null} */
      this.selected.prune(context2)
    );
    return selected ? new _DerivedMatch(selected, this.from, this.derives) : null;
  }
  /**
   * @param {API.Source[]} capabilities
   */
  select(capabilities) {
    const { derives, selected, from: from19 } = this;
    const { value } = selected;
    const direct = selected.select(capabilities);
    const derived = from19.select(capabilities);
    const matches = [];
    const errors = [];
    for (const match5 of derived.matches) {
      const result = derives(value, match5.value);
      if (result.error) {
        errors.push(
          new DelegationError(
            [new EscalatedCapability(value, match5.value, result.error)],
            this
          )
        );
      } else {
        matches.push(match5);
      }
    }
    return {
      unknown: intersection2(direct.unknown, derived.unknown),
      errors: [
        ...errors,
        ...direct.errors,
        ...derived.errors.map((error3) => new DelegationError([error3], this))
      ],
      matches: [
        ...direct.matches.map((match5) => new _DerivedMatch(match5, from19, derives)),
        ...matches
      ]
    };
  }
  toString() {
    return this.selected.toString();
  }
};
var AndMatch = class _AndMatch {
  /**
   * @param {API.Match[]} matches
   */
  constructor(matches) {
    this.matches = matches;
  }
  get selectors() {
    return this.matches;
  }
  /**
   * @returns {API.Source[]}
   */
  get source() {
    const source = [];
    for (const match5 of this.matches) {
      source.push(...match5.source);
    }
    Object.defineProperties(this, { source: { value: source } });
    return source;
  }
  /**
   * @param {API.CanIssue} context
   */
  prune(context2) {
    const matches = [];
    for (const match5 of this.matches) {
      const pruned = match5.prune(context2);
      if (pruned) {
        matches.push(pruned);
      }
    }
    return matches.length === 0 ? null : new _AndMatch(matches);
  }
  get proofs() {
    const proofs2 = [];
    for (const { delegation } of this.source) {
      proofs2.push(delegation);
    }
    Object.defineProperties(this, { proofs: { value: proofs2 } });
    return proofs2;
  }
  /**
   * @type {API.InferValue<API.InferMembers<Selectors>>}
   */
  get value() {
    const value = [];
    for (const match5 of this.matches) {
      value.push(match5.value);
    }
    Object.defineProperties(this, { value: { value } });
    return (
      /** @type {any} */
      value
    );
  }
  /**
   * @param {API.Source[]} capabilities
   */
  select(capabilities) {
    return selectGroup(this, capabilities);
  }
  toString() {
    return `[${this.matches.map((match5) => match5.toString()).join(", ")}]`;
  }
};
var resolveAbility = (pattern, can, fallback) => {
  switch (pattern) {
    case can:
    case "*":
      return can;
    default:
      return pattern.endsWith("/*") && can.startsWith(pattern.slice(0, -1)) ? can : fallback;
  }
};
var resolveResource = (source, uri2, fallback) => {
  switch (source) {
    case uri2:
    case "ucan:*":
      return uri2;
    default:
      return fallback;
  }
};
var parseCapability = (descriptor, source) => {
  const { delegation } = source;
  const capability2 = (
    /** @type {API.Capability<A, R, C>} */
    source.capability
  );
  if (descriptor.can !== capability2.can) {
    return { error: new UnknownCapability(capability2) };
  }
  const uri2 = descriptor.with.read(capability2.with);
  if (uri2.error) {
    return { error: new MalformedCapability(capability2, uri2.error) };
  }
  const nb = descriptor.nb.read(capability2.nb || {});
  if (nb.error) {
    return { error: new MalformedCapability(capability2, nb.error) };
  }
  return { ok: new CapabilityView(descriptor.can, uri2.ok, nb.ok, delegation) };
};
var resolveCapability = (descriptor, claimed, { capability: capability2, delegation }) => {
  const can = resolveAbility(capability2.can, claimed.can, null);
  if (can == null) {
    return { error: new UnknownCapability(capability2) };
  }
  const resource = resolveResource(
    capability2.with,
    claimed.with,
    capability2.with
  );
  const uri2 = descriptor.with.read(resource);
  if (uri2.error) {
    return { error: new MalformedCapability(capability2, uri2.error) };
  }
  const nb = descriptor.nb.read({
    ...claimed.nb,
    ...capability2.nb
  });
  if (nb.error) {
    return { error: new MalformedCapability(capability2, nb.error) };
  }
  return { ok: new CapabilityView(can, uri2.ok, nb.ok, delegation) };
};
var CapabilityView = class {
  /**
   * @param {A} can
   * @param {R} with_
   * @param {C} nb
   * @param {API.Delegation} delegation
   */
  constructor(can, with_, nb, delegation) {
    this.can = can;
    this.with = with_;
    this.delegation = delegation;
    this.nb = nb;
  }
};
var select = (matcher, capabilities) => {
  const unknown2 = [];
  const matches = [];
  const errors = [];
  for (const capability2 of capabilities) {
    const result = matcher.match(capability2);
    if (result.error) {
      switch (result.error.name) {
        case "UnknownCapability":
          unknown2.push(result.error.capability);
          break;
        case "MalformedCapability":
        default:
          errors.push(new DelegationError([result.error], result.error.capability));
      }
    } else {
      matches.push(result.ok);
    }
  }
  return { matches, errors, unknown: unknown2 };
};
var selectGroup = (self2, capabilities) => {
  let unknown2;
  const data = [];
  const errors = [];
  for (const selector of self2.selectors) {
    const selected = selector.select(capabilities);
    unknown2 = unknown2 ? intersection2(unknown2, selected.unknown) : selected.unknown;
    for (const error3 of selected.errors) {
      errors.push(new DelegationError([error3], self2));
    }
    data.push(selected.matches);
  }
  const matches = combine(data).map((group2) => new AndMatch(group2));
  return {
    unknown: (
      /* c8 ignore next */
      unknown2 || []
    ),
    errors,
    matches
  };
};
var defaultDerives = (claimed, delegated) => {
  if (delegated.with.endsWith("*")) {
    if (!claimed.with.startsWith(delegated.with.slice(0, -1))) {
      return schema_exports3.error(
        `Resource ${claimed.with} does not match delegated ${delegated.with} `
      );
    }
  } else if (delegated.with !== claimed.with) {
    return schema_exports3.error(
      `Resource ${claimed.with} is not contained by ${delegated.with}`
    );
  }
  const caveats = delegated.nb || {};
  const nb = claimed.nb || {};
  const kv = entries(caveats);
  for (const [name14, value] of kv) {
    if (nb[name14] != value) {
      return schema_exports3.error(`${String(name14)}: ${nb[name14]} violates ${value}`);
    }
  }
  return { ok: true };
};

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/filecoin/lib.js
var FR32_SHA2_256_TRUNC254_PADDED_BINARY_TREE = (
  /** @type {const} */
  4113
);
var RAW_CODE = (
  /** @type {const} */
  85
);
var PieceLink = (
  /** @type {import('../types.js').PieceLinkSchema} */
  schema_exports3.link({
    code: RAW_CODE,
    version: 1,
    multihash: {
      code: FR32_SHA2_256_TRUNC254_PADDED_BINARY_TREE
    }
  })
);

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/equals.js
function equals5(a, b) {
  if (a === b) {
    return true;
  }
  if (a.byteLength !== b.byteLength) {
    return false;
  }
  for (let i = 0; i < a.byteLength; i++) {
    if (a[i] !== b[i]) {
      return false;
    }
  }
  return true;
}

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/utils.js
var ProviderDID = did_exports2.match({ method: "web" });
var SpaceDID = did_exports2.match({ method: "key" });
var AccountDID = did_exports2.match({ method: "mailto" });
var Await = schema_exports3.struct({
  "ucan/await": schema_exports3.tuple([schema_exports3.string(), schema_exports3.link()])
});
function equalWith(child, parent) {
  return child.with === parent.with ? ok({}) : fail2(`Can not derive ${child.can} with ${child.with} from ${parent.with}`);
}
function equal(child, parent, constraint) {
  if (parent === void 0 || parent === "*") {
    return ok({});
  } else if (String(child) === String(parent)) {
    return ok({});
  } else {
    return fail2(
      `Constrain violation: ${child} violates imposed ${constraint} constraint ${parent}`
    );
  }
}
var checkLink = (claimed, imposed, at2) => {
  return equal(
    String(claimed),
    imposed === void 0 ? void 0 : String(imposed),
    at2
  );
};
var and3 = (result) => result.error ? result : void 0;

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/filecoin/storefront.js
var filecoinOffer = capability({
  can: "filecoin/offer",
  /**
   * DID of the space the content is stored in.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the content that resulted in Filecoin piece.
     */
    content: schema_exports3.link(),
    /**
     * CID of the piece.
     */
    piece: PieceLink
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.content, from19.nb.content, "nb.content")) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || ok({});
  }
});
var filecoinSubmit = capability({
  can: "filecoin/submit",
  /**
   * DID of the Storefront.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the content that resulted in Filecoin piece.
     */
    content: schema_exports3.link(),
    /**
     * CID of the piece.
     *
     * @see https://github.com/filecoin-project/FIPs/pull/758/files
     */
    piece: PieceLink
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.content, from19.nb.content, "nb.content")) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || ok({});
  }
});
var filecoinAccept = capability({
  can: "filecoin/accept",
  /**
   * DID of the Storefront.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the content that resulted in Filecoin piece.
     */
    content: schema_exports3.link(),
    /**
     * CID of the piece.
     *
     * @see https://github.com/filecoin-project/FIPs/pull/758/files
     */
    piece: PieceLink
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.content, from19.nb.content, "nb.content")) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || ok({});
  }
});
var filecoinInfo = capability({
  can: "filecoin/info",
  /**
   * DID of the space the content is stored in.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the piece.
     *
     * @see https://github.com/filecoin-project/FIPs/pull/758/files
     */
    piece: PieceLink
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/service.js
var services = {
  STOREFRONT: {
    url: new URL("https://up.web3.storage"),
    principal: parse2("did:web:web3.storage")
  },
  AGGREGATOR: {
    url: new URL("https://aggregator.web3.storage"),
    principal: parse2("did:web:web3.storage")
  },
  DEALER: {
    url: new URL("https://dealer.web3.storage"),
    principal: parse2("did:web:web3.storage")
  },
  DEAL_TRACKER: {
    url: new URL("https://tracker.web3.storage"),
    principal: parse2("did:web:web3.storage")
  }
};

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/storefront.js
var connection = connect({
  id: services.STOREFRONT.principal,
  codec: car_exports2.outbound,
  channel: http_exports.open({
    url: services.STOREFRONT.url,
    method: "POST"
  })
});
async function filecoinOffer2({ issuer, with: resource, proofs: proofs2, audience }, content2, piece, options = {}) {
  const conn = options.connection ?? connection;
  const invocation = filecoinOffer.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? services.STOREFRONT.principal,
    with: resource,
    nb: {
      content: content2,
      piece
    },
    proofs: proofs2,
    expiration: Infinity
  });
  return await invocation.execute(conn);
}
async function filecoinSubmit2({ issuer, with: resource, proofs: proofs2, audience }, content2, piece, options = {}) {
  const conn = options.connection ?? connection;
  const invocation = filecoinSubmit.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? services.STOREFRONT.principal,
    with: resource,
    nb: {
      content: content2,
      piece
    },
    proofs: proofs2,
    expiration: Infinity
  });
  return await invocation.execute(conn);
}
async function filecoinAccept2({ issuer, with: resource, proofs: proofs2, audience }, content2, piece, options = {}) {
  const conn = options.connection ?? connection;
  const invocation = filecoinAccept.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? services.STOREFRONT.principal,
    with: resource,
    nb: {
      content: content2,
      piece
    },
    proofs: proofs2,
    expiration: Infinity
  });
  return await invocation.execute(conn);
}
async function filecoinInfo2({ issuer, with: resource, proofs: proofs2, audience }, piece, options = {}) {
  const conn = options.connection ?? connection;
  const invocation = filecoinInfo.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? services.STOREFRONT.principal,
    with: resource,
    nb: {
      piece
    },
    proofs: proofs2
  });
  return await invocation.execute(conn);
}

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/filecoin/aggregator.js
var pieceOffer = capability({
  can: "piece/offer",
  /**
   * DID of an authorized Storefront.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the piece.
     */
    piece: PieceLink,
    /**
     * Grouping of joining segments into an aggregate.
     */
    group: schema_exports3.text()
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || and3(equal(claim.nb.group, from19.nb.group, "nb.group")) || ok({});
  }
});
var pieceAccept = capability({
  can: "piece/accept",
  /**
   * DID of the Aggregator.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the piece.
     *
     * @see https://github.com/filecoin-project/FIPs/pull/758/files
     */
    piece: PieceLink,
    /**
     * Grouping of joining segments into an aggregate.
     */
    group: schema_exports3.text()
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || and3(equal(claim.nb.group, from19.nb.group, "nb.group")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/aggregator.js
var connection2 = connect({
  id: services.AGGREGATOR.principal,
  codec: car_exports2.outbound,
  channel: http_exports.open({
    url: services.AGGREGATOR.url,
    method: "POST"
  })
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/filecoin/dealer.js
var aggregateOffer = capability({
  can: "aggregate/offer",
  /**
   * DID of an authorized Storefront.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * Commitment proof for the aggregate being offered.
     */
    aggregate: PieceLink,
    /**
     * CID of the DAG-CBOR encoded block with offer details.
     * Service will queue given offer to be validated and handled.
     */
    pieces: schema_exports3.link({ version: 1 })
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.aggregate, from19.nb.aggregate, "nb.aggregate")) || and3(checkLink(claim.nb.pieces, from19.nb.pieces, "nb.pieces")) || ok({});
  }
});
var aggregateAccept = capability({
  can: "aggregate/accept",
  /**
   * did:key identifier of the broker authority where offer is made available.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * Commitment proof for the aggregate being offered.
     */
    aggregate: PieceLink,
    /**
     * CID of the DAG-CBOR encoded block with offer details.
     * Service will queue given offer to be validated and handled.
     */
    pieces: schema_exports3.link()
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.aggregate, from19.nb.aggregate, "nb.aggregate")) || and3(checkLink(claim.nb.pieces, from19.nb.pieces, "nb.pieces")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/dealer.js
var connection3 = connect({
  id: services.DEALER.principal,
  codec: car_exports2.outbound,
  channel: http_exports.open({
    url: services.DEALER.url,
    method: "POST"
  })
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@16.0.0/node_modules/@web3-storage/capabilities/src/filecoin/deal-tracker.js
var dealInfo = capability({
  can: "deal/info",
  /**
   * DID of the Storefront.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the piece.
     *
     * @see https://github.com/filecoin-project/FIPs/pull/758/files
     */
    piece: PieceLink
  }),
  derives: (claim, from19) => {
    return and3(equalWith(claim, from19)) || and3(checkLink(claim.nb.piece, from19.nb.piece, "nb.piece")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+filecoin-client@3.3.3/node_modules/@web3-storage/filecoin-client/dist/src/deal-tracker.js
var connection4 = connect({
  id: services.DEAL_TRACKER.principal,
  codec: car_exports2.outbound,
  channel: http_exports.open({
    url: services.DEAL_TRACKER.url,
    method: "POST"
  })
});

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/vendor/base-x.js
function base3(ALPHABET, name14) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode34(source) {
    if (source instanceof Uint8Array) ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length4 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size5 = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size5);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size5 - 1; (carry !== 0 || i2 < length4) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      pbegin++;
    }
    var it2 = size5 - length4;
    while (it2 !== size5 && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size5; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length4 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size5 = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size5);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size5 - 1; (carry !== 0 || i2 < length4) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length4 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size5 - length4;
    while (it4 !== size5 && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size5 - it4));
    var j2 = zeroes;
    while (it4 !== size5) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode41(string3) {
    var buffer2 = decodeUnsafe(string3);
    if (buffer2) {
      return buffer2;
    }
    throw new Error(`Non-${name14} character`);
  }
  return {
    encode: encode34,
    decodeUnsafe,
    decode: decode41
  };
}
var src3 = base3;
var _brrp__multiformats_scope_baseX3 = src3;
var base_x_default3 = _brrp__multiformats_scope_baseX3;

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/bytes.js
var empty4 = new Uint8Array(0);
var equals6 = (aa, bb) => {
  if (aa === bb) return true;
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
};
var coerce3 = (o) => {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") return o;
  if (o instanceof ArrayBuffer) return new Uint8Array(o);
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
};

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/bases/base.js
var Encoder3 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor(name14, prefix2, baseEncode) {
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
  }
  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode(bytes2) {
    if (bytes2 instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes2)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder3 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor(name14, prefix2, baseDecode) {
    this.name = name14;
    this.prefix = prefix2;
    if (prefix2.codePointAt(0) === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = /** @type {number} */
    prefix2.codePointAt(0);
    this.baseDecode = baseDecode;
  }
  /**
   * @param {string} text
   */
  decode(text2) {
    if (typeof text2 === "string") {
      if (text2.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text2)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text2.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or(decoder3) {
    return or5(this, decoder3);
  }
};
var ComposedDecoder3 = class {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor(decoders) {
    this.decoders = decoders;
  }
  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or(decoder3) {
    return or5(this, decoder3);
  }
  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode(input10) {
    const prefix2 = (
      /** @type {Prefix} */
      input10[0]
    );
    const decoder3 = this.decoders[prefix2];
    if (decoder3) {
      return decoder3.decode(input10);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input10)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
var or5 = (left, right) => new ComposedDecoder3(
  /** @type {Decoders<L|R>} */
  {
    ...left.decoders || { [
      /** @type API.UnibaseDecoder<L> */
      left.prefix
    ]: left },
    ...right.decoders || { [
      /** @type API.UnibaseDecoder<R> */
      right.prefix
    ]: right }
  }
);
var Codec3 = class {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor(name14, prefix2, baseEncode, baseDecode) {
    this.name = name14;
    this.prefix = prefix2;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder3(name14, prefix2, baseEncode);
    this.decoder = new Decoder3(name14, prefix2, baseDecode);
  }
  /**
   * @param {Uint8Array} input
   */
  encode(input10) {
    return this.encoder.encode(input10);
  }
  /**
   * @param {string} input
   */
  decode(input10) {
    return this.decoder.decode(input10);
  }
};
var from11 = ({ name: name14, prefix: prefix2, encode: encode34, decode: decode41 }) => new Codec3(name14, prefix2, encode34, decode41);
var baseX3 = ({ prefix: prefix2, name: name14, alphabet: alphabet2 }) => {
  const { encode: encode34, decode: decode41 } = base_x_default3(alphabet2, name14);
  return from11({
    prefix: prefix2,
    name: name14,
    encode: encode34,
    /**
     * @param {string} text
     */
    decode: (text2) => coerce3(decode41(text2))
  });
};
var decode25 = (string3, alphabet2, bitsPerChar, name14) => {
  const codes = {};
  for (let i = 0; i < alphabet2.length; ++i) {
    codes[alphabet2[i]] = i;
  }
  let end = string3.length;
  while (string3[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer2 = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = codes[string3[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name14} character`);
    }
    buffer2 = buffer2 << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer2 >> bits;
    }
  }
  if (bits >= bitsPerChar || 255 & buffer2 << 8 - bits) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
};
var encode20 = (data, alphabet2, bitsPerChar) => {
  const pad2 = alphabet2[alphabet2.length - 1] === "=";
  const mask2 = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer2 = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer2 = buffer2 << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet2[mask2 & buffer2 >> bits];
    }
  }
  if (bits) {
    out += alphabet2[mask2 & buffer2 << bitsPerChar - bits];
  }
  if (pad2) {
    while (out.length * bitsPerChar & 7) {
      out += "=";
    }
  }
  return out;
};
var rfc46483 = ({ name: name14, prefix: prefix2, bitsPerChar, alphabet: alphabet2 }) => {
  return from11({
    prefix: prefix2,
    name: name14,
    encode(input10) {
      return encode20(input10, alphabet2, bitsPerChar);
    },
    decode(input10) {
      return decode25(input10, alphabet2, bitsPerChar, name14);
    }
  });
};

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/bases/base32.js
var base323 = rfc46483({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper3 = rfc46483({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad3 = rfc46483({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper3 = rfc46483({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex3 = rfc46483({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper3 = rfc46483({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad3 = rfc46483({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper3 = rfc46483({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z3 = rfc46483({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/bases/base58.js
var base58btc3 = baseX3({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr3 = baseX3({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/vendor/varint.js
var encode_13 = encode21;
var MSB3 = 128;
var REST3 = 127;
var MSBALL3 = ~REST3;
var INT3 = Math.pow(2, 31);
function encode21(num, out, offset2) {
  out = out || [];
  offset2 = offset2 || 0;
  var oldOffset = offset2;
  while (num >= INT3) {
    out[offset2++] = num & 255 | MSB3;
    num /= 128;
  }
  while (num & MSBALL3) {
    out[offset2++] = num & 255 | MSB3;
    num >>>= 7;
  }
  out[offset2] = num | 0;
  encode21.bytes = offset2 - oldOffset + 1;
  return out;
}
var decode26 = read7;
var MSB$13 = 128;
var REST$13 = 127;
function read7(buf2, offset2) {
  var res = 0, offset2 = offset2 || 0, shift = 0, counter = offset2, b, l = buf2.length;
  do {
    if (counter >= l) {
      read7.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf2[counter++];
    res += shift < 28 ? (b & REST$13) << shift : (b & REST$13) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$13);
  read7.bytes = counter - offset2;
  return res;
}
var N13 = Math.pow(2, 7);
var N23 = Math.pow(2, 14);
var N33 = Math.pow(2, 21);
var N43 = Math.pow(2, 28);
var N53 = Math.pow(2, 35);
var N63 = Math.pow(2, 42);
var N73 = Math.pow(2, 49);
var N83 = Math.pow(2, 56);
var N93 = Math.pow(2, 63);
var length3 = function(value) {
  return value < N13 ? 1 : value < N23 ? 2 : value < N33 ? 3 : value < N43 ? 4 : value < N53 ? 5 : value < N63 ? 6 : value < N73 ? 7 : value < N83 ? 8 : value < N93 ? 9 : 10;
};
var varint5 = {
  encode: encode_13,
  decode: decode26,
  encodingLength: length3
};
var _brrp_varint3 = varint5;
var varint_default3 = _brrp_varint3;

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/varint.js
var decode27 = (data, offset2 = 0) => {
  const code19 = varint_default3.decode(data, offset2);
  return [code19, varint_default3.decode.bytes];
};
var encodeTo3 = (int, target, offset2 = 0) => {
  varint_default3.encode(int, target, offset2);
  return target;
};
var encodingLength3 = (int) => {
  return varint_default3.encodingLength(int);
};

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/hashes/digest.js
var create9 = (code19, digest5) => {
  const size5 = digest5.byteLength;
  const sizeOffset = encodingLength3(code19);
  const digestOffset = sizeOffset + encodingLength3(size5);
  const bytes2 = new Uint8Array(digestOffset + size5);
  encodeTo3(code19, bytes2, 0);
  encodeTo3(size5, bytes2, sizeOffset);
  bytes2.set(digest5, digestOffset);
  return new Digest5(code19, size5, digest5, bytes2);
};
var decode28 = (multihash) => {
  const bytes2 = coerce3(multihash);
  const [code19, sizeOffset] = decode27(bytes2);
  const [size5, digestOffset] = decode27(bytes2.subarray(sizeOffset));
  const digest5 = bytes2.subarray(sizeOffset + digestOffset);
  if (digest5.byteLength !== size5) {
    throw new Error("Incorrect length");
  }
  return new Digest5(code19, size5, digest5, bytes2);
};
var equals7 = (a, b) => {
  if (a === b) {
    return true;
  } else {
    const data = (
      /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */
      b
    );
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals6(a.bytes, data.bytes);
  }
};
var Digest5 = class {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor(code19, size5, digest5, bytes2) {
    this.code = code19;
    this.size = size5;
    this.digest = digest5;
    this.bytes = bytes2;
  }
};

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/cid.js
var format8 = (link5, base4) => {
  const { bytes: bytes2, version: version2 } = link5;
  switch (version2) {
    case 0:
      return toStringV03(
        bytes2,
        baseCache3(link5),
        /** @type {API.MultibaseEncoder<"z">} */
        base4 || base58btc3.encoder
      );
    default:
      return toStringV13(
        bytes2,
        baseCache3(link5),
        /** @type {API.MultibaseEncoder<Prefix>} */
        base4 || base323.encoder
      );
  }
};
var cache3 = /* @__PURE__ */ new WeakMap();
var baseCache3 = (cid) => {
  const baseCache4 = cache3.get(cid);
  if (baseCache4 == null) {
    const baseCache5 = /* @__PURE__ */ new Map();
    cache3.set(cid, baseCache5);
    return baseCache5;
  }
  return baseCache4;
};
var CID3 = class _CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   */
  constructor(version2, code19, multihash, bytes2) {
    this.code = code19;
    this.version = version2;
    this.multihash = multihash;
    this.bytes = bytes2;
    this["/"] = bytes2;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0() {
    switch (this.version) {
      case 0: {
        return (
          /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */
          this
        );
      }
      case 1: {
        const { code: code19, multihash } = this;
        if (code19 !== DAG_PB_CODE4) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE3) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return (
          /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */
          _CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */
            multihash
          )
        );
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        );
      }
    }
  }
  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code19, digest: digest5 } = this.multihash;
        const multihash = create9(code19, digest5);
        return (
          /** @type {CID<Data, Format, Alg, 1>} */
          _CID.createV1(this.code, multihash)
        );
      }
      case 1: {
        return (
          /** @type {CID<Data, Format, Alg, 1>} */
          this
        );
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        );
      }
    }
  }
  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals(other) {
    return _CID.equals(this, other);
  }
  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals(self2, other) {
    const unknown2 = (
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */
      other
    );
    return unknown2 && self2.code === unknown2.code && self2.version === unknown2.version && equals7(self2.multihash, unknown2.multihash);
  }
  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString(base4) {
    return format8(this, base4);
  }
  /**
   * @returns {API.LinkJSON<this>}
   */
  toJSON() {
    return { "/": format8(this) };
  }
  link() {
    return this;
  }
  get [Symbol.toStringTag]() {
    return "CID";
  }
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID(input10) {
    if (input10 == null) {
      return null;
    }
    const value = (
      /** @type {any} */
      input10
    );
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version: version2, code: code19, multihash, bytes: bytes2 } = value;
      return new _CID(
        version2,
        code19,
        /** @type {API.MultihashDigest<Alg>} */
        multihash,
        bytes2 || encodeCID3(version2, code19, multihash.bytes)
      );
    } else if (value[cidSymbol3] === true) {
      const { version: version2, multihash, code: code19 } = value;
      const digest5 = (
        /** @type {API.MultihashDigest<Alg>} */
        decode28(multihash)
      );
      return _CID.create(version2, code19, digest5);
    } else {
      return null;
    }
  }
  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create(version2, code19, digest5) {
    if (typeof code19 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest5.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version2) {
      case 0: {
        if (code19 !== DAG_PB_CODE4) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE4}) block encoding`
          );
        } else {
          return new _CID(version2, code19, digest5, digest5.bytes);
        }
      }
      case 1: {
        const bytes2 = encodeCID3(version2, code19, digest5.bytes);
        return new _CID(version2, code19, digest5, bytes2);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0(digest5) {
    return _CID.create(0, DAG_PB_CODE4, digest5);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1(code19, digest5) {
    return _CID.create(1, code19, digest5);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode(bytes2) {
    const [cid, remainder] = _CID.decodeFirst(bytes2);
    if (remainder.length) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst(bytes2) {
    const specs = _CID.inspectBytes(bytes2);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce3(
      bytes2.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest5 = new Digest5(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid = specs.version === 0 ? _CID.createV0(
      /** @type {API.MultihashDigest<API.SHA_256>} */
      digest5
    ) : _CID.createV1(specs.codec, digest5);
    return [
      /** @type {CID<T, C, A, V>} */
      cid,
      bytes2.subarray(specs.size)
    ];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes(initialBytes) {
    let offset2 = 0;
    const next = () => {
      const [i, length4] = decode27(initialBytes.subarray(offset2));
      offset2 += length4;
      return i;
    };
    let version2 = (
      /** @type {V} */
      next()
    );
    let codec = (
      /** @type {C} */
      DAG_PB_CODE4
    );
    if (
      /** @type {number} */
      version2 === 18
    ) {
      version2 = /** @type {V} */
      0;
      offset2 = 0;
    } else {
      codec = /** @type {C} */
      next();
    }
    if (version2 !== 0 && version2 !== 1) {
      throw new RangeError(`Invalid CID version ${version2}`);
    }
    const prefixSize = offset2;
    const multihashCode = (
      /** @type {A} */
      next()
    );
    const digestSize = next();
    const size5 = offset2 + digestSize;
    const multihashSize = size5 - prefixSize;
    return { version: version2, codec, multihashCode, digestSize, multihashSize, size: size5 };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse(source, base4) {
    const [prefix2, bytes2] = parseCIDtoBytes3(source, base4);
    const cid = _CID.decode(bytes2);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache3(cid).set(prefix2, source);
    return cid;
  }
};
var parseCIDtoBytes3 = (source, base4) => {
  switch (source[0]) {
    case "Q": {
      const decoder3 = base4 || base58btc3;
      return [
        /** @type {Prefix} */
        base58btc3.prefix,
        decoder3.decode(`${base58btc3.prefix}${source}`)
      ];
    }
    case base58btc3.prefix: {
      const decoder3 = base4 || base58btc3;
      return [
        /** @type {Prefix} */
        base58btc3.prefix,
        decoder3.decode(source)
      ];
    }
    case base323.prefix: {
      const decoder3 = base4 || base323;
      return [
        /** @type {Prefix} */
        base323.prefix,
        decoder3.decode(source)
      ];
    }
    default: {
      if (base4 == null) {
        throw Error(
          "To parse non base32 or base58btc encoded CID multibase decoder must be provided"
        );
      }
      return [
        /** @type {Prefix} */
        source[0],
        base4.decode(source)
      ];
    }
  }
};
var toStringV03 = (bytes2, cache5, base4) => {
  const { prefix: prefix2 } = base4;
  if (prefix2 !== base58btc3.prefix) {
    throw Error(`Cannot string encode V0 in ${base4.name} encoding`);
  }
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2).slice(1);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
};
var toStringV13 = (bytes2, cache5, base4) => {
  const { prefix: prefix2 } = base4;
  const cid = cache5.get(prefix2);
  if (cid == null) {
    const cid2 = base4.encode(bytes2);
    cache5.set(prefix2, cid2);
    return cid2;
  } else {
    return cid;
  }
};
var DAG_PB_CODE4 = 112;
var SHA_256_CODE3 = 18;
var encodeCID3 = (version2, code19, multihash) => {
  const codeOffset = encodingLength3(version2);
  const hashOffset = codeOffset + encodingLength3(code19);
  const bytes2 = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo3(version2, bytes2, 0);
  encodeTo3(code19, bytes2, codeOffset);
  bytes2.set(multihash, hashOffset);
  return bytes2;
};
var cidSymbol3 = Symbol.for("@ipld/js-cid/CID");

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/link.js
var create10 = (code19, digest5) => CID3.create(1, code19, digest5);

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/codecs/raw.js
var raw_exports2 = {};
__export(raw_exports2, {
  code: () => code10,
  decode: () => decode29,
  encode: () => encode22,
  name: () => name7
});
var name7 = "raw";
var code10 = 85;
var encode22 = (node) => coerce3(node);
var decode29 = (data) => coerce3(data);

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/hashes/hasher.js
var from12 = ({ name: name14, code: code19, encode: encode34 }) => new Hasher4(name14, code19, encode34);
var Hasher4 = class {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor(name14, code19, encode34) {
    this.name = name14;
    this.code = code19;
    this.encode = encode34;
  }
  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest(input10) {
    if (input10 instanceof Uint8Array) {
      const result = this.encode(input10);
      return result instanceof Uint8Array ? create9(this.code, result) : result.then((digest5) => create9(this.code, digest5));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// ../../node_modules/.pnpm/multiformats@12.1.3/node_modules/multiformats/src/hashes/sha2-browser.js
var sha2 = (name14) => (
  /**
   * @param {Uint8Array} data
   */
  async (data) => new Uint8Array(await crypto.subtle.digest(name14, data))
);
var sha2563 = from12({
  name: "sha2-256",
  code: 18,
  encode: sha2("SHA-256")
});
var sha5122 = from12({
  name: "sha2-512",
  code: 19,
  encode: sha2("SHA-512")
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/store.js
var store_exports = {};
__export(store_exports, {
  add: () => add2,
  get: () => get3,
  list: () => list2,
  remove: () => remove2
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/utils.js
var ProviderDID2 = did_exports2.match({ method: "web" });
var SpaceDID2 = did_exports2.match({ method: "key" });
var AccountDID2 = did_exports2.match({ method: "mailto" });
var Await2 = schema_exports3.struct({
  "ucan/await": schema_exports3.tuple([schema_exports3.string(), schema_exports3.link()])
});
function equalWith2(child, parent) {
  return child.with === parent.with ? ok({}) : fail2(`Can not derive ${child.can} with ${child.with} from ${parent.with}`);
}
function equal2(child, parent, constraint) {
  if (parent === void 0 || parent === "*") {
    return ok({});
  } else if (String(child) === String(parent)) {
    return ok({});
  } else {
    return fail2(
      `Constrain violation: ${child} violates imposed ${constraint} constraint ${parent}`
    );
  }
}
var equalLink = (claimed, delegated) => {
  if (claimed.with !== delegated.with) {
    return fail2(
      `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
    );
  } else if (delegated.nb.link && `${delegated.nb.link}` !== `${claimed.nb.link}`) {
    return fail2(
      `Link ${claimed.nb.link ? `${claimed.nb.link}` : ""} violates imposed ${delegated.nb.link} constraint.`
    );
  } else {
    return ok({});
  }
};
var equalBlob = (claimed, delegated) => {
  if (claimed.with !== delegated.with) {
    return fail2(
      `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
    );
  } else if (delegated.nb.blob.digest && !equals5(delegated.nb.blob.digest, claimed.nb.blob.digest)) {
    return fail2(
      `Link ${claimed.nb.blob.digest ? `${claimed.nb.blob.digest}` : ""} violates imposed ${delegated.nb.blob.digest} constraint.`
    );
  } else if (claimed.nb.blob.size !== void 0 && delegated.nb.blob.size !== void 0) {
    return claimed.nb.blob.size > delegated.nb.blob.size ? fail2(
      `Size constraint violation: ${claimed.nb.blob.size} > ${delegated.nb.blob.size}`
    ) : ok({});
  } else {
    return ok({});
  }
};
var equalBody = (claimed, delegated) => {
  if (claimed.with !== delegated.with) {
    return fail2(
      `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
    );
  } else if (delegated.nb.body.digest && !equals5(delegated.nb.body.digest, claimed.nb.body.digest)) {
    return fail2(
      `Link ${claimed.nb.body.digest ? `${claimed.nb.body.digest}` : ""} violates imposed ${delegated.nb.body.digest} constraint.`
    );
  } else if (claimed.nb.body.size !== void 0 && delegated.nb.body.size !== void 0) {
    return claimed.nb.body.size > delegated.nb.body.size ? fail2(
      `Size constraint violation: ${claimed.nb.body.size} > ${delegated.nb.body.size}`
    ) : ok({});
  } else {
    return ok({});
  }
};
var checkLink2 = (claimed, imposed, at2) => {
  return equal2(
    String(claimed),
    imposed === void 0 ? void 0 : String(imposed),
    at2
  );
};
var and4 = (result) => result.error ? result : void 0;

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/store.js
var code11 = 514;
var CARLink = schema_exports3.link({ code: code11, version: 1 });
var store = capability({
  can: "store/*",
  /**
   * DID of the (memory) space where CAR is intended to
   * be stored.
   */
  with: SpaceDID2,
  derives: equalWith2
});
var add = capability({
  can: "store/add",
  /**
   * DID of the (memory) space where CAR is intended to
   * be stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * CID of the CAR file to be stored. Service will provision write target
     * for this exact CAR file for agent to PUT or POST it. Attempt to write
     * any other content will fail.
     */
    link: CARLink,
    /**
     * Size of the CAR file to be stored. Service will provision write target
     * for this exact size. Attempt to write a larger CAR file will fail.
     */
    size: schema_exports3.integer(),
    /**
     * Agent may optionally provide a link to a related CAR file using `origin`
     * field. This is useful when storing large DAGs, agent could shard it
     * across multiple CAR files and then link each shard with a previous one.
     *
     * Providing this relation tells service that given CAR is shard of the
     * larger DAG as opposed to it being intentionally partial DAG. When DAG is
     * not sharded, there will be only one `store/add` with `origin` left out.
     */
    origin: link_exports2.optional()
  }),
  derives: (claim, from19) => {
    const result = equalLink(claim, from19);
    if (result.error) {
      return result;
    } else if (claim.nb.size !== void 0 && from19.nb.size !== void 0) {
      return claim.nb.size > from19.nb.size ? fail2(`Size constraint violation: ${claim.nb.size} > ${from19.nb.size}`) : ok({});
    } else {
      return ok({});
    }
  }
});
var get2 = capability({
  can: "store/get",
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * shard CID to fetch info about.
     */
    link: CARLink.optional()
  }),
  derives: equalLink
});
var remove = capability({
  can: "store/remove",
  /**
   * DID of the (memory) space where CAR is intended to
   * be stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * CID of the CAR file to be removed from the store.
     */
    link: CARLink
  }),
  derives: equalLink
});
var list = capability({
  can: "store/list",
  /**
   * DID of the (memory) space where CAR is intended to
   * be stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * A pointer that can be moved back and forth on the list.
     * It can be used to paginate a list for instance.
     */
    cursor: schema_exports3.string().optional(),
    /**
     * Maximum number of items per page.
     */
    size: schema_exports3.integer().optional(),
    /**
     * If true, return page of results preceding cursor. Defaults to false.
     */
    pre: schema_exports3.boolean().optional()
  }),
  derives: (claimed, delegated) => {
    if (claimed.with !== delegated.with) {
      return fail2(
        `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
      );
    }
    return ok({});
  }
});
var all = add.or(remove).or(list);

// ../../node_modules/.pnpm/p-retry@5.1.2/node_modules/p-retry/index.js
var import_retry = __toESM(require_retry2(), 1);
var networkErrorMsgs = /* @__PURE__ */ new Set([
  "Failed to fetch",
  // Chrome
  "NetworkError when attempting to fetch resource.",
  // Firefox
  "The Internet connection appears to be offline.",
  // Safari
  "Network request failed",
  // `cross-fetch`
  "fetch failed"
  // Undici (Node.js)
]);
var AbortError = class extends Error {
  constructor(message) {
    super();
    if (message instanceof Error) {
      this.originalError = message;
      ({ message } = message);
    } else {
      this.originalError = new Error(message);
      this.originalError.stack = this.stack;
    }
    this.name = "AbortError";
    this.message = message;
  }
};
var decorateErrorWithCounts = (error3, attemptNumber, options) => {
  const retriesLeft = options.retries - (attemptNumber - 1);
  error3.attemptNumber = attemptNumber;
  error3.retriesLeft = retriesLeft;
  return error3;
};
var isNetworkError = (errorMessage) => networkErrorMsgs.has(errorMessage);
var getDOMException = (errorMessage) => globalThis.DOMException === void 0 ? new Error(errorMessage) : new DOMException(errorMessage);
async function pRetry(input10, options) {
  return new Promise((resolve, reject) => {
    options = {
      onFailedAttempt() {
      },
      retries: 10,
      ...options
    };
    const operation = import_retry.default.operation(options);
    operation.attempt(async (attemptNumber) => {
      try {
        resolve(await input10(attemptNumber));
      } catch (error3) {
        if (!(error3 instanceof Error)) {
          reject(new TypeError(`Non-error was thrown: "${error3}". You should only throw errors.`));
          return;
        }
        if (error3 instanceof AbortError) {
          operation.stop();
          reject(error3.originalError);
        } else if (error3 instanceof TypeError && !isNetworkError(error3.message)) {
          operation.stop();
          reject(error3);
        } else {
          decorateErrorWithCounts(error3, attemptNumber, options);
          try {
            await options.onFailedAttempt(error3);
          } catch (error4) {
            reject(error4);
            return;
          }
          if (!operation.retry(error3)) {
            reject(operation.mainError());
          }
        }
      }
    });
    if (options.signal && !options.signal.aborted) {
      options.signal.addEventListener("abort", () => {
        operation.stop();
        const reason = options.signal.reason === void 0 ? getDOMException("The operation was aborted.") : options.signal.reason;
        reject(reason instanceof Error ? reason : getDOMException(reason));
      }, {
        once: true
      });
    }
  });
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/service.js
var serviceURL = new URL("https://up.web3.storage");
var servicePrincipal = parse2("did:web:web3.storage");
var receiptsEndpoint = "https://up.web3.storage/receipt/";
var connection5 = connect({
  id: servicePrincipal,
  codec: car_exports2.outbound,
  channel: http_exports.open({
    url: serviceURL,
    method: "POST"
  })
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/constants.js
var REQUEST_RETRIES = 3;

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/store.js
function createUploadProgressHandler(url, handler) {
  function onUploadProgress({ total, loaded, lengthComputable }) {
    return handler({ total, loaded, lengthComputable, url });
  }
  return onUploadProgress;
}
async function add2({ issuer, with: resource, proofs: proofs2, audience }, car, options = {}) {
  const bytes2 = car instanceof Uint8Array ? car : new Uint8Array(await car.arrayBuffer());
  const link5 = await car_exports2.codec.link(bytes2);
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await add.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: { link: link5, size: bytes2.length },
      proofs: proofs2,
      nonce: options.nonce
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${add.can} invocation`, {
      cause: result.out.error
    });
  }
  if (result.out.ok.status === "done") {
    return link5;
  }
  const responseAddUpload = result.out.ok;
  const fetchWithUploadProgress = options.fetchWithUploadProgress || options.fetch || globalThis.fetch.bind(globalThis);
  let fetchDidCallUploadProgressCb = false;
  const res = await pRetry(async () => {
    try {
      const res2 = await fetchWithUploadProgress(responseAddUpload.url, {
        method: "PUT",
        body: car,
        headers: responseAddUpload.headers,
        signal: options.signal,
        onUploadProgress: (status) => {
          fetchDidCallUploadProgressCb = true;
          if (options.onUploadProgress)
            createUploadProgressHandler(responseAddUpload.url, options.onUploadProgress)(status);
        },
        // @ts-expect-error - this is needed by recent versions of node - see https://github.com/bluesky-social/atproto/pull/470 for more info
        duplex: "half"
      });
      if (res2.status >= 400 && res2.status < 500) {
        throw new AbortError(`upload failed: ${res2.status}`);
      }
      return res2;
    } catch (err) {
      if (options.signal?.aborted === true) {
        throw new AbortError("upload aborted");
      }
      throw err;
    }
  }, {
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!fetchDidCallUploadProgressCb && options.onUploadProgress) {
    const carBlob = new Blob([car]);
    options.onUploadProgress({
      total: carBlob.size,
      loaded: carBlob.size,
      lengthComputable: false
    });
  }
  if (!res.ok) {
    throw new Error(`upload failed: ${res.status}`);
  }
  return link5;
}
async function get3({ issuer, with: resource, proofs: proofs2, audience }, link5, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await get2.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: { link: link5 },
      proofs: proofs2,
      nonce: options.nonce
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${get2.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
async function list2({ issuer, with: resource, proofs: proofs2, audience }, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await list.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    proofs: proofs2,
    nb: {
      cursor: options.cursor,
      size: options.size,
      pre: options.pre
    },
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${list.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
async function remove2({ issuer, with: resource, proofs: proofs2, audience }, link5, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await remove.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    nb: { link: link5 },
    proofs: proofs2,
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${remove.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out;
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/blob/index.js
var blob_exports3 = {};
__export(blob_exports3, {
  add: () => add4,
  get: () => get6,
  list: () => list4,
  remove: () => remove4
});

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/ed25519.js
var ed25519_exports = {};
__export(ed25519_exports, {
  PUB_KEY_OFFSET: () => PUB_KEY_OFFSET,
  Signer: () => signer_exports,
  Verifier: () => verifier_exports,
  code: () => code13,
  decode: () => decode31,
  derive: () => derive2,
  encode: () => encode24,
  format: () => format10,
  from: () => from13,
  generate: () => generate,
  name: () => name9,
  or: () => or9,
  parse: () => parse6,
  signatureAlgorithm: () => signatureAlgorithm2,
  signatureCode: () => signatureCode2
});

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/ed25519/signer.js
var signer_exports = {};
__export(signer_exports, {
  PUB_KEY_OFFSET: () => PUB_KEY_OFFSET,
  code: () => code13,
  decode: () => decode31,
  derive: () => derive2,
  encode: () => encode24,
  format: () => format10,
  from: () => from13,
  generate: () => generate,
  name: () => name9,
  or: () => or9,
  parse: () => parse6,
  signatureAlgorithm: () => signatureAlgorithm2,
  signatureCode: () => signatureCode2
});

// ../../node_modules/.pnpm/@noble+ed25519@1.7.3/node_modules/@noble/ed25519/lib/esm/index.js
init_empty();
var _0n = BigInt(0);
var _1n = BigInt(1);
var _2n = BigInt(2);
var _8n = BigInt(8);
var CU_O = BigInt("7237005577332262213973186563042994240857116359379907606001950938285454250989");
var CURVE = Object.freeze({
  a: BigInt(-1),
  d: BigInt("37095705934669439343138083508754565189542113879843219016388785533085940283555"),
  P: BigInt("57896044618658097711785492504343953926634992332820282019728792003956564819949"),
  l: CU_O,
  n: CU_O,
  h: BigInt(8),
  Gx: BigInt("15112221349535400772501151409588531511454012693041857206046113283949847762202"),
  Gy: BigInt("46316835694926478169428394003475163141307993866256225615783033603165251855960")
});
var POW_2_256 = BigInt("0x10000000000000000000000000000000000000000000000000000000000000000");
var SQRT_M1 = BigInt("19681161376707505956807079304988542015446066515923890162744021073123829784752");
var SQRT_D = BigInt("6853475219497561581579357271197624642482790079785650197046958215289687604742");
var SQRT_AD_MINUS_ONE = BigInt("25063068953384623474111414158702152701244531502492656460079210482610430750235");
var INVSQRT_A_MINUS_D = BigInt("54469307008909316920995813868745141605393597292927456921205312896311721017578");
var ONE_MINUS_D_SQ = BigInt("1159843021668779879193775521855586647937357759715417654439879720876111806838");
var D_MINUS_ONE_SQ = BigInt("40440834346308536858101042469323190826248399146238708352240133220865137265952");
var ExtendedPoint = class _ExtendedPoint {
  constructor(x, y, z, t) {
    this.x = x;
    this.y = y;
    this.z = z;
    this.t = t;
  }
  static fromAffine(p) {
    if (!(p instanceof Point)) {
      throw new TypeError("ExtendedPoint#fromAffine: expected Point");
    }
    if (p.equals(Point.ZERO))
      return _ExtendedPoint.ZERO;
    return new _ExtendedPoint(p.x, p.y, _1n, mod(p.x * p.y));
  }
  static toAffineBatch(points) {
    const toInv = invertBatch(points.map((p) => p.z));
    return points.map((p, i) => p.toAffine(toInv[i]));
  }
  static normalizeZ(points) {
    return this.toAffineBatch(points).map(this.fromAffine);
  }
  equals(other) {
    assertExtPoint(other);
    const { x: X1, y: Y1, z: Z1 } = this;
    const { x: X2, y: Y2, z: Z2 } = other;
    const X1Z2 = mod(X1 * Z2);
    const X2Z1 = mod(X2 * Z1);
    const Y1Z2 = mod(Y1 * Z2);
    const Y2Z1 = mod(Y2 * Z1);
    return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
  }
  negate() {
    return new _ExtendedPoint(mod(-this.x), this.y, this.z, mod(-this.t));
  }
  double() {
    const { x: X1, y: Y1, z: Z1 } = this;
    const { a } = CURVE;
    const A = mod(X1 * X1);
    const B = mod(Y1 * Y1);
    const C = mod(_2n * mod(Z1 * Z1));
    const D = mod(a * A);
    const x1y1 = X1 + Y1;
    const E = mod(mod(x1y1 * x1y1) - A - B);
    const G = D + B;
    const F = G - C;
    const H = D - B;
    const X3 = mod(E * F);
    const Y3 = mod(G * H);
    const T3 = mod(E * H);
    const Z3 = mod(F * G);
    return new _ExtendedPoint(X3, Y3, Z3, T3);
  }
  add(other) {
    assertExtPoint(other);
    const { x: X1, y: Y1, z: Z1, t: T1 } = this;
    const { x: X2, y: Y2, z: Z2, t: T2 } = other;
    const A = mod((Y1 - X1) * (Y2 + X2));
    const B = mod((Y1 + X1) * (Y2 - X2));
    const F = mod(B - A);
    if (F === _0n)
      return this.double();
    const C = mod(Z1 * _2n * T2);
    const D = mod(T1 * _2n * Z2);
    const E = D + C;
    const G = B + A;
    const H = D - C;
    const X3 = mod(E * F);
    const Y3 = mod(G * H);
    const T3 = mod(E * H);
    const Z3 = mod(F * G);
    return new _ExtendedPoint(X3, Y3, Z3, T3);
  }
  subtract(other) {
    return this.add(other.negate());
  }
  precomputeWindow(W) {
    const windows = 1 + 256 / W;
    const points = [];
    let p = this;
    let base4 = p;
    for (let window2 = 0; window2 < windows; window2++) {
      base4 = p;
      points.push(base4);
      for (let i = 1; i < 2 ** (W - 1); i++) {
        base4 = base4.add(p);
        points.push(base4);
      }
      p = base4.double();
    }
    return points;
  }
  wNAF(n, affinePoint) {
    if (!affinePoint && this.equals(_ExtendedPoint.BASE))
      affinePoint = Point.BASE;
    const W = affinePoint && affinePoint._WINDOW_SIZE || 1;
    if (256 % W) {
      throw new Error("Point#wNAF: Invalid precomputation window, must be power of 2");
    }
    let precomputes = affinePoint && pointPrecomputes.get(affinePoint);
    if (!precomputes) {
      precomputes = this.precomputeWindow(W);
      if (affinePoint && W !== 1) {
        precomputes = _ExtendedPoint.normalizeZ(precomputes);
        pointPrecomputes.set(affinePoint, precomputes);
      }
    }
    let p = _ExtendedPoint.ZERO;
    let f = _ExtendedPoint.BASE;
    const windows = 1 + 256 / W;
    const windowSize = 2 ** (W - 1);
    const mask2 = BigInt(2 ** W - 1);
    const maxNumber = 2 ** W;
    const shiftBy = BigInt(W);
    for (let window2 = 0; window2 < windows; window2++) {
      const offset2 = window2 * windowSize;
      let wbits = Number(n & mask2);
      n >>= shiftBy;
      if (wbits > windowSize) {
        wbits -= maxNumber;
        n += _1n;
      }
      const offset1 = offset2;
      const offset22 = offset2 + Math.abs(wbits) - 1;
      const cond1 = window2 % 2 !== 0;
      const cond2 = wbits < 0;
      if (wbits === 0) {
        f = f.add(constTimeNegate(cond1, precomputes[offset1]));
      } else {
        p = p.add(constTimeNegate(cond2, precomputes[offset22]));
      }
    }
    return _ExtendedPoint.normalizeZ([p, f])[0];
  }
  multiply(scalar, affinePoint) {
    return this.wNAF(normalizeScalar(scalar, CURVE.l), affinePoint);
  }
  multiplyUnsafe(scalar) {
    let n = normalizeScalar(scalar, CURVE.l, false);
    const G = _ExtendedPoint.BASE;
    const P0 = _ExtendedPoint.ZERO;
    if (n === _0n)
      return P0;
    if (this.equals(P0) || n === _1n)
      return this;
    if (this.equals(G))
      return this.wNAF(n);
    let p = P0;
    let d = this;
    while (n > _0n) {
      if (n & _1n)
        p = p.add(d);
      d = d.double();
      n >>= _1n;
    }
    return p;
  }
  isSmallOrder() {
    return this.multiplyUnsafe(CURVE.h).equals(_ExtendedPoint.ZERO);
  }
  isTorsionFree() {
    let p = this.multiplyUnsafe(CURVE.l / _2n).double();
    if (CURVE.l % _2n)
      p = p.add(this);
    return p.equals(_ExtendedPoint.ZERO);
  }
  toAffine(invZ) {
    const { x, y, z } = this;
    const is0 = this.equals(_ExtendedPoint.ZERO);
    if (invZ == null)
      invZ = is0 ? _8n : invert(z);
    const ax = mod(x * invZ);
    const ay = mod(y * invZ);
    const zz = mod(z * invZ);
    if (is0)
      return Point.ZERO;
    if (zz !== _1n)
      throw new Error("invZ was invalid");
    return new Point(ax, ay);
  }
  fromRistrettoBytes() {
    legacyRist();
  }
  toRistrettoBytes() {
    legacyRist();
  }
  fromRistrettoHash() {
    legacyRist();
  }
};
ExtendedPoint.BASE = new ExtendedPoint(CURVE.Gx, CURVE.Gy, _1n, mod(CURVE.Gx * CURVE.Gy));
ExtendedPoint.ZERO = new ExtendedPoint(_0n, _1n, _1n, _0n);
function constTimeNegate(condition, item) {
  const neg = item.negate();
  return condition ? neg : item;
}
function assertExtPoint(other) {
  if (!(other instanceof ExtendedPoint))
    throw new TypeError("ExtendedPoint expected");
}
function assertRstPoint(other) {
  if (!(other instanceof RistrettoPoint))
    throw new TypeError("RistrettoPoint expected");
}
function legacyRist() {
  throw new Error("Legacy method: switch to RistrettoPoint");
}
var RistrettoPoint = class _RistrettoPoint {
  constructor(ep) {
    this.ep = ep;
  }
  static calcElligatorRistrettoMap(r0) {
    const { d } = CURVE;
    const r = mod(SQRT_M1 * r0 * r0);
    const Ns = mod((r + _1n) * ONE_MINUS_D_SQ);
    let c = BigInt(-1);
    const D = mod((c - d * r) * mod(r + d));
    let { isValid: Ns_D_is_sq, value: s } = uvRatio(Ns, D);
    let s_ = mod(s * r0);
    if (!edIsNegative(s_))
      s_ = mod(-s_);
    if (!Ns_D_is_sq)
      s = s_;
    if (!Ns_D_is_sq)
      c = r;
    const Nt = mod(c * (r - _1n) * D_MINUS_ONE_SQ - D);
    const s2 = s * s;
    const W0 = mod((s + s) * D);
    const W1 = mod(Nt * SQRT_AD_MINUS_ONE);
    const W2 = mod(_1n - s2);
    const W3 = mod(_1n + s2);
    return new ExtendedPoint(mod(W0 * W3), mod(W2 * W1), mod(W1 * W3), mod(W0 * W2));
  }
  static hashToCurve(hex) {
    hex = ensureBytes(hex, 64);
    const r1 = bytes255ToNumberLE(hex.slice(0, 32));
    const R1 = this.calcElligatorRistrettoMap(r1);
    const r2 = bytes255ToNumberLE(hex.slice(32, 64));
    const R2 = this.calcElligatorRistrettoMap(r2);
    return new _RistrettoPoint(R1.add(R2));
  }
  static fromHex(hex) {
    hex = ensureBytes(hex, 32);
    const { a, d } = CURVE;
    const emsg = "RistrettoPoint.fromHex: the hex is not valid encoding of RistrettoPoint";
    const s = bytes255ToNumberLE(hex);
    if (!equalBytes(numberTo32BytesLE(s), hex) || edIsNegative(s))
      throw new Error(emsg);
    const s2 = mod(s * s);
    const u1 = mod(_1n + a * s2);
    const u2 = mod(_1n - a * s2);
    const u1_2 = mod(u1 * u1);
    const u2_2 = mod(u2 * u2);
    const v = mod(a * d * u1_2 - u2_2);
    const { isValid, value: I } = invertSqrt(mod(v * u2_2));
    const Dx = mod(I * u2);
    const Dy = mod(I * Dx * v);
    let x = mod((s + s) * Dx);
    if (edIsNegative(x))
      x = mod(-x);
    const y = mod(u1 * Dy);
    const t = mod(x * y);
    if (!isValid || edIsNegative(t) || y === _0n)
      throw new Error(emsg);
    return new _RistrettoPoint(new ExtendedPoint(x, y, _1n, t));
  }
  toRawBytes() {
    let { x, y, z, t } = this.ep;
    const u1 = mod(mod(z + y) * mod(z - y));
    const u2 = mod(x * y);
    const u2sq = mod(u2 * u2);
    const { value: invsqrt } = invertSqrt(mod(u1 * u2sq));
    const D1 = mod(invsqrt * u1);
    const D2 = mod(invsqrt * u2);
    const zInv = mod(D1 * D2 * t);
    let D;
    if (edIsNegative(t * zInv)) {
      let _x = mod(y * SQRT_M1);
      let _y = mod(x * SQRT_M1);
      x = _x;
      y = _y;
      D = mod(D1 * INVSQRT_A_MINUS_D);
    } else {
      D = D2;
    }
    if (edIsNegative(x * zInv))
      y = mod(-y);
    let s = mod((z - y) * D);
    if (edIsNegative(s))
      s = mod(-s);
    return numberTo32BytesLE(s);
  }
  toHex() {
    return bytesToHex(this.toRawBytes());
  }
  toString() {
    return this.toHex();
  }
  equals(other) {
    assertRstPoint(other);
    const a = this.ep;
    const b = other.ep;
    const one = mod(a.x * b.y) === mod(a.y * b.x);
    const two = mod(a.y * b.y) === mod(a.x * b.x);
    return one || two;
  }
  add(other) {
    assertRstPoint(other);
    return new _RistrettoPoint(this.ep.add(other.ep));
  }
  subtract(other) {
    assertRstPoint(other);
    return new _RistrettoPoint(this.ep.subtract(other.ep));
  }
  multiply(scalar) {
    return new _RistrettoPoint(this.ep.multiply(scalar));
  }
  multiplyUnsafe(scalar) {
    return new _RistrettoPoint(this.ep.multiplyUnsafe(scalar));
  }
};
RistrettoPoint.BASE = new RistrettoPoint(ExtendedPoint.BASE);
RistrettoPoint.ZERO = new RistrettoPoint(ExtendedPoint.ZERO);
var pointPrecomputes = /* @__PURE__ */ new WeakMap();
var Point = class _Point {
  constructor(x, y) {
    this.x = x;
    this.y = y;
  }
  _setWindowSize(windowSize) {
    this._WINDOW_SIZE = windowSize;
    pointPrecomputes.delete(this);
  }
  static fromHex(hex, strict = true) {
    const { d, P } = CURVE;
    hex = ensureBytes(hex, 32);
    const normed = hex.slice();
    normed[31] = hex[31] & ~128;
    const y = bytesToNumberLE(normed);
    if (strict && y >= P)
      throw new Error("Expected 0 < hex < P");
    if (!strict && y >= POW_2_256)
      throw new Error("Expected 0 < hex < 2**256");
    const y2 = mod(y * y);
    const u = mod(y2 - _1n);
    const v = mod(d * y2 + _1n);
    let { isValid, value: x } = uvRatio(u, v);
    if (!isValid)
      throw new Error("Point.fromHex: invalid y coordinate");
    const isXOdd = (x & _1n) === _1n;
    const isLastByteOdd = (hex[31] & 128) !== 0;
    if (isLastByteOdd !== isXOdd) {
      x = mod(-x);
    }
    return new _Point(x, y);
  }
  static async fromPrivateKey(privateKey) {
    return (await getExtendedPublicKey(privateKey)).point;
  }
  toRawBytes() {
    const bytes2 = numberTo32BytesLE(this.y);
    bytes2[31] |= this.x & _1n ? 128 : 0;
    return bytes2;
  }
  toHex() {
    return bytesToHex(this.toRawBytes());
  }
  toX25519() {
    const { y } = this;
    const u = mod((_1n + y) * invert(_1n - y));
    return numberTo32BytesLE(u);
  }
  isTorsionFree() {
    return ExtendedPoint.fromAffine(this).isTorsionFree();
  }
  equals(other) {
    return this.x === other.x && this.y === other.y;
  }
  negate() {
    return new _Point(mod(-this.x), this.y);
  }
  add(other) {
    return ExtendedPoint.fromAffine(this).add(ExtendedPoint.fromAffine(other)).toAffine();
  }
  subtract(other) {
    return this.add(other.negate());
  }
  multiply(scalar) {
    return ExtendedPoint.fromAffine(this).multiply(scalar, this).toAffine();
  }
};
Point.BASE = new Point(CURVE.Gx, CURVE.Gy);
Point.ZERO = new Point(_0n, _1n);
var Signature2 = class _Signature {
  constructor(r, s) {
    this.r = r;
    this.s = s;
    this.assertValidity();
  }
  static fromHex(hex) {
    const bytes2 = ensureBytes(hex, 64);
    const r = Point.fromHex(bytes2.slice(0, 32), false);
    const s = bytesToNumberLE(bytes2.slice(32, 64));
    return new _Signature(r, s);
  }
  assertValidity() {
    const { r, s } = this;
    if (!(r instanceof Point))
      throw new Error("Expected Point instance");
    normalizeScalar(s, CURVE.l, false);
    return this;
  }
  toRawBytes() {
    const u8 = new Uint8Array(64);
    u8.set(this.r.toRawBytes());
    u8.set(numberTo32BytesLE(this.s), 32);
    return u8;
  }
  toHex() {
    return bytesToHex(this.toRawBytes());
  }
};
function concatBytes(...arrays) {
  if (!arrays.every((a) => a instanceof Uint8Array))
    throw new Error("Expected Uint8Array list");
  if (arrays.length === 1)
    return arrays[0];
  const length4 = arrays.reduce((a, arr) => a + arr.length, 0);
  const result = new Uint8Array(length4);
  for (let i = 0, pad2 = 0; i < arrays.length; i++) {
    const arr = arrays[i];
    result.set(arr, pad2);
    pad2 += arr.length;
  }
  return result;
}
var hexes = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, "0"));
function bytesToHex(uint8a) {
  if (!(uint8a instanceof Uint8Array))
    throw new Error("Uint8Array expected");
  let hex = "";
  for (let i = 0; i < uint8a.length; i++) {
    hex += hexes[uint8a[i]];
  }
  return hex;
}
function hexToBytes(hex) {
  if (typeof hex !== "string") {
    throw new TypeError("hexToBytes: expected string, got " + typeof hex);
  }
  if (hex.length % 2)
    throw new Error("hexToBytes: received invalid unpadded hex");
  const array2 = new Uint8Array(hex.length / 2);
  for (let i = 0; i < array2.length; i++) {
    const j = i * 2;
    const hexByte = hex.slice(j, j + 2);
    const byte = Number.parseInt(hexByte, 16);
    if (Number.isNaN(byte) || byte < 0)
      throw new Error("Invalid byte sequence");
    array2[i] = byte;
  }
  return array2;
}
function numberTo32BytesBE(num) {
  const length4 = 32;
  const hex = num.toString(16).padStart(length4 * 2, "0");
  return hexToBytes(hex);
}
function numberTo32BytesLE(num) {
  return numberTo32BytesBE(num).reverse();
}
function edIsNegative(num) {
  return (mod(num) & _1n) === _1n;
}
function bytesToNumberLE(uint8a) {
  if (!(uint8a instanceof Uint8Array))
    throw new Error("Expected Uint8Array");
  return BigInt("0x" + bytesToHex(Uint8Array.from(uint8a).reverse()));
}
var MAX_255B = BigInt("0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff");
function bytes255ToNumberLE(bytes2) {
  return mod(bytesToNumberLE(bytes2) & MAX_255B);
}
function mod(a, b = CURVE.P) {
  const res = a % b;
  return res >= _0n ? res : b + res;
}
function invert(number2, modulo = CURVE.P) {
  if (number2 === _0n || modulo <= _0n) {
    throw new Error(`invert: expected positive integers, got n=${number2} mod=${modulo}`);
  }
  let a = mod(number2, modulo);
  let b = modulo;
  let x = _0n, y = _1n, u = _1n, v = _0n;
  while (a !== _0n) {
    const q = b / a;
    const r = b % a;
    const m = x - u * q;
    const n = y - v * q;
    b = a, a = r, x = u, y = v, u = m, v = n;
  }
  const gcd = b;
  if (gcd !== _1n)
    throw new Error("invert: does not exist");
  return mod(x, modulo);
}
function invertBatch(nums, p = CURVE.P) {
  const tmp = new Array(nums.length);
  const lastMultiplied = nums.reduce((acc, num, i) => {
    if (num === _0n)
      return acc;
    tmp[i] = acc;
    return mod(acc * num, p);
  }, _1n);
  const inverted = invert(lastMultiplied, p);
  nums.reduceRight((acc, num, i) => {
    if (num === _0n)
      return acc;
    tmp[i] = mod(acc * tmp[i], p);
    return mod(acc * num, p);
  }, inverted);
  return tmp;
}
function pow2(x, power) {
  const { P } = CURVE;
  let res = x;
  while (power-- > _0n) {
    res *= res;
    res %= P;
  }
  return res;
}
function pow_2_252_3(x) {
  const { P } = CURVE;
  const _5n = BigInt(5);
  const _10n = BigInt(10);
  const _20n = BigInt(20);
  const _40n = BigInt(40);
  const _80n = BigInt(80);
  const x2 = x * x % P;
  const b2 = x2 * x % P;
  const b4 = pow2(b2, _2n) * b2 % P;
  const b5 = pow2(b4, _1n) * x % P;
  const b10 = pow2(b5, _5n) * b5 % P;
  const b20 = pow2(b10, _10n) * b10 % P;
  const b40 = pow2(b20, _20n) * b20 % P;
  const b80 = pow2(b40, _40n) * b40 % P;
  const b160 = pow2(b80, _80n) * b80 % P;
  const b240 = pow2(b160, _80n) * b80 % P;
  const b250 = pow2(b240, _10n) * b10 % P;
  const pow_p_5_8 = pow2(b250, _2n) * x % P;
  return { pow_p_5_8, b2 };
}
function uvRatio(u, v) {
  const v3 = mod(v * v * v);
  const v7 = mod(v3 * v3 * v);
  const pow = pow_2_252_3(u * v7).pow_p_5_8;
  let x = mod(u * v3 * pow);
  const vx2 = mod(v * x * x);
  const root1 = x;
  const root2 = mod(x * SQRT_M1);
  const useRoot1 = vx2 === u;
  const useRoot2 = vx2 === mod(-u);
  const noRoot = vx2 === mod(-u * SQRT_M1);
  if (useRoot1)
    x = root1;
  if (useRoot2 || noRoot)
    x = root2;
  if (edIsNegative(x))
    x = mod(-x);
  return { isValid: useRoot1 || useRoot2, value: x };
}
function invertSqrt(number2) {
  return uvRatio(_1n, number2);
}
function modlLE(hash) {
  return mod(bytesToNumberLE(hash), CURVE.l);
}
function equalBytes(b1, b2) {
  if (b1.length !== b2.length) {
    return false;
  }
  for (let i = 0; i < b1.length; i++) {
    if (b1[i] !== b2[i]) {
      return false;
    }
  }
  return true;
}
function ensureBytes(hex, expectedLength) {
  const bytes2 = hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes(hex);
  if (typeof expectedLength === "number" && bytes2.length !== expectedLength)
    throw new Error(`Expected ${expectedLength} bytes`);
  return bytes2;
}
function normalizeScalar(num, max, strict = true) {
  if (!max)
    throw new TypeError("Specify max value");
  if (typeof num === "number" && Number.isSafeInteger(num))
    num = BigInt(num);
  if (typeof num === "bigint" && num < max) {
    if (strict) {
      if (_0n < num)
        return num;
    } else {
      if (_0n <= num)
        return num;
    }
  }
  throw new TypeError("Expected valid scalar: 0 < scalar < max");
}
function adjustBytes25519(bytes2) {
  bytes2[0] &= 248;
  bytes2[31] &= 127;
  bytes2[31] |= 64;
  return bytes2;
}
function checkPrivateKey(key) {
  key = typeof key === "bigint" || typeof key === "number" ? numberTo32BytesBE(normalizeScalar(key, POW_2_256)) : ensureBytes(key);
  if (key.length !== 32)
    throw new Error(`Expected 32 bytes`);
  return key;
}
function getKeyFromHash(hashed) {
  const head = adjustBytes25519(hashed.slice(0, 32));
  const prefix2 = hashed.slice(32, 64);
  const scalar = modlLE(head);
  const point = Point.BASE.multiply(scalar);
  const pointBytes = point.toRawBytes();
  return { head, prefix: prefix2, scalar, point, pointBytes };
}
var _sha512Sync;
async function getExtendedPublicKey(key) {
  return getKeyFromHash(await utils.sha512(checkPrivateKey(key)));
}
async function getPublicKey(privateKey) {
  return (await getExtendedPublicKey(privateKey)).pointBytes;
}
async function sign(message, privateKey) {
  message = ensureBytes(message);
  const { prefix: prefix2, scalar, pointBytes } = await getExtendedPublicKey(privateKey);
  const r = modlLE(await utils.sha512(prefix2, message));
  const R = Point.BASE.multiply(r);
  const k = modlLE(await utils.sha512(R.toRawBytes(), pointBytes, message));
  const s = mod(r + k * scalar, CURVE.l);
  return new Signature2(R, s).toRawBytes();
}
function prepareVerification(sig, message, publicKey) {
  message = ensureBytes(message);
  if (!(publicKey instanceof Point))
    publicKey = Point.fromHex(publicKey, false);
  const { r, s } = sig instanceof Signature2 ? sig.assertValidity() : Signature2.fromHex(sig);
  const SB = ExtendedPoint.BASE.multiplyUnsafe(s);
  return { r, s, SB, pub: publicKey, msg: message };
}
function finishVerification(publicKey, r, SB, hashed) {
  const k = modlLE(hashed);
  const kA = ExtendedPoint.fromAffine(publicKey).multiplyUnsafe(k);
  const RkA = ExtendedPoint.fromAffine(r).add(kA);
  return RkA.subtract(SB).multiplyUnsafe(CURVE.h).equals(ExtendedPoint.ZERO);
}
async function verify(sig, message, publicKey) {
  const { r, SB, msg, pub } = prepareVerification(sig, message, publicKey);
  const hashed = await utils.sha512(r.toRawBytes(), pub.toRawBytes(), msg);
  return finishVerification(pub, r, SB, hashed);
}
Point.BASE._setWindowSize(8);
var crypto2 = {
  node: empty_exports,
  web: typeof self === "object" && "crypto" in self ? self.crypto : void 0
};
var utils = {
  bytesToHex,
  hexToBytes,
  concatBytes,
  getExtendedPublicKey,
  mod,
  invert,
  TORSION_SUBGROUP: [
    "0100000000000000000000000000000000000000000000000000000000000000",
    "c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac037a",
    "0000000000000000000000000000000000000000000000000000000000000080",
    "26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc05",
    "ecffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff7f",
    "26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc85",
    "0000000000000000000000000000000000000000000000000000000000000000",
    "c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac03fa"
  ],
  hashToPrivateScalar: (hash) => {
    hash = ensureBytes(hash);
    if (hash.length < 40 || hash.length > 1024)
      throw new Error("Expected 40-1024 bytes of private key as per FIPS 186");
    return mod(bytesToNumberLE(hash), CURVE.l - _1n) + _1n;
  },
  randomBytes: (bytesLength = 32) => {
    if (crypto2.web) {
      return crypto2.web.getRandomValues(new Uint8Array(bytesLength));
    } else if (crypto2.node) {
      const { randomBytes } = crypto2.node;
      return new Uint8Array(randomBytes(bytesLength).buffer);
    } else {
      throw new Error("The environment doesn't have randomBytes function");
    }
  },
  randomPrivateKey: () => {
    return utils.randomBytes(32);
  },
  sha512: async (...messages) => {
    const message = concatBytes(...messages);
    if (crypto2.web) {
      const buffer2 = await crypto2.web.subtle.digest("SHA-512", message.buffer);
      return new Uint8Array(buffer2);
    } else if (crypto2.node) {
      return Uint8Array.from(crypto2.node.createHash("sha512").update(message).digest());
    } else {
      throw new Error("The environment doesn't have sha512 function");
    }
  },
  precompute(windowSize = 8, point = Point.BASE) {
    const cached = point.equals(Point.BASE) ? point : new Point(point.x, point.y);
    cached._setWindowSize(windowSize);
    cached.multiply(_2n);
    return cached;
  },
  sha512Sync: void 0
};
Object.defineProperties(utils, {
  sha512Sync: {
    configurable: false,
    get() {
      return _sha512Sync;
    },
    set(val) {
      if (!_sha512Sync)
        _sha512Sync = val;
    }
  }
});

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/ed25519/verifier.js
var verifier_exports = {};
__export(verifier_exports, {
  code: () => code12,
  decode: () => decode30,
  encode: () => encode23,
  format: () => format9,
  name: () => name8,
  or: () => or7,
  parse: () => parse5,
  signatureAlgorithm: () => signatureAlgorithm,
  signatureCode: () => signatureCode
});

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/verifier.js
var parseWith = (did2, parsers) => {
  if (did2.startsWith("did:")) {
    for (const parser of parsers) {
      try {
        return parser.parse(did2);
      } catch (_) {
      }
    }
    throw new Error(`Unsupported did ${did2}`);
  } else {
    throw new Error(`Expected did instead got ${did2}`);
  }
};
var or6 = (left, right) => new Parser([left, right]);
var Parser = class _Parser {
  /**
   * @param {API.PrincipalParser[]} variants
   */
  constructor(variants) {
    this.variants = variants;
  }
  /**
   * @param {API.DID} did
   */
  parse(did2) {
    return parseWith(did2, this.variants);
  }
  /**
   * @param {API.PrincipalParser} parser
   */
  or(parser) {
    return new _Parser([...this.variants, parser]);
  }
};
var withDID = (key, id) => new VerifierWithDID(id, key);
var VerifierWithDID = class {
  /**
   * @param {ID} id
   * @param {API.VerifierKey<SigAlg>} key
   */
  constructor(id, key) {
    this.id = id;
    this.key = key;
  }
  did() {
    return this.id;
  }
  toDIDKey() {
    return this.key.toDIDKey();
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, SigAlg>} signature
   * @returns {API.Await<boolean>}
   */
  verify(payload, signature) {
    return this.key.verify(payload, signature);
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   */
  withDID(id) {
    return withDID(this.key, id);
  }
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/ed25519/verifier.js
var code12 = 237;
var name8 = "Ed25519";
var signatureCode = EdDSA;
var signatureAlgorithm = "EdDSA";
var PUBLIC_TAG_SIZE = varint_exports2.encodingLength(code12);
var SIZE = 32 + PUBLIC_TAG_SIZE;
var parse5 = (did2) => decode30(parse2(did2));
var decode30 = (bytes2) => {
  const [algorithm2] = varint_exports2.decode(bytes2);
  if (algorithm2 !== code12) {
    throw new RangeError(
      `Unsupported key algorithm with multicode 0x${code12.toString(16)}`
    );
  } else if (bytes2.byteLength !== SIZE) {
    throw new RangeError(
      `Expected Uint8Array with byteLength ${SIZE}, instead got Uint8Array with byteLength ${bytes2.byteLength}`
    );
  } else {
    return new Ed25519Verifier(bytes2.buffer, bytes2.byteOffset, bytes2.byteLength);
  }
};
var format9 = (principal) => format3(principal);
var encode23 = (principal) => encode9(principal);
var Ed25519Verifier = class extends Uint8Array {
  /** @type {typeof code} */
  get code() {
    return code12;
  }
  /** @type {typeof signatureCode} */
  get signatureCode() {
    return signatureCode;
  }
  /** @type {typeof signatureAlgorithm} */
  get signatureAlgorithm() {
    return signatureAlgorithm;
  }
  /**
   * Raw public key without a multiformat code.
   *
   * @readonly
   */
  get publicKey() {
    const key = new Uint8Array(this.buffer, this.byteOffset + PUBLIC_TAG_SIZE);
    Object.defineProperties(this, {
      publicKey: {
        value: key
      }
    });
    return key;
  }
  /**
   * DID of the Principal in `did:key` format.
   * @returns {API.DID<"key">}
   */
  did() {
    return `did:key:${base58btc2.encode(this)}`;
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, Signature.EdDSA>} signature
   * @returns {API.Await<boolean>}
   */
  verify(payload, signature) {
    return signature.code === signatureCode && verify(signature.raw, payload, this.publicKey);
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   * @returns {API.Verifier<ID, typeof signatureCode>}
   */
  withDID(id) {
    return withDID(this, id);
  }
  toDIDKey() {
    return this.did();
  }
};
var or7 = (other) => or6({ parse: parse5 }, other);

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/signer.js
var or8 = (left, right) => new Importer([left, right]);
var Importer = class _Importer {
  /**
   * @param {Importers} variants
   */
  constructor(variants) {
    this.variants = variants;
    this.from = create11(variants);
  }
  /**
   * @template {API.SignerImporter} Other
   * @param {Other} other
   * @returns {API.CompositeImporter<[Other, ...Importers]>}
   */
  or(other) {
    return new _Importer([other, ...this.variants]);
  }
};
var create11 = (importers) => {
  const from19 = (archive3) => {
    if (archive3.id.startsWith("did:key:")) {
      return (
        /** @type {API.Signer<ID, Alg>} */
        importWith(archive3, importers)
      );
    } else {
      for (const [name14, key] of Object.entries(archive3.keys)) {
        const id = (
          /** @type {API.DIDKey} */
          name14
        );
        const signer = (
          /** @type {API.Signer<API.DIDKey, Alg>} */
          importWith(
            {
              id,
              keys: { [id]: key }
            },
            importers
          )
        );
        return signer.withDID(archive3.id);
      }
      throw new Error(`Archive ${archive3.id} contains no keys`);
    }
  };
  return (
    /** @type {API.Intersection<Importers[number]['from']>} */
    from19
  );
};
var importWith = (archive3, importers) => {
  for (const importer of importers) {
    try {
      return importer.from(archive3);
    } catch (_) {
    }
  }
  throw new Error(`Unsupported signer`);
};
var withDID2 = ({ signer, verifier }, id) => new SignerWithDID(signer, verifier.withDID(id));
var SignerWithDID = class {
  /**
   * @param {API.Signer<API.DID<'key'>, Code>} key
   * @param {API.Verifier<ID, Code>} verifier
   */
  constructor(key, verifier) {
    this.key = key;
    this.verifier = verifier;
  }
  /** @type {API.Signer<ID, Code>} */
  get signer() {
    return this;
  }
  get signatureAlgorithm() {
    return this.key.signatureAlgorithm;
  }
  get signatureCode() {
    return this.key.signatureCode;
  }
  /**
   * @returns {ID}
   */
  did() {
    return this.verifier.did();
  }
  toDIDKey() {
    return this.verifier.toDIDKey();
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   */
  withDID(id) {
    return withDID2(this.key, id);
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   */
  sign(payload) {
    return this.key.sign(payload);
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, Code>} signature
   */
  verify(payload, signature) {
    return this.verifier.verify(payload, signature);
  }
  toArchive() {
    const { keys: keys2 } = this.key.toArchive();
    return {
      id: this.did(),
      keys: keys2
    };
  }
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/ed25519/signer.js
var code13 = 4864;
var name9 = name8;
var signatureAlgorithm2 = signatureAlgorithm;
var signatureCode2 = signatureCode;
var PRIVATE_TAG_SIZE = varint_exports2.encodingLength(code13);
var PUBLIC_TAG_SIZE2 = varint_exports2.encodingLength(code12);
var KEY_SIZE = 32;
var SIZE2 = PRIVATE_TAG_SIZE + KEY_SIZE + PUBLIC_TAG_SIZE2 + KEY_SIZE;
var PUB_KEY_OFFSET = PRIVATE_TAG_SIZE + KEY_SIZE;
var generate = () => derive2(utils.randomPrivateKey());
var derive2 = async (secret) => {
  if (secret.byteLength !== KEY_SIZE) {
    throw new Error(
      `Expected Uint8Array with byteLength of ${KEY_SIZE} instead not ${secret.byteLength}`
    );
  }
  const publicKey = await getPublicKey(secret);
  const signer = new Ed25519Signer(SIZE2);
  varint_exports2.encodeTo(code13, signer, 0);
  signer.set(secret, PRIVATE_TAG_SIZE);
  varint_exports2.encodeTo(code12, signer, PRIVATE_TAG_SIZE + KEY_SIZE);
  signer.set(publicKey, PRIVATE_TAG_SIZE + KEY_SIZE + PUBLIC_TAG_SIZE2);
  return signer;
};
var from13 = ({ id, keys: keys2 }) => {
  if (id.startsWith("did:key:")) {
    const key = keys2[
      /** @type {API.DIDKey} */
      id
    ];
    if (key instanceof Uint8Array) {
      return decode31(key);
    }
  }
  throw new TypeError(`Unsupported archive format`);
};
var or9 = (other) => or8({ from: from13 }, other);
var decode31 = (bytes2) => {
  if (bytes2.byteLength !== SIZE2) {
    throw new Error(
      `Expected Uint8Array with byteLength of ${SIZE2} instead not ${bytes2.byteLength}`
    );
  }
  {
    const [keyCode] = varint_exports2.decode(bytes2);
    if (keyCode !== code13) {
      throw new Error(`Given bytes must be a multiformat with ${code13} tag`);
    }
  }
  {
    const [code19] = varint_exports2.decode(bytes2.subarray(PUB_KEY_OFFSET));
    if (code19 !== code12) {
      throw new Error(
        `Given bytes must contain public key in multiformats with ${code12} tag`
      );
    }
  }
  return new Ed25519Signer(bytes2);
};
var encode24 = (signer) => signer.encode();
var format10 = (signer, encoder3) => (encoder3 || base64pad).encode(encode24(signer));
var parse6 = (principal, decoder3) => decode31((decoder3 || base64pad).decode(principal));
var Ed25519Signer = class extends Uint8Array {
  /** @type {typeof code} */
  get code() {
    return code13;
  }
  get signer() {
    return this;
  }
  /** @type {API.EdVerifier} */
  get verifier() {
    const bytes2 = new Uint8Array(this.buffer, PRIVATE_TAG_SIZE + KEY_SIZE);
    const verifier = decode30(bytes2);
    Object.defineProperties(this, {
      verifier: {
        value: verifier
      }
    });
    return verifier;
  }
  /**
   * Raw public key without multiformat code.
   */
  get secret() {
    const secret = new Uint8Array(this.buffer, PRIVATE_TAG_SIZE, KEY_SIZE);
    Object.defineProperties(this, {
      secret: {
        value: secret
      }
    });
    return secret;
  }
  /**
   * DID of this principal in `did:key` format.
   */
  did() {
    return this.verifier.did();
  }
  toDIDKey() {
    return this.verifier.toDIDKey();
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   * @returns {API.Signer<ID, typeof Signature.EdDSA>}
   */
  withDID(id) {
    return withDID2(this, id);
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @returns {Promise<API.SignatureView<T, typeof Signature.EdDSA>>}
   */
  async sign(payload) {
    const raw = await sign(payload, this.secret);
    return create5(this.signatureCode, raw);
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, typeof this.signatureCode>} signature
   */
  verify(payload, signature) {
    return this.verifier.verify(payload, signature);
  }
  get signatureAlgorithm() {
    return signatureAlgorithm2;
  }
  get signatureCode() {
    return EdDSA;
  }
  encode() {
    return this;
  }
  toArchive() {
    const id = this.did();
    return {
      id,
      keys: { [id]: this.encode() }
    };
  }
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa.js
var rsa_exports = {};
__export(rsa_exports, {
  Verifier: () => RSAVerifier,
  code: () => code14,
  decode: () => decode36,
  from: () => from14,
  generate: () => generate2,
  name: () => name10,
  or: () => or10,
  signatureAlgorithm: () => signatureAlgorithm3,
  signatureCode: () => signatureCode3
});

// ../../node_modules/.pnpm/one-webcrypto@1.0.3/node_modules/one-webcrypto/browser.mjs
var _globalReference = globalThis || window || self;
var webcrypto = _globalReference.crypto;

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/multiformat.js
var tagWith = (code19, bytes2) => {
  const offset2 = varint_exports2.encodingLength(code19);
  const multiformat = new Uint8Array(bytes2.byteLength + offset2);
  varint_exports2.encodeTo(code19, multiformat, 0);
  multiformat.set(bytes2, offset2);
  return multiformat;
};
var untagWith = (code19, source, byteOffset = 0) => {
  const bytes2 = byteOffset !== 0 ? source.subarray(byteOffset) : source;
  const [tag2, size5] = varint_exports2.decode(bytes2);
  if (tag2 !== code19) {
    throw new Error(
      `Expected multiformat with 0x${code19.toString(
        16
      )} tag instead got 0x${tag2.toString(16)}`
    );
  } else {
    return new Uint8Array(bytes2.buffer, bytes2.byteOffset + size5);
  }
};
var encodingLength4 = varint_exports2.encodingLength;
var encodeTo4 = varint_exports2.encodeTo;
var decode32 = varint_exports2.decode;

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa/asn1.js
var TAG_SIZE2 = 1;
var INT_TAG = 2;
var BITSTRING_TAG = 3;
var OCTET_STRING_TAG = 4;
var SEQUENCE_TAG = 48;
var UNUSED_BIT_PAD = 0;
var encodeDERLength = (length4) => {
  if (length4 <= 127) {
    return new Uint8Array([length4]);
  }
  const octets = [];
  while (length4 !== 0) {
    octets.push(length4 & 255);
    length4 = length4 >>> 8;
  }
  octets.reverse();
  return new Uint8Array([128 | octets.length & 255, ...octets]);
};
var readDERLength = (bytes2, offset2 = 0) => {
  if ((bytes2[offset2] & 128) === 0) {
    return { number: bytes2[offset2], consumed: 1 };
  }
  const numberBytes = bytes2[offset2] & 127;
  if (bytes2.length < numberBytes + 1) {
    throw new Error(
      `ASN parsing error: Too few bytes. Expected encoded length's length to be at least ${numberBytes}`
    );
  }
  let length4 = 0;
  for (let i = 0; i < numberBytes; i++) {
    length4 = length4 << 8;
    length4 = length4 | bytes2[offset2 + i + 1];
  }
  return { number: length4, consumed: numberBytes + 1 };
};
var skip = (input10, expectedTag, position) => {
  const parsed = into(input10, expectedTag, position);
  return parsed.position + parsed.length;
};
var into = (input10, expectedTag, offset2) => {
  const actualTag = input10[offset2];
  if (actualTag !== expectedTag) {
    throw new Error(
      `ASN parsing error: Expected tag 0x${expectedTag.toString(
        16
      )} at position ${offset2}, but got 0x${actualTag.toString(16)}.`
    );
  }
  const length4 = readDERLength(input10, offset2 + TAG_SIZE2);
  const position = offset2 + TAG_SIZE2 + length4.consumed;
  return { position, length: length4.number };
};
var encodeBitString = (input10) => {
  const length4 = encodeDERLength(input10.byteLength + 1);
  const bytes2 = new Uint8Array(
    TAG_SIZE2 + // ASN_BITSTRING_TAG
    length4.byteLength + 1 + // amount of unused bits at the end of our bitstring
    input10.byteLength
  );
  let byteOffset = 0;
  bytes2[byteOffset] = BITSTRING_TAG;
  byteOffset += TAG_SIZE2;
  bytes2.set(length4, byteOffset);
  byteOffset += length4.byteLength;
  bytes2[byteOffset] = UNUSED_BIT_PAD;
  byteOffset += 1;
  bytes2.set(input10, byteOffset);
  return bytes2;
};
var encodeOctetString = (input10) => {
  const length4 = encodeDERLength(input10.byteLength);
  const bytes2 = new Uint8Array(TAG_SIZE2 + length4.byteLength + input10.byteLength);
  let byteOffset = 0;
  bytes2[byteOffset] = OCTET_STRING_TAG;
  byteOffset += TAG_SIZE2;
  bytes2.set(length4, byteOffset);
  byteOffset += length4.byteLength;
  bytes2.set(input10, byteOffset);
  return bytes2;
};
var encodeSequence = (sequence) => {
  let byteLength = 0;
  for (const item of sequence) {
    byteLength += item.byteLength;
  }
  const length4 = encodeDERLength(byteLength);
  const bytes2 = new Uint8Array(TAG_SIZE2 + length4.byteLength + byteLength);
  let byteOffset = 0;
  bytes2[byteOffset] = SEQUENCE_TAG;
  byteOffset += TAG_SIZE2;
  bytes2.set(length4, byteOffset);
  byteOffset += length4.byteLength;
  for (const item of sequence) {
    bytes2.set(item, byteOffset);
    byteOffset += item.byteLength;
  }
  return bytes2;
};
var readSequence = (bytes2, offset2 = 0) => {
  const { position, length: length4 } = into(bytes2, SEQUENCE_TAG, offset2);
  return new Uint8Array(bytes2.buffer, bytes2.byteOffset + position, length4);
};
var encodeInt = (input10) => {
  const extra = input10.byteLength === 0 || input10[0] & 128 ? 1 : 0;
  const length4 = encodeDERLength(input10.byteLength + extra);
  const bytes2 = new Uint8Array(
    TAG_SIZE2 + // INT_TAG
    length4.byteLength + input10.byteLength + extra
  );
  let byteOffset = 0;
  bytes2[byteOffset] = INT_TAG;
  byteOffset += TAG_SIZE2;
  bytes2.set(length4, byteOffset);
  byteOffset += length4.byteLength;
  if (extra > 0) {
    bytes2[byteOffset] = UNUSED_BIT_PAD;
    byteOffset += extra;
  }
  bytes2.set(input10, byteOffset);
  return bytes2;
};
var enterSequence = (bytes2, offset2 = 0) => into(bytes2, SEQUENCE_TAG, offset2).position;
var skipSequence = (bytes2, offset2 = 0) => skip(bytes2, SEQUENCE_TAG, offset2);
var skipInt = (bytes2, offset2 = 0) => skip(bytes2, INT_TAG, offset2);
var readBitString = (bytes2, offset2 = 0) => {
  const { position, length: length4 } = into(bytes2, BITSTRING_TAG, offset2);
  const tag2 = bytes2[position];
  if (tag2 !== UNUSED_BIT_PAD) {
    throw new Error(
      `Can not read bitstring, expected length to be multiple of 8, but got ${tag2} unused bits in last byte.`
    );
  }
  return new Uint8Array(
    bytes2.buffer,
    bytes2.byteOffset + position + 1,
    length4 - 1
  );
};
var readInt2 = (bytes2, byteOffset = 0) => {
  const { position, length: length4 } = into(bytes2, INT_TAG, byteOffset);
  let delta = 0;
  while (bytes2[position + delta] === 0) {
    delta++;
  }
  return new Uint8Array(
    bytes2.buffer,
    bytes2.byteOffset + position + delta,
    length4 - delta
  );
};
var readOctetString = (bytes2, offset2 = 0) => {
  const { position, length: length4 } = into(bytes2, OCTET_STRING_TAG, offset2);
  return new Uint8Array(bytes2.buffer, bytes2.byteOffset + position, length4);
};
var readSequenceWith = (readers, source, byteOffset = 0) => {
  const results = [];
  const sequence = readSequence(source, byteOffset);
  let offset2 = 0;
  for (const read9 of readers) {
    const chunk = read9(sequence, offset2);
    results.push(chunk);
    offset2 = chunk.byteOffset + chunk.byteLength - sequence.byteOffset;
  }
  return results;
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa/spki.js
var SPKI_PARAMS_ENCODED = new Uint8Array([
  48,
  13,
  6,
  9,
  42,
  134,
  72,
  134,
  247,
  13,
  1,
  1,
  1,
  5,
  0
]);
var encode25 = (key) => encodeSequence([SPKI_PARAMS_ENCODED, encodeBitString(key)]);
var decode33 = (info) => {
  const offset2 = enterSequence(info, 0);
  const keyOffset = skipSequence(info, offset2);
  return readBitString(info, keyOffset);
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa/pkcs8.js
var PKSC8_HEADER = new Uint8Array([
  // version
  2,
  1,
  0,
  // privateKeyAlgorithm
  48,
  13,
  6,
  9,
  42,
  134,
  72,
  134,
  247,
  13,
  1,
  1,
  1,
  5,
  0
]);
var decode34 = (info) => {
  let offset2 = 0;
  offset2 = enterSequence(info, offset2);
  offset2 = skipInt(info, offset2);
  offset2 = skipSequence(info, offset2);
  return readOctetString(info, offset2);
};
var encode26 = (key) => encodeSequence([PKSC8_HEADER, encodeOctetString(key)]);

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa/public-key.js
var encode27 = ({ n, e }) => encodeSequence([encodeInt(n), encodeInt(e)]);

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa/private-key.js
var VERSION2 = new Uint8Array();
var decode35 = (source, byteOffset = 0) => {
  const [v, n, e, d, p, q, dp, dq, qi] = readSequenceWith(
    [
      readInt2,
      readInt2,
      readInt2,
      readInt2,
      readInt2,
      readInt2,
      readInt2,
      readInt2,
      readInt2
    ],
    source,
    byteOffset
  );
  return { v, n, e, d, p, q, dp, dq, qi };
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/rsa.js
var name10 = "RSA";
var code14 = 4869;
var verifierCode = 4613;
var signatureCode3 = RS256;
var signatureAlgorithm3 = "RS256";
var ALG = "RSASSA-PKCS1-v1_5";
var HASH_ALG = "SHA-256";
var KEY_SIZE2 = 2048;
var SALT_LENGTH = 128;
var IMPORT_PARAMS = {
  name: ALG,
  hash: { name: HASH_ALG }
};
var generate2 = async ({
  size: size5 = KEY_SIZE2,
  extractable = false
} = {}) => {
  const { publicKey, privateKey } = await webcrypto.subtle.generateKey(
    {
      name: ALG,
      modulusLength: size5,
      publicExponent: new Uint8Array([1, 0, 1]),
      hash: { name: HASH_ALG }
    },
    extractable,
    ["sign", "verify"]
  );
  const spki = await webcrypto.subtle.exportKey("spki", publicKey);
  const publicBytes = tagWith(verifierCode, decode33(new Uint8Array(spki)));
  const verifier = new RSAVerifier({ bytes: publicBytes, publicKey });
  if (!extractable) {
    return new UnextractableRSASigner({
      privateKey,
      verifier
    });
  } else {
    const pkcs8 = await webcrypto.subtle.exportKey("pkcs8", privateKey);
    const bytes2 = tagWith(code14, decode34(new Uint8Array(pkcs8)));
    return new ExtractableRSASigner({
      privateKey,
      bytes: bytes2,
      verifier
    });
  }
};
var from14 = ({ id, keys: keys2 }) => {
  if (id.startsWith("did:key:")) {
    const did2 = (
      /** @type {API.DIDKey} */
      id
    );
    const key = keys2[did2];
    if (key instanceof Uint8Array) {
      return decode36(key);
    } else {
      return new UnextractableRSASigner({
        privateKey: key,
        verifier: RSAVerifier.parse(did2)
      });
    }
  } else {
    throw new TypeError(
      `RSA can not import from ${id} archive, try generic Signer instead`
    );
  }
};
var or10 = (other) => or8({ from: from14 }, other);
var decode36 = (bytes2) => {
  const rsa = decode35(untagWith(code14, bytes2));
  const publicBytes = tagWith(verifierCode, encode27(rsa));
  return new ExtractableRSASigner({
    bytes: bytes2,
    privateKey: webcrypto.subtle.importKey(
      "pkcs8",
      encode26(untagWith(code14, bytes2)),
      IMPORT_PARAMS,
      true,
      ["sign"]
    ),
    verifier: RSAVerifier.decode(publicBytes)
  });
};
var RSAVerifier = class _RSAVerifier {
  /**
   * @param {object} options
   * @param {API.Await<CryptoKey>} options.publicKey
   * @param {API.ByteView<API.RSAVerifier>} options.bytes
   */
  constructor({ publicKey, bytes: bytes2 }) {
    this.publicKey = publicKey;
    this.bytes = bytes2;
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   * @returns {API.Verifier<ID, typeof signatureCode>}
   */
  withDID(id) {
    return withDID(this, id);
  }
  toDIDKey() {
    return this.did();
  }
  /**
   * @param {API.ByteView<API.RSAVerifier>} bytes
   * @returns {API.RSAVerifier}
   */
  static decode(bytes2) {
    return new this({
      bytes: bytes2,
      publicKey: webcrypto.subtle.importKey(
        "spki",
        encode25(untagWith(verifierCode, bytes2)),
        IMPORT_PARAMS,
        true,
        ["verify"]
      )
    });
  }
  /**
   * @param {API.DIDKey} did
   * @returns {API.RSAVerifier}
   */
  static parse(did2) {
    return _RSAVerifier.decode(
      /** @type {Uint8Array} */
      parse2(did2)
    );
  }
  /**
   * @param {API.PrincipalParser} other
   */
  static or(other) {
    return or6(this, other);
  }
  /** @type {typeof verifierCode} */
  get code() {
    return verifierCode;
  }
  /**
   * @type {typeof signatureCode}
   */
  get signatureCode() {
    return signatureCode3;
  }
  /**
   * @type {typeof signatureAlgorithm}
   */
  get signatureAlgorithm() {
    return signatureAlgorithm3;
  }
  /**
   * DID of the Principal in `did:key` format.
   * @returns {API.DID<"key">}
   */
  did() {
    return `did:key:${base58btc2.encode(this.bytes)}`;
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, typeof this.signatureCode>} signature
   * @returns {Promise<boolean>}
   */
  async verify(payload, signature) {
    if (signature.code !== signatureCode3) {
      return false;
    }
    return webcrypto.subtle.verify(
      { name: ALG, hash: { name: HASH_ALG } },
      await this.publicKey,
      signature.raw,
      payload
    );
  }
};
var RSASigner = class {
  /**
   * @param {object} options
   * @param {API.Await<CryptoKey>} options.privateKey
   * @param {API.RSAVerifier} options.verifier
   */
  constructor({ privateKey, verifier }) {
    this.verifier = verifier;
    this.privateKey = privateKey;
  }
  get signer() {
    return this;
  }
  /**
   * @type {typeof code}
   */
  get code() {
    return code14;
  }
  /**
   * @type {typeof signatureCode}
   */
  get signatureCode() {
    return signatureCode3;
  }
  /**
   * @type {typeof signatureAlgorithm}
   */
  get signatureAlgorithm() {
    return signatureAlgorithm3;
  }
  did() {
    return this.verifier.did();
  }
  toDIDKey() {
    return this.verifier.toDIDKey();
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @param {API.Signature<T, typeof this.signatureCode>} signature
   */
  verify(payload, signature) {
    return this.verifier.verify(payload, signature);
  }
  /**
   * @template T
   * @param {API.ByteView<T>} payload
   * @returns {Promise<API.SignatureView<T, typeof signatureCode>>}
   */
  async sign(payload) {
    const buffer2 = await webcrypto.subtle.sign(
      { name: ALG, saltLength: SALT_LENGTH },
      await this.privateKey,
      payload
    );
    return create5(signatureCode3, new Uint8Array(buffer2));
  }
};
var ExtractableRSASigner = class extends RSASigner {
  /**
   * @param {object} options
   * @param {API.Await<CryptoKey>} options.privateKey
   * @param {EncodedSigner} options.bytes
   * @param {API.RSAVerifier} options.verifier
   */
  constructor(options) {
    super(options);
    this.bytes = options.bytes;
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   * @returns {API.Signer<ID, typeof signatureCode>}
   */
  withDID(id) {
    return withDID2(this, id);
  }
  toArchive() {
    const id = this.did();
    return {
      id,
      keys: { [id]: this.bytes }
    };
  }
};
var UnextractableRSASigner = class extends RSASigner {
  /**
   * @param {object} options
   * @param {CryptoKey} options.privateKey
   * @param {API.RSAVerifier} options.verifier
   */
  constructor(options) {
    super(options);
    this.privateKey = options.privateKey;
  }
  /**
   * @template {API.DID} ID
   * @param {ID} id
   * @returns {API.Signer<ID, typeof signatureCode>}
   */
  withDID(id) {
    return withDID2(this, id);
  }
  toArchive() {
    const id = this.did();
    return {
      id,
      keys: { [id]: this.privateKey }
    };
  }
};

// ../../node_modules/.pnpm/@ucanto+principal@9.0.0/node_modules/@ucanto/principal/src/lib.js
var Verifier = verifier_exports.or(RSAVerifier);
var Signer = or9(rsa_exports);

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/ucan.js
var UCANLink = (
  /** @type {Schema.Schema<API.UCANLink, unknown>} */
  schema_exports3.link({ version: 1 })
);
var ucan = capability({
  can: "ucan/*",
  with: schema_exports3.did(),
  derives: equalWith2
});
var revoke = capability({
  can: "ucan/revoke",
  /**
   * DID of the principal authorizing revocation.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * UCAN being revoked from all proof chains that lead to the UCAN that is
     * either issued (iss) by or delegated to (aud) the principal identified
     * by the `with` field.
     */
    ucan: UCANLink,
    /**
     * Proof chain illustrating the path from revoked UCAN to the one that is
     * either issued (iss) by or delegated to (aud) the principal identified
     * by the `with` field.
     *
     * If the UCAN being revoked is either issued (iss) by or delegated to (aud)
     * the principal identified by the `with` field no `proof` is required and
     * it can be omitted or set to an empty array.
     *
     * It is RECOMMENDED that `proof` is provided in all other cases otherwise
     * it MAY not be possible to verify that revoking principal is a participant
     * in the proof chain.
     */
    proof: UCANLink.array().optional()
  }),
  derives: (claim, from19) => (
    // With field MUST be the same
    and4(equalWith2(claim, from19)) ?? // UCAN being revoked MUST be the same
    and4(checkLink2(claim.nb.ucan, from19.nb.ucan, "nb.ucan")) ?? // And proof chain MUST be the same
    equal2(
      (claim.nb.proof ?? []).join("/"),
      (from19.nb.proof ?? []).join("/"),
      "nb.proof"
    )
  )
});
var conclude = capability({
  can: "ucan/conclude",
  /**
   * DID of the principal representing the Conclusion Authority.
   * MUST be the DID of the audience of the ran invocation.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * CID of the content with the Receipt.
     */
    receipt: schema_exports3.link()
  }),
  derives: (claim, from19) => (
    // With field MUST be the same
    and4(equalWith2(claim, from19)) || and4(checkLink2(claim.nb.receipt, from19.nb.receipt, "nb.receipt")) || ok({})
  )
});
var attest = capability({
  can: "ucan/attest",
  // Should be web3.storage DID
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    // UCAN delegation that is being attested.
    proof: schema_exports3.link({ version: 1 })
  }),
  derives: (claim, from19) => (
    // With field MUST be the same
    and4(equalWith2(claim, from19)) ?? // UCAN link MUST be the same
    checkLink2(claim.nb.proof, from19.nb.proof, "nb.proof")
  )
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/blob.js
var blob = capability({
  can: "space/blob/*",
  /**
   * DID of the (memory) space where Blob is intended to
   * be stored.
   */
  with: SpaceDID2,
  derives: equalWith2
});
var content = schema_exports3.struct({
  /**
   * A multihash digest of the blob payload bytes, uniquely identifying blob.
   */
  digest: schema_exports3.bytes(),
  /**
   * Number of bytes contained by this blob. Service will provision write target
   * for this exact size. Attempt to write a larger Blob file will fail.
   */
  size: schema_exports3.integer()
});
var add3 = capability({
  can: "space/blob/add",
  /**
   * DID of the (memory) space where Blob is intended to
   * be stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * Blob to be added on the space.
     */
    blob: content
  }),
  derives: equalBlob
});
var remove3 = capability({
  can: "space/blob/remove",
  /**
   * DID of the (memory) space where Blob is stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * A multihash digest of the blob payload bytes, uniquely identifying blob.
     */
    digest: schema_exports3.bytes()
  }),
  derives: (claimed, delegated) => {
    if (claimed.with !== delegated.with) {
      return fail2(
        `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
      );
    } else if (delegated.nb.digest && !equals5(delegated.nb.digest, claimed.nb.digest)) {
      return fail2(
        `Link ${claimed.nb.digest ? `${claimed.nb.digest}` : ""} violates imposed ${delegated.nb.digest} constraint.`
      );
    }
    return ok({});
  }
});
var list3 = capability({
  can: "space/blob/list",
  /**
   * DID of the (memory) space where Blobs to be listed are stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * A pointer that can be moved back and forth on the list.
     * It can be used to paginate a list for instance.
     */
    cursor: schema_exports3.string().optional(),
    /**
     * Maximum number of items per page.
     */
    size: schema_exports3.integer().optional()
  }),
  derives: (claimed, delegated) => {
    if (claimed.with !== delegated.with) {
      return fail2(
        `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
      );
    }
    return ok({});
  }
});
var get4 = capability({
  can: "space/blob/get/0/1",
  /**
   * DID of the (memory) space where Blob is stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * A multihash digest of the blob payload bytes, uniquely identifying blob.
     */
    digest: schema_exports3.bytes()
  }),
  derives: (claimed, delegated) => {
    if (claimed.with !== delegated.with) {
      return fail2(
        `Expected 'with: "${delegated.with}"' instead got '${claimed.with}'`
      );
    } else if (delegated.nb.digest && !equals5(delegated.nb.digest, claimed.nb.digest)) {
      return fail2(
        `Link ${claimed.nb.digest ? `${claimed.nb.digest}` : ""} violates imposed ${delegated.nb.digest} constraint.`
      );
    }
    return ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/web3.storage/blob.js
var blob2 = capability({
  can: "web3.storage/blob/*",
  /**
   * DID of the (memory) space where Blob is intended to
   * be stored.
   */
  with: SpaceDID2,
  derives: equalWith2
});
var allocate = capability({
  can: "web3.storage/blob/allocate",
  /**
   * Provider DID.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * Blob to allocate on the space.
     */
    blob: content,
    /**
     * The Link for an Add Blob task, that caused an allocation
     */
    cause: link_exports2,
    /**
     * DID of the user space where allocation takes place
     */
    space: SpaceDID2
  }),
  derives: (claim, from19) => {
    return and4(equalWith2(claim, from19)) || and4(equalBlob(claim, from19)) || and4(checkLink2(claim.nb.cause, from19.nb.cause, "cause")) || and4(equal2(claim.nb.space, from19.nb.space, "space")) || ok({});
  }
});
var accept = capability({
  can: "web3.storage/blob/accept",
  /**
   * Provider DID.
   */
  with: schema_exports3.did(),
  nb: schema_exports3.struct({
    /**
     * Blob to accept.
     */
    blob: content,
    /**
     * Content location commitment time to live, which will be encoded as expiry of the issued location claim.
     */
    ttl: schema_exports3.integer().optional(),
    /**
     * DID of the user space where allocation took place
     */
    space: SpaceDID2,
    /**
     * This task is blocked on `http/put` receipt available
     */
    _put: Await2
  }),
  derives: (claim, from19) => {
    return and4(equalWith2(claim, from19)) || and4(equalBlob(claim, from19)) || and4(equal2(claim.nb.ttl, from19.nb.ttl, "ttl")) || and4(equal2(claim.nb.space, from19.nb.space, "space")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/http.js
var put = capability({
  can: "http/put",
  /**
   * DID of the (memory) space where Blob is intended to
   * be stored.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * Description of body to send (digest/size).
     */
    body: content,
    /**
     * HTTP(S) location that can receive blob content via HTTP PUT request.
     */
    url: schema_exports3.string().or(Await2),
    /**
     * HTTP headers.
     */
    headers: schema_exports3.dictionary({ value: schema_exports3.string() }).or(Await2)
  }),
  derives: (claim, from19) => {
    return and4(equalWith2(claim, from19)) || and4(equalBody(claim, from19)) || and4(equal2(claim.nb.url, from19.nb, "url")) || and4(equal2(claim.nb.headers, from19.nb, "headers")) || ok({});
  }
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/receipts.js
var receipts_exports = {};
__export(receipts_exports, {
  ReceiptMissing: () => ReceiptMissing,
  ReceiptNotFound: () => ReceiptNotFound,
  poll: () => poll
});
var ReceiptNotFound = class extends Error {
  /**
   * @param {import('multiformats').UnknownLink} taskCid
   */
  constructor(taskCid) {
    super();
    this.taskCid = taskCid;
  }
  /* c8 ignore start */
  get reason() {
    return `receipt not found for task ${this.taskCid} in the indexed workflow`;
  }
  /* c8 ignore end */
  get name() {
    return "ReceiptNotFound";
  }
};
var ReceiptMissing = class extends Error {
  /**
   * @param {import('multiformats').UnknownLink} taskCid
   */
  constructor(taskCid) {
    super();
    this.taskCid = taskCid;
  }
  /* c8 ignore start */
  get reason() {
    return `receipt missing for task ${this.taskCid}`;
  }
  /* c8 ignore end */
  get name() {
    return "ReceiptMissing";
  }
};
async function poll(taskCid, options = {}) {
  return await pRetry(async () => {
    const res = await get5(taskCid, options);
    if (res.error) {
      if (res.error.name === "ReceiptNotFound") {
        throw res.error;
      } else {
        throw new AbortError(new Error("failed to fetch blob/accept receipt", {
          cause: res.error
        }));
      }
    }
    return res.ok;
  }, {
    onFailedAttempt: console.warn,
    /* c8 ignore next */
    retries: options.retries ?? REQUEST_RETRIES
  });
}
async function get5(taskCid, options = {}) {
  const url = new URL(taskCid.toString(), options.receiptsEndpoint ?? receiptsEndpoint);
  const fetchReceipt = options.fetch ?? globalThis.fetch.bind(globalThis);
  const workflowResponse = await fetchReceipt(url);
  if (workflowResponse.status === 404) {
    return {
      error: new ReceiptNotFound(taskCid)
    };
  }
  const agentMessageBytes = new Uint8Array(await workflowResponse.arrayBuffer());
  const agentMessage = await car_exports2.request.decode({
    body: agentMessageBytes,
    headers: {}
  });
  const receipt = agentMessage.receipts.get(taskCid.toString());
  if (!receipt) {
    return {
      error: new ReceiptMissing(taskCid)
    };
  }
  return {
    ok: receipt
  };
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/blob/add.js
function createUploadProgressHandler2(url, handler) {
  const onUploadProgress = ({ total, loaded, lengthComputable }) => {
    return handler({ total, loaded, lengthComputable, url });
  };
  return onUploadProgress;
}
function getConcludeReceipt(concludeFx) {
  const receiptBlocks = /* @__PURE__ */ new Map();
  for (const block of concludeFx.iterateIPLDBlocks()) {
    receiptBlocks.set(`${block.cid}`, block);
  }
  return receipt_exports.view({
    // @ts-expect-error object of type unknown
    root: concludeFx.capabilities[0].nb.receipt,
    blocks: receiptBlocks
  });
}
function parseBlobAddReceiptNext(receipt) {
  const forkInvocations = receipt.fx.fork;
  const allocateTask = forkInvocations.find((fork5) => fork5.capabilities[0].can === allocate.can);
  const concludefxs = forkInvocations.filter((fork5) => fork5.capabilities[0].can === conclude.can);
  const putTask = forkInvocations.find((fork5) => fork5.capabilities[0].can === put.can);
  const acceptTask = forkInvocations.find((fork5) => fork5.capabilities[0].can === accept.can);
  if (!allocateTask || !concludefxs.length || !putTask || !acceptTask) {
    throw new Error("mandatory effects not received");
  }
  const nextReceipts = concludefxs.map((fx) => getConcludeReceipt(fx));
  const allocateReceipt = nextReceipts.find((receipt2) => receipt2.ran.link().equals(allocateTask.cid));
  const putReceipt = nextReceipts.find((receipt2) => receipt2.ran.link().equals(putTask.cid));
  const acceptReceipt = nextReceipts.find((receipt2) => receipt2.ran.link().equals(acceptTask.cid));
  if (!allocateReceipt) {
    throw new Error("mandatory effects not received");
  }
  return {
    allocate: {
      task: allocateTask,
      receipt: allocateReceipt
    },
    put: {
      task: putTask,
      receipt: putReceipt
    },
    accept: {
      task: acceptTask,
      receipt: acceptReceipt
    }
  };
}
function createConcludeInvocation(id, serviceDid, receipt) {
  const receiptBlocks = [];
  const receiptCids = [];
  for (const block of receipt.iterateIPLDBlocks()) {
    receiptBlocks.push(block);
    receiptCids.push(block.cid);
  }
  const concludeAllocatefx = conclude.invoke({
    issuer: id,
    audience: serviceDid,
    with: id.toDIDKey(),
    nb: {
      receipt: receipt.link()
    },
    expiration: Infinity,
    facts: [
      {
        ...receiptCids
      }
    ]
  });
  for (const block of receiptBlocks) {
    concludeAllocatefx.attach(block);
  }
  return concludeAllocatefx;
}
async function add4({ issuer, with: resource, proofs: proofs2, audience }, digest5, data, options = {}) {
  const bytes2 = data instanceof Uint8Array ? data : new Uint8Array(await data.arrayBuffer());
  const size5 = bytes2.length;
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await add3.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: input(digest5, size5),
      proofs: proofs2,
      nonce: options.nonce
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${add3.can} invocation`, {
      cause: result.out.error
    });
  }
  const nextTasks = parseBlobAddReceiptNext(result);
  const { receipt: allocateReceipt } = nextTasks.allocate;
  if (!allocateReceipt.out.ok) {
    throw new Error(`failed ${add3.can} invocation`, {
      cause: allocateReceipt.out.error
    });
  }
  const { address } = allocateReceipt.out.ok;
  if (address) {
    const fetchWithUploadProgress = options.fetchWithUploadProgress || options.fetch || globalThis.fetch.bind(globalThis);
    let fetchDidCallUploadProgressCb = false;
    const { status } = await pRetry(async () => {
      try {
        const res = await fetchWithUploadProgress(address.url, {
          method: "PUT",
          mode: "cors",
          body: bytes2,
          headers: address.headers,
          signal: options.signal,
          onUploadProgress: (status2) => {
            fetchDidCallUploadProgressCb = true;
            if (options.onUploadProgress)
              createUploadProgressHandler2(address.url, options.onUploadProgress)(status2);
          },
          // @ts-expect-error - this is needed by recent versions of node - see https://github.com/bluesky-social/atproto/pull/470 for more info
          duplex: "half"
        });
        if (res.status >= 400 && res.status < 500) {
          throw new AbortError(`upload failed: ${res.status}`);
        }
        return res;
      } catch (err) {
        if (options.signal?.aborted === true) {
          throw new AbortError("upload aborted");
        }
        throw err;
      }
    }, {
      retries: options.retries ?? REQUEST_RETRIES
    });
    if (status !== 200)
      throw new Error(`upload failed: ${status}`);
    if (!fetchDidCallUploadProgressCb && options.onUploadProgress) {
      const blob3 = new Blob([bytes2]);
      options.onUploadProgress({
        total: blob3.size,
        loaded: blob3.size,
        lengthComputable: false
      });
    }
  }
  let { receipt: httpPutReceipt } = nextTasks.put;
  if (!httpPutReceipt?.out.ok) {
    const derivedSigner = ed25519_exports.from(
      /** @type {import('@ucanto/interface').SignerArchive<import('@ucanto/interface').DID, typeof ed25519.signatureCode>} */
      nextTasks.put.task.facts[0]["keys"]
    );
    httpPutReceipt = await receipt_exports.issue({
      issuer: derivedSigner,
      ran: nextTasks.put.task.cid,
      result: { ok: {} }
    });
    const httpPutConcludeInvocation = createConcludeInvocation(
      issuer,
      /* c8 ignore next */
      audience ?? servicePrincipal,
      httpPutReceipt
    );
    const ucanConclude = await httpPutConcludeInvocation.execute(conn);
    if (!ucanConclude.out.ok) {
      throw new Error(`failed ${add3.can} invocation`, {
        cause: result.out.error
      });
    }
  }
  let { receipt: acceptReceipt } = nextTasks.accept;
  if (!acceptReceipt?.out.ok) {
    acceptReceipt = await poll(nextTasks.accept.task.link(), options);
  }
  const blocks = new Map([...acceptReceipt.iterateIPLDBlocks()].map((block) => [
    `${block.cid}`,
    block
  ]));
  const site = delegation_exports.view({
    root: (
      /** @type {import('@ucanto/interface').UCANLink} */
      acceptReceipt.out.ok?.site
    ),
    blocks
  });
  return { site };
}
var ability = add3.can;
var input = (digest5, size5) => ({
  blob: {
    digest: digest5.bytes,
    size: size5
  }
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/blob/get.js
async function get6({ issuer, with: resource, proofs: proofs2, audience }, multihash, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await get4.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    nb: input2(multihash),
    proofs: proofs2,
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${get4.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out;
}
var ability2 = get4.can;
var input2 = (digest5) => ({ digest: digest5.bytes });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/blob/list.js
async function list4({ issuer, with: resource, proofs: proofs2, audience }, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await list3.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    proofs: proofs2,
    nb: input3(options.cursor, options.size),
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${list3.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability3 = list3.can;
var input3 = (cursor, size5) => ({ cursor, size: size5 });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/blob/remove.js
async function remove4({ issuer, with: resource, proofs: proofs2, audience }, multihash, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await remove3.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    nb: input4(multihash),
    proofs: proofs2,
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${remove3.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out;
}
var ability4 = remove3.can;
var input4 = (digest5) => ({ digest: digest5.bytes });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/index/index.js
var index_exports2 = {};
__export(index_exports2, {
  add: () => add6
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/index/index.js
var index = capability({
  can: "space/index/*",
  /** DID of the space where indexed data is stored. */
  with: SpaceDID2,
  derives: equalWith2
});
var add5 = capability({
  can: "space/index/add",
  /** DID of the space where indexed data is stored. */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /** Content Archive (CAR) containing the `Index`. */
    index: schema_exports3.link({ code: car_exports.code })
  }),
  derives: (claimed, delegated) => and4(equalWith2(claimed, delegated)) || and4(equal2(claimed.nb.index, delegated.nb.index, "index")) || ok({})
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/index/add.js
async function add6({ issuer, with: resource, proofs: proofs2, audience }, index2, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await add5.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: input5(index2),
      proofs: proofs2
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${add5.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability5 = add5.can;
var input5 = (index2) => ({ index: index2 });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/upload/index.js
var upload_exports2 = {};
__export(upload_exports2, {
  add: () => add8,
  get: () => get8,
  list: () => list6,
  remove: () => remove6
});

// ../../node_modules/.pnpm/@web3-storage+capabilities@17.2.0/node_modules/@web3-storage/capabilities/src/upload.js
var upload = capability({
  can: "upload/*",
  /**
   * DID of the (memory) space where upload is add to the
   * upload list.
   */
  with: SpaceDID2,
  derives: equalWith2
});
var CARLink2 = link_exports2.match({ code: car_exports.code, version: 1 });
var add7 = capability({
  can: "upload/add",
  /**
   * DID of the (memory) space where uploaded is added.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * Root CID of the DAG to be added to the upload list.
     */
    root: link_exports2,
    /**
     * CIDs to the CAR files that contain blocks of the DAG.
     */
    shards: CARLink2.array().optional()
  }),
  derives: (self2, from19) => {
    return and4(equalWith2(self2, from19)) || and4(equal2(self2.nb.root, from19.nb.root, "root")) || and4(equal2(self2.nb.shards, from19.nb.shards, "shards")) || ok({});
  }
});
var get7 = capability({
  can: "upload/get",
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * Root CID of the DAG to fetch upload info about.
     */
    root: link_exports2.optional()
  }),
  derives: (self2, from19) => {
    const res = equalWith2(self2, from19);
    if (res.error) {
      return res;
    }
    if (!from19.nb.root) {
      return res;
    }
    return equal2(self2.nb.root, from19.nb.root, "root");
  }
});
var remove5 = capability({
  can: "upload/remove",
  /**
   * DID of the (memory) space where uploaded is removed from.
   */
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * Root CID of the DAG to be removed from the upload list.
     */
    root: link_exports2
  }),
  derives: (self2, from19) => {
    return and4(equalWith2(self2, from19)) || and4(equal2(self2.nb.root, from19.nb.root, "root")) || ok({});
  }
});
var list5 = capability({
  can: "upload/list",
  with: SpaceDID2,
  nb: schema_exports3.struct({
    /**
     * A pointer that can be moved back and forth on the list.
     * It can be used to paginate a list for instance.
     */
    cursor: schema_exports3.string().optional(),
    /**
     * Maximum number of items per page.
     */
    size: schema_exports3.integer().optional(),
    /**
     * If true, return page of results preceding cursor. Defaults to false.
     */
    pre: schema_exports3.boolean().optional()
  })
});
var all2 = add7.or(remove5).or(list5);

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/upload/add.js
async function add8({ issuer, with: resource, proofs: proofs2, audience }, root2, shards, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await add7.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: input6(root2, shards),
      proofs: proofs2,
      nonce: options.nonce
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${add7.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability6 = add7.can;
var input6 = (root2, shards) => ({ root: root2, shards });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/upload/get.js
async function get8({ issuer, with: resource, proofs: proofs2, audience }, root2, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await pRetry(async () => {
    return await get7.invoke({
      issuer,
      /* c8 ignore next */
      audience: audience ?? servicePrincipal,
      with: SpaceDID2.from(resource),
      nb: input7(root2),
      proofs: proofs2,
      nonce: options.nonce
    }).execute(conn);
  }, {
    onFailedAttempt: console.warn,
    retries: options.retries ?? REQUEST_RETRIES
  });
  if (!result.out.ok) {
    throw new Error(`failed ${get7.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability7 = get7.can;
var input7 = (root2) => ({ root: root2 });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/upload/list.js
async function list6({ issuer, with: resource, proofs: proofs2, audience }, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await list5.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    proofs: proofs2,
    nb: input8(options.cursor, options.size, options.pre),
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${list5.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability8 = list5.can;
var input8 = (cursor, size5, pre) => ({ cursor, size: size5, pre });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/upload/remove.js
async function remove6({ issuer, with: resource, proofs: proofs2, audience }, root2, options = {}) {
  const conn = options.connection ?? connection5;
  const result = await remove5.invoke({
    issuer,
    /* c8 ignore next */
    audience: audience ?? servicePrincipal,
    with: SpaceDID2.from(resource),
    nb: input9(root2),
    proofs: proofs2,
    nonce: options.nonce
  }).execute(conn);
  if (!result.out.ok) {
    throw new Error(`failed ${remove5.can} invocation`, {
      cause: result.out.error
    });
  }
  return result.out.ok;
}
var ability9 = remove5.can;
var input9 = (root2) => ({ root: root2 });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/unixfs.js
var unixfs_exports3 = {};
__export(unixfs_exports3, {
  createDirectoryEncoderStream: () => createDirectoryEncoderStream,
  createFileEncoderStream: () => createFileEncoderStream,
  encodeDirectory: () => encodeDirectory2,
  encodeFile: () => encodeFile2
});

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/codec.js
var codec_exports2 = {};
__export(codec_exports2, {
  DEFAULT_DIRECTORY_MODE: () => DEFAULT_DIRECTORY_MODE,
  DEFAULT_FILE_MODE: () => DEFAULT_FILE_MODE,
  NodeType: () => NodeType,
  code: () => code16,
  createAdvancedFile: () => createAdvancedFile,
  createComplexFile: () => createComplexFile,
  createDirectoryShard: () => createDirectoryShard,
  createEmptyFile: () => createEmptyFile,
  createFileChunk: () => createFileChunk,
  createFileShard: () => createFileShard,
  createFlatDirectory: () => createFlatDirectory,
  createRaw: () => createRaw,
  createShardedDirectory: () => createShardedDirectory,
  createSimpleFile: () => createSimpleFile,
  createSymlink: () => createSymlink,
  cumulativeContentByteLength: () => cumulativeContentByteLength,
  cumulativeDagByteLength: () => cumulativeDagByteLength,
  decode: () => decode38,
  decodeMetadata: () => decodeMetadata,
  encode: () => encode29,
  encodeAdvancedFile: () => encodeAdvancedFile,
  encodeComplexFile: () => encodeComplexFile,
  encodeDirectory: () => encodeDirectory,
  encodeDirectoryMetadata: () => encodeDirectoryMetadata,
  encodeFile: () => encodeFile,
  encodeFileChunk: () => encodeFileChunk,
  encodeFileShard: () => encodeFileShard,
  encodeHAMTShard: () => encodeHAMTShard,
  encodeLink: () => encodeLink2,
  encodeMetadata: () => encodeMetadata,
  encodeMode: () => encodeMode,
  encodeRaw: () => encodeRaw,
  encodeSimpleFile: () => encodeSimpleFile,
  encodeSymlink: () => encodeSymlink,
  filesize: () => filesize,
  matchFile: () => matchFile,
  name: () => name11
});

// ../../node_modules/.pnpm/@ipld+dag-pb@4.1.2/node_modules/@ipld/dag-pb/src/pb-decode.js
var textDecoder2 = new TextDecoder();
function decodeVarint2(bytes2, offset2) {
  let v = 0;
  for (let shift = 0; ; shift += 7) {
    if (shift >= 64) {
      throw new Error("protobuf: varint overflow");
    }
    if (offset2 >= bytes2.length) {
      throw new Error("protobuf: unexpected end of data");
    }
    const b = bytes2[offset2++];
    v += shift < 28 ? (b & 127) << shift : (b & 127) * 2 ** shift;
    if (b < 128) {
      break;
    }
  }
  return [v, offset2];
}
function decodeBytes(bytes2, offset2) {
  let byteLen;
  [byteLen, offset2] = decodeVarint2(bytes2, offset2);
  const postOffset = offset2 + byteLen;
  if (byteLen < 0 || postOffset < 0) {
    throw new Error("protobuf: invalid length");
  }
  if (postOffset > bytes2.length) {
    throw new Error("protobuf: unexpected end of data");
  }
  return [bytes2.subarray(offset2, postOffset), postOffset];
}
function decodeKey(bytes2, index2) {
  let wire;
  [wire, index2] = decodeVarint2(bytes2, index2);
  return [wire & 7, wire >> 3, index2];
}
function decodeLink(bytes2) {
  const link5 = {};
  const l = bytes2.length;
  let index2 = 0;
  while (index2 < l) {
    let wireType, fieldNum;
    [wireType, fieldNum, index2] = decodeKey(bytes2, index2);
    if (fieldNum === 1) {
      if (link5.Hash) {
        throw new Error("protobuf: (PBLink) duplicate Hash section");
      }
      if (wireType !== 2) {
        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Hash`);
      }
      if (link5.Name !== void 0) {
        throw new Error("protobuf: (PBLink) invalid order, found Name before Hash");
      }
      if (link5.Tsize !== void 0) {
        throw new Error("protobuf: (PBLink) invalid order, found Tsize before Hash");
      }
      [link5.Hash, index2] = decodeBytes(bytes2, index2);
    } else if (fieldNum === 2) {
      if (link5.Name !== void 0) {
        throw new Error("protobuf: (PBLink) duplicate Name section");
      }
      if (wireType !== 2) {
        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Name`);
      }
      if (link5.Tsize !== void 0) {
        throw new Error("protobuf: (PBLink) invalid order, found Tsize before Name");
      }
      let byts;
      [byts, index2] = decodeBytes(bytes2, index2);
      link5.Name = textDecoder2.decode(byts);
    } else if (fieldNum === 3) {
      if (link5.Tsize !== void 0) {
        throw new Error("protobuf: (PBLink) duplicate Tsize section");
      }
      if (wireType !== 0) {
        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Tsize`);
      }
      [link5.Tsize, index2] = decodeVarint2(bytes2, index2);
    } else {
      throw new Error(`protobuf: (PBLink) invalid fieldNumber, expected 1, 2 or 3, got ${fieldNum}`);
    }
  }
  if (index2 > l) {
    throw new Error("protobuf: (PBLink) unexpected end of data");
  }
  return link5;
}
function decodeNode(bytes2) {
  const l = bytes2.length;
  let index2 = 0;
  let links3 = void 0;
  let linksBeforeData = false;
  let data = void 0;
  while (index2 < l) {
    let wireType, fieldNum;
    [wireType, fieldNum, index2] = decodeKey(bytes2, index2);
    if (wireType !== 2) {
      throw new Error(`protobuf: (PBNode) invalid wireType, expected 2, got ${wireType}`);
    }
    if (fieldNum === 1) {
      if (data) {
        throw new Error("protobuf: (PBNode) duplicate Data section");
      }
      [data, index2] = decodeBytes(bytes2, index2);
      if (links3) {
        linksBeforeData = true;
      }
    } else if (fieldNum === 2) {
      if (linksBeforeData) {
        throw new Error("protobuf: (PBNode) duplicate Links section");
      } else if (!links3) {
        links3 = [];
      }
      let byts;
      [byts, index2] = decodeBytes(bytes2, index2);
      links3.push(decodeLink(byts));
    } else {
      throw new Error(`protobuf: (PBNode) invalid fieldNumber, expected 1 or 2, got ${fieldNum}`);
    }
  }
  if (index2 > l) {
    throw new Error("protobuf: (PBNode) unexpected end of data");
  }
  const node = {};
  if (data) {
    node.Data = data;
  }
  node.Links = links3 || [];
  return node;
}

// ../../node_modules/.pnpm/@ipld+dag-pb@4.1.2/node_modules/@ipld/dag-pb/src/pb-encode.js
var textEncoder2 = new TextEncoder();
var maxInt32 = 2 ** 32;
var maxUInt32 = 2 ** 31;
function encodeLink(link5, bytes2) {
  let i = bytes2.length;
  if (typeof link5.Tsize === "number") {
    if (link5.Tsize < 0) {
      throw new Error("Tsize cannot be negative");
    }
    if (!Number.isSafeInteger(link5.Tsize)) {
      throw new Error("Tsize too large for encoding");
    }
    i = encodeVarint(bytes2, i, link5.Tsize) - 1;
    bytes2[i] = 24;
  }
  if (typeof link5.Name === "string") {
    const nameBytes = textEncoder2.encode(link5.Name);
    i -= nameBytes.length;
    bytes2.set(nameBytes, i);
    i = encodeVarint(bytes2, i, nameBytes.length) - 1;
    bytes2[i] = 18;
  }
  if (link5.Hash) {
    i -= link5.Hash.length;
    bytes2.set(link5.Hash, i);
    i = encodeVarint(bytes2, i, link5.Hash.length) - 1;
    bytes2[i] = 10;
  }
  return bytes2.length - i;
}
function encodeNode(node) {
  const size5 = sizeNode(node);
  const bytes2 = new Uint8Array(size5);
  let i = size5;
  if (node.Data) {
    i -= node.Data.length;
    bytes2.set(node.Data, i);
    i = encodeVarint(bytes2, i, node.Data.length) - 1;
    bytes2[i] = 10;
  }
  if (node.Links) {
    for (let index2 = node.Links.length - 1; index2 >= 0; index2--) {
      const size6 = encodeLink(node.Links[index2], bytes2.subarray(0, i));
      i -= size6;
      i = encodeVarint(bytes2, i, size6) - 1;
      bytes2[i] = 18;
    }
  }
  return bytes2;
}
function sizeLink(link5) {
  let n = 0;
  if (link5.Hash) {
    const l = link5.Hash.length;
    n += 1 + l + sov(l);
  }
  if (typeof link5.Name === "string") {
    const l = textEncoder2.encode(link5.Name).length;
    n += 1 + l + sov(l);
  }
  if (typeof link5.Tsize === "number") {
    n += 1 + sov(link5.Tsize);
  }
  return n;
}
function sizeNode(node) {
  let n = 0;
  if (node.Data) {
    const l = node.Data.length;
    n += 1 + l + sov(l);
  }
  if (node.Links) {
    for (const link5 of node.Links) {
      const l = sizeLink(link5);
      n += 1 + l + sov(l);
    }
  }
  return n;
}
function encodeVarint(bytes2, offset2, v) {
  offset2 -= sov(v);
  const base4 = offset2;
  while (v >= maxUInt32) {
    bytes2[offset2++] = v & 127 | 128;
    v /= 128;
  }
  while (v >= 128) {
    bytes2[offset2++] = v & 127 | 128;
    v >>>= 7;
  }
  bytes2[offset2] = v;
  return base4;
}
function sov(x) {
  if (x % 2 === 0) {
    x++;
  }
  return Math.floor((len64(x) + 6) / 7);
}
function len64(x) {
  let n = 0;
  if (x >= maxInt32) {
    x = Math.floor(x / maxInt32);
    n = 32;
  }
  if (x >= 1 << 16) {
    x >>>= 16;
    n += 16;
  }
  if (x >= 1 << 8) {
    x >>>= 8;
    n += 8;
  }
  return n + len8tab[x];
}
var len8tab = [
  0,
  1,
  2,
  2,
  3,
  3,
  3,
  3,
  4,
  4,
  4,
  4,
  4,
  4,
  4,
  4,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  5,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  6,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  7,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8,
  8
];

// ../../node_modules/.pnpm/@ipld+dag-pb@4.1.2/node_modules/@ipld/dag-pb/src/util.js
var pbNodeProperties = ["Data", "Links"];
var pbLinkProperties = ["Hash", "Name", "Tsize"];
var textEncoder3 = new TextEncoder();
function linkComparator(a, b) {
  if (a === b) {
    return 0;
  }
  const abuf = a.Name ? textEncoder3.encode(a.Name) : [];
  const bbuf = b.Name ? textEncoder3.encode(b.Name) : [];
  let x = abuf.length;
  let y = bbuf.length;
  for (let i = 0, len = Math.min(x, y); i < len; ++i) {
    if (abuf[i] !== bbuf[i]) {
      x = abuf[i];
      y = bbuf[i];
      break;
    }
  }
  return x < y ? -1 : y < x ? 1 : 0;
}
function hasOnlyProperties(node, properties) {
  return !Object.keys(node).some((p) => !properties.includes(p));
}
function asLink(link5) {
  if (typeof link5.asCID === "object") {
    const Hash = CID.asCID(link5);
    if (!Hash) {
      throw new TypeError("Invalid DAG-PB form");
    }
    return { Hash };
  }
  if (typeof link5 !== "object" || Array.isArray(link5)) {
    throw new TypeError("Invalid DAG-PB form");
  }
  const pbl = {};
  if (link5.Hash) {
    let cid = CID.asCID(link5.Hash);
    try {
      if (!cid) {
        if (typeof link5.Hash === "string") {
          cid = CID.parse(link5.Hash);
        } else if (link5.Hash instanceof Uint8Array) {
          cid = CID.decode(link5.Hash);
        }
      }
    } catch (e) {
      throw new TypeError(`Invalid DAG-PB form: ${e.message}`);
    }
    if (cid) {
      pbl.Hash = cid;
    }
  }
  if (!pbl.Hash) {
    throw new TypeError("Invalid DAG-PB form");
  }
  if (typeof link5.Name === "string") {
    pbl.Name = link5.Name;
  }
  if (typeof link5.Tsize === "number") {
    pbl.Tsize = link5.Tsize;
  }
  return pbl;
}
function prepare2(node) {
  if (node instanceof Uint8Array || typeof node === "string") {
    node = { Data: node };
  }
  if (typeof node !== "object" || Array.isArray(node)) {
    throw new TypeError("Invalid DAG-PB form");
  }
  const pbn = {};
  if (node.Data !== void 0) {
    if (typeof node.Data === "string") {
      pbn.Data = textEncoder3.encode(node.Data);
    } else if (node.Data instanceof Uint8Array) {
      pbn.Data = node.Data;
    } else {
      throw new TypeError("Invalid DAG-PB form");
    }
  }
  if (node.Links !== void 0) {
    if (Array.isArray(node.Links)) {
      pbn.Links = node.Links.map(asLink);
      pbn.Links.sort(linkComparator);
    } else {
      throw new TypeError("Invalid DAG-PB form");
    }
  } else {
    pbn.Links = [];
  }
  return pbn;
}
function validate(node) {
  if (!node || typeof node !== "object" || Array.isArray(node) || node instanceof Uint8Array || node["/"] && node["/"] === node.bytes) {
    throw new TypeError("Invalid DAG-PB form");
  }
  if (!hasOnlyProperties(node, pbNodeProperties)) {
    throw new TypeError("Invalid DAG-PB form (extraneous properties)");
  }
  if (node.Data !== void 0 && !(node.Data instanceof Uint8Array)) {
    throw new TypeError("Invalid DAG-PB form (Data must be bytes)");
  }
  if (!Array.isArray(node.Links)) {
    throw new TypeError("Invalid DAG-PB form (Links must be a list)");
  }
  for (let i = 0; i < node.Links.length; i++) {
    const link5 = node.Links[i];
    if (!link5 || typeof link5 !== "object" || Array.isArray(link5) || link5 instanceof Uint8Array || link5["/"] && link5["/"] === link5.bytes) {
      throw new TypeError("Invalid DAG-PB form (bad link)");
    }
    if (!hasOnlyProperties(link5, pbLinkProperties)) {
      throw new TypeError("Invalid DAG-PB form (extraneous properties on link)");
    }
    if (link5.Hash === void 0) {
      throw new TypeError("Invalid DAG-PB form (link must have a Hash)");
    }
    if (link5.Hash == null || !link5.Hash["/"] || link5.Hash["/"] !== link5.Hash.bytes) {
      throw new TypeError("Invalid DAG-PB form (link Hash must be a CID)");
    }
    if (link5.Name !== void 0 && typeof link5.Name !== "string") {
      throw new TypeError("Invalid DAG-PB form (link Name must be a string)");
    }
    if (link5.Tsize !== void 0) {
      if (typeof link5.Tsize !== "number" || link5.Tsize % 1 !== 0) {
        throw new TypeError("Invalid DAG-PB form (link Tsize must be an integer)");
      }
      if (link5.Tsize < 0) {
        throw new TypeError("Invalid DAG-PB form (link Tsize cannot be negative)");
      }
    }
    if (i > 0 && linkComparator(link5, node.Links[i - 1]) === -1) {
      throw new TypeError("Invalid DAG-PB form (links must be sorted by Name bytes)");
    }
  }
}
function toByteView3(buf2) {
  if (buf2 instanceof ArrayBuffer) {
    return new Uint8Array(buf2, 0, buf2.byteLength);
  }
  return buf2;
}

// ../../node_modules/.pnpm/@ipld+dag-pb@4.1.2/node_modules/@ipld/dag-pb/src/index.js
var code15 = 112;
function encode28(node) {
  validate(node);
  const pbn = {};
  if (node.Links) {
    pbn.Links = node.Links.map((l) => {
      const link5 = {};
      if (l.Hash) {
        link5.Hash = l.Hash.bytes;
      }
      if (l.Name !== void 0) {
        link5.Name = l.Name;
      }
      if (l.Tsize !== void 0) {
        link5.Tsize = l.Tsize;
      }
      return link5;
    });
  }
  if (node.Data) {
    pbn.Data = node.Data;
  }
  return encodeNode(pbn);
}
function decode37(bytes2) {
  const buf2 = toByteView3(bytes2);
  const pbn = decodeNode(buf2);
  const node = {};
  if (pbn.Data) {
    node.Data = pbn.Data;
  }
  if (pbn.Links) {
    node.Links = pbn.Links.map((l) => {
      const link5 = {};
      try {
        link5.Hash = CID.decode(l.Hash);
      } catch (e) {
      }
      if (!link5.Hash) {
        throw new Error("Invalid Hash field found in link, expected CID");
      }
      if (l.Name !== void 0) {
        link5.Name = l.Name;
      }
      if (l.Tsize !== void 0) {
        link5.Tsize = l.Tsize;
      }
      return link5;
    });
  }
  return node;
}

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/gen/unixfs.js
var import_minimal = __toESM(require_minimal2(), 1);
var $Reader = import_minimal.default.Reader;
var $Writer = import_minimal.default.Writer;
var $util = import_minimal.default.util;
var $root = import_minimal.default.roots.unixfs || (import_minimal.default.roots.unixfs = {});
var Data = $root.Data = (() => {
  function Data2(p) {
    this.blocksizes = [];
    if (p) {
      for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
        if (p[ks[i]] != null)
          this[ks[i]] = p[ks[i]];
    }
  }
  Data2.prototype.Type = 0;
  Data2.prototype.Data = $util.newBuffer([]);
  Data2.prototype.filesize = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;
  Data2.prototype.blocksizes = $util.emptyArray;
  Data2.prototype.hashType = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;
  Data2.prototype.fanout = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;
  Data2.prototype.mode = 0;
  Data2.prototype.mtime = null;
  Data2.encode = function encode34(m, w) {
    if (!w)
      w = $Writer.create();
    w.uint32(8).int32(m.Type);
    if (m.Data != null && Object.hasOwnProperty.call(m, "Data"))
      w.uint32(18).bytes(m.Data);
    if (m.filesize != null && Object.hasOwnProperty.call(m, "filesize"))
      w.uint32(24).uint64(m.filesize);
    if (m.blocksizes != null && m.blocksizes.length) {
      for (var i = 0; i < m.blocksizes.length; ++i)
        w.uint32(32).uint64(m.blocksizes[i]);
    }
    if (m.hashType != null && Object.hasOwnProperty.call(m, "hashType"))
      w.uint32(40).uint64(m.hashType);
    if (m.fanout != null && Object.hasOwnProperty.call(m, "fanout"))
      w.uint32(48).uint64(m.fanout);
    if (m.mode != null && Object.hasOwnProperty.call(m, "mode"))
      w.uint32(56).uint32(m.mode);
    if (m.mtime != null && Object.hasOwnProperty.call(m, "mtime"))
      $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();
    return w;
  };
  Data2.decode = function decode41(r, l) {
    if (!(r instanceof $Reader))
      r = $Reader.create(r);
    var c = l === void 0 ? r.len : r.pos + l, m = new $root.Data();
    while (r.pos < c) {
      var t = r.uint32();
      switch (t >>> 3) {
        case 1:
          m.Type = r.int32();
          break;
        case 2:
          m.Data = r.bytes();
          break;
        case 3:
          m.filesize = r.uint64();
          break;
        case 4:
          if (!(m.blocksizes && m.blocksizes.length))
            m.blocksizes = [];
          if ((t & 7) === 2) {
            var c2 = r.uint32() + r.pos;
            while (r.pos < c2)
              m.blocksizes.push(r.uint64());
          } else
            m.blocksizes.push(r.uint64());
          break;
        case 5:
          m.hashType = r.uint64();
          break;
        case 6:
          m.fanout = r.uint64();
          break;
        case 7:
          m.mode = r.uint32();
          break;
        case 8:
          m.mtime = $root.UnixTime.decode(r, r.uint32());
          break;
        default:
          r.skipType(t & 7);
          break;
      }
    }
    if (!m.hasOwnProperty("Type"))
      throw $util.ProtocolError("missing required 'Type'", { instance: m });
    return m;
  };
  Data2.fromObject = function fromObject(d) {
    if (d instanceof $root.Data)
      return d;
    var m = new $root.Data();
    switch (d.Type) {
      case "Raw":
      case 0:
        m.Type = 0;
        break;
      case "Directory":
      case 1:
        m.Type = 1;
        break;
      case "File":
      case 2:
        m.Type = 2;
        break;
      case "Metadata":
      case 3:
        m.Type = 3;
        break;
      case "Symlink":
      case 4:
        m.Type = 4;
        break;
      case "HAMTShard":
      case 5:
        m.Type = 5;
        break;
    }
    if (d.Data != null) {
      if (typeof d.Data === "string")
        $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);
      else if (d.Data.length)
        m.Data = d.Data;
    }
    if (d.filesize != null) {
      if ($util.Long)
        (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;
      else if (typeof d.filesize === "string")
        m.filesize = parseInt(d.filesize, 10);
      else if (typeof d.filesize === "number")
        m.filesize = d.filesize;
      else if (typeof d.filesize === "object")
        m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);
    }
    if (d.blocksizes) {
      if (!Array.isArray(d.blocksizes))
        throw TypeError(".Data.blocksizes: array expected");
      m.blocksizes = [];
      for (var i = 0; i < d.blocksizes.length; ++i) {
        if ($util.Long)
          (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;
        else if (typeof d.blocksizes[i] === "string")
          m.blocksizes[i] = parseInt(d.blocksizes[i], 10);
        else if (typeof d.blocksizes[i] === "number")
          m.blocksizes[i] = d.blocksizes[i];
        else if (typeof d.blocksizes[i] === "object")
          m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);
      }
    }
    if (d.hashType != null) {
      if ($util.Long)
        (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;
      else if (typeof d.hashType === "string")
        m.hashType = parseInt(d.hashType, 10);
      else if (typeof d.hashType === "number")
        m.hashType = d.hashType;
      else if (typeof d.hashType === "object")
        m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);
    }
    if (d.fanout != null) {
      if ($util.Long)
        (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;
      else if (typeof d.fanout === "string")
        m.fanout = parseInt(d.fanout, 10);
      else if (typeof d.fanout === "number")
        m.fanout = d.fanout;
      else if (typeof d.fanout === "object")
        m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);
    }
    if (d.mode != null) {
      m.mode = d.mode >>> 0;
    }
    if (d.mtime != null) {
      if (typeof d.mtime !== "object")
        throw TypeError(".Data.mtime: object expected");
      m.mtime = $root.UnixTime.fromObject(d.mtime);
    }
    return m;
  };
  Data2.toObject = function toObject(m, o) {
    if (!o)
      o = {};
    var d = {};
    if (o.arrays || o.defaults) {
      d.blocksizes = [];
    }
    if (o.defaults) {
      d.Type = o.enums === String ? "Raw" : 0;
      if (o.bytes === String)
        d.Data = "";
      else {
        d.Data = [];
        if (o.bytes !== Array)
          d.Data = $util.newBuffer(d.Data);
      }
      if ($util.Long) {
        var n = new $util.Long(0, 0, true);
        d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;
      } else
        d.filesize = o.longs === String ? "0" : 0;
      if ($util.Long) {
        var n = new $util.Long(0, 0, true);
        d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;
      } else
        d.hashType = o.longs === String ? "0" : 0;
      if ($util.Long) {
        var n = new $util.Long(0, 0, true);
        d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;
      } else
        d.fanout = o.longs === String ? "0" : 0;
      d.mode = 0;
      d.mtime = null;
    }
    if (m.Type != null && m.hasOwnProperty("Type")) {
      d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;
    }
    if (m.Data != null && m.hasOwnProperty("Data")) {
      d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;
    }
    if (m.filesize != null && m.hasOwnProperty("filesize")) {
      if (typeof m.filesize === "number")
        d.filesize = o.longs === String ? String(m.filesize) : m.filesize;
      else
        d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;
    }
    if (m.blocksizes && m.blocksizes.length) {
      d.blocksizes = [];
      for (var j = 0; j < m.blocksizes.length; ++j) {
        if (typeof m.blocksizes[j] === "number")
          d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];
        else
          d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];
      }
    }
    if (m.hashType != null && m.hasOwnProperty("hashType")) {
      if (typeof m.hashType === "number")
        d.hashType = o.longs === String ? String(m.hashType) : m.hashType;
      else
        d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;
    }
    if (m.fanout != null && m.hasOwnProperty("fanout")) {
      if (typeof m.fanout === "number")
        d.fanout = o.longs === String ? String(m.fanout) : m.fanout;
      else
        d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;
    }
    if (m.mode != null && m.hasOwnProperty("mode")) {
      d.mode = m.mode;
    }
    if (m.mtime != null && m.hasOwnProperty("mtime")) {
      d.mtime = $root.UnixTime.toObject(m.mtime, o);
    }
    return d;
  };
  Data2.prototype.toJSON = function toJSON6() {
    return this.constructor.toObject(this, import_minimal.default.util.toJSONOptions);
  };
  Data2.DataType = function() {
    const valuesById = {}, values2 = Object.create(valuesById);
    values2[valuesById[0] = "Raw"] = 0;
    values2[valuesById[1] = "Directory"] = 1;
    values2[valuesById[2] = "File"] = 2;
    values2[valuesById[3] = "Metadata"] = 3;
    values2[valuesById[4] = "Symlink"] = 4;
    values2[valuesById[5] = "HAMTShard"] = 5;
    return values2;
  }();
  return Data2;
})();
var UnixTime = $root.UnixTime = (() => {
  function UnixTime2(p) {
    if (p) {
      for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
        if (p[ks[i]] != null)
          this[ks[i]] = p[ks[i]];
    }
  }
  UnixTime2.prototype.Seconds = $util.Long ? $util.Long.fromBits(0, 0, false) : 0;
  UnixTime2.prototype.FractionalNanoseconds = 0;
  UnixTime2.encode = function encode34(m, w) {
    if (!w)
      w = $Writer.create();
    w.uint32(8).int64(m.Seconds);
    if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, "FractionalNanoseconds"))
      w.uint32(21).fixed32(m.FractionalNanoseconds);
    return w;
  };
  UnixTime2.decode = function decode41(r, l) {
    if (!(r instanceof $Reader))
      r = $Reader.create(r);
    var c = l === void 0 ? r.len : r.pos + l, m = new $root.UnixTime();
    while (r.pos < c) {
      var t = r.uint32();
      switch (t >>> 3) {
        case 1:
          m.Seconds = r.int64();
          break;
        case 2:
          m.FractionalNanoseconds = r.fixed32();
          break;
        default:
          r.skipType(t & 7);
          break;
      }
    }
    if (!m.hasOwnProperty("Seconds"))
      throw $util.ProtocolError("missing required 'Seconds'", { instance: m });
    return m;
  };
  UnixTime2.fromObject = function fromObject(d) {
    if (d instanceof $root.UnixTime)
      return d;
    var m = new $root.UnixTime();
    if (d.Seconds != null) {
      if ($util.Long)
        (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;
      else if (typeof d.Seconds === "string")
        m.Seconds = parseInt(d.Seconds, 10);
      else if (typeof d.Seconds === "number")
        m.Seconds = d.Seconds;
      else if (typeof d.Seconds === "object")
        m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();
    }
    if (d.FractionalNanoseconds != null) {
      m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;
    }
    return m;
  };
  UnixTime2.toObject = function toObject(m, o) {
    if (!o)
      o = {};
    var d = {};
    if (o.defaults) {
      if ($util.Long) {
        var n = new $util.Long(0, 0, false);
        d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;
      } else
        d.Seconds = o.longs === String ? "0" : 0;
      d.FractionalNanoseconds = 0;
    }
    if (m.Seconds != null && m.hasOwnProperty("Seconds")) {
      if (typeof m.Seconds === "number")
        d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;
      else
        d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;
    }
    if (m.FractionalNanoseconds != null && m.hasOwnProperty("FractionalNanoseconds")) {
      d.FractionalNanoseconds = m.FractionalNanoseconds;
    }
    return d;
  };
  UnixTime2.prototype.toJSON = function toJSON6() {
    return this.constructor.toObject(this, import_minimal.default.util.toJSONOptions);
  };
  return UnixTime2;
})();
var Metadata = $root.Metadata = (() => {
  function Metadata2(p) {
    if (p) {
      for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
        if (p[ks[i]] != null)
          this[ks[i]] = p[ks[i]];
    }
  }
  Metadata2.prototype.MimeType = "";
  Metadata2.encode = function encode34(m, w) {
    if (!w)
      w = $Writer.create();
    if (m.MimeType != null && Object.hasOwnProperty.call(m, "MimeType"))
      w.uint32(10).string(m.MimeType);
    return w;
  };
  Metadata2.decode = function decode41(r, l) {
    if (!(r instanceof $Reader))
      r = $Reader.create(r);
    var c = l === void 0 ? r.len : r.pos + l, m = new $root.Metadata();
    while (r.pos < c) {
      var t = r.uint32();
      switch (t >>> 3) {
        case 1:
          m.MimeType = r.string();
          break;
        default:
          r.skipType(t & 7);
          break;
      }
    }
    return m;
  };
  Metadata2.fromObject = function fromObject(d) {
    if (d instanceof $root.Metadata)
      return d;
    var m = new $root.Metadata();
    if (d.MimeType != null) {
      m.MimeType = String(d.MimeType);
    }
    return m;
  };
  Metadata2.toObject = function toObject(m, o) {
    if (!o)
      o = {};
    var d = {};
    if (o.defaults) {
      d.MimeType = "";
    }
    if (m.MimeType != null && m.hasOwnProperty("MimeType")) {
      d.MimeType = m.MimeType;
    }
    return d;
  };
  Metadata2.prototype.toJSON = function toJSON6() {
    return this.constructor.toObject(this, import_minimal.default.util.toJSONOptions);
  };
  return Metadata2;
})();

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/unixfs.js
var NodeType = Data.DataType;

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/codec.js
var EMPTY2 = Object.freeze([]);
var EMPTY_BUFFER = new Uint8Array(0);
var BLANK = Object.freeze({});
var DEFAULT_FILE_MODE = parseInt("0644", 8);
var DEFAULT_DIRECTORY_MODE = parseInt("0755", 8);
var code16 = code15;
var name11 = "UnixFS";
var encodePB = (data, links3) => {
  Object(globalThis).debug && console.log({ data, links: links3 });
  return encode28(
    // We run through prepare as links need to be sorted by name which it will
    // do.
    prepare2({
      Data: Data.encode(data).finish(),
      // We can cast to mutable array as we know no mutation occurs there
      Links: (
        /** @type {PB.PBLink[]} */
        links3
      )
    })
  );
};
var createRaw = (content2) => ({
  type: NodeType.Raw,
  content: content2
});
var createEmptyFile = (metadata) => createSimpleFile(EMPTY_BUFFER, metadata);
var createSimpleFile = (content2, metadata) => ({
  type: NodeType.File,
  layout: "simple",
  content: content2,
  metadata: decodeMetadata(metadata)
});
var createFileChunk = (content2) => ({
  type: NodeType.File,
  layout: "simple",
  content: content2
});
var createAdvancedFile = (parts, metadata) => ({
  type: NodeType.File,
  layout: "advanced",
  parts,
  metadata: decodeMetadata(metadata)
});
var createFileShard = (parts) => ({
  type: NodeType.File,
  layout: "advanced",
  parts
});
var createComplexFile = (content2, parts, metadata) => ({
  type: NodeType.File,
  layout: "complex",
  content: content2,
  parts,
  metadata: decodeMetadata(metadata)
});
var createFlatDirectory = (entries3, metadata) => ({
  type: NodeType.Directory,
  metadata: decodeMetadata(metadata),
  entries: entries3
});
var createShardedDirectory = (entries3, bitfield, fanout, hashType, metadata = BLANK) => ({
  type: NodeType.HAMTShard,
  bitfield,
  fanout: readFanout(fanout),
  hashType: readInt3(hashType),
  entries: entries3,
  metadata: decodeMetadata(metadata)
});
var createDirectoryShard = (entries3, bitfield, fanout, hashType) => ({
  type: NodeType.HAMTShard,
  bitfield,
  fanout: readFanout(fanout),
  hashType: readInt3(hashType),
  entries: entries3
});
var encodeRaw = (content2) => encodePB(
  {
    Type: NodeType.Raw,
    // TODO:
    Data: content2.byteLength > 0 ? content2 : void 0,
    filesize: content2.byteLength,
    // @ts-ignore
    blocksizes: EMPTY2
  },
  []
);
var encodeFile = (node, ignoreMetadata = false) => {
  const metadata = ignoreMetadata ? BLANK : Object(node).metadata;
  switch (node.layout) {
    case "simple":
      return encodeSimpleFile(node.content, metadata);
    case "advanced":
      return encodeAdvancedFile(node.parts, metadata);
    case "complex":
      return encodeComplexFile(node.content, node.parts, metadata);
    default:
      throw new TypeError(
        `File with unknown layout "${Object(node).layout}" was passed`
      );
  }
};
var encodeFileChunk = (content2) => encodeSimpleFile(content2, BLANK);
var encodeFileShard = (parts) => encodePB(
  {
    Type: NodeType.File,
    blocksizes: parts.map(contentByteLength),
    filesize: cumulativeContentByteLength(parts)
  },
  parts.map(encodeLink2)
);
var encodeAdvancedFile = (parts, metadata = BLANK) => encodePB(
  {
    Type: NodeType.File,
    blocksizes: parts.map(contentByteLength),
    filesize: cumulativeContentByteLength(parts),
    ...encodeMetadata(metadata)
  },
  parts.map(encodeLink2)
);
var encodeLink2 = (dag) => ({
  Name: "",
  Tsize: dag.dagByteLength,
  // @ts-ignore - @see https://github.com/multiformats/js-multiformats/pull/161
  Hash: dag.cid
});
var encodeSimpleFile = (content2, metadata = BLANK) => encodePB(
  {
    Type: NodeType.File,
    // adding empty file to both go-ipfs and js-ipfs produces block in
    // which `Data` is omitted but filesize and blocksizes are present.
    // For the sake of hash consistency we do the same.
    Data: content2.byteLength > 0 ? content2 : void 0,
    filesize: content2.byteLength,
    blocksizes: [],
    ...encodeMetadata(metadata)
  },
  []
);
var encodeComplexFile = (content2, parts, metadata = BLANK) => encodePB(
  {
    Type: NodeType.File,
    Data: content2,
    filesize: content2.byteLength + cumulativeContentByteLength(parts),
    blocksizes: parts.map(contentByteLength)
  },
  parts.map(encodeLink2)
);
var encodeDirectory = (node) => encodePB(
  {
    Type: node.type,
    ...encodeDirectoryMetadata(node.metadata || BLANK)
  },
  node.entries.map(encodeNamedLink)
);
var encodeHAMTShard = ({
  bitfield,
  fanout,
  hashType,
  entries: entries3,
  metadata = BLANK
}) => encodePB(
  {
    Type: NodeType.HAMTShard,
    Data: bitfield.byteLength > 0 ? bitfield : void 0,
    fanout: readFanout(fanout),
    hashType: readInt3(hashType),
    ...encodeDirectoryMetadata(metadata)
  },
  entries3.map(encodeNamedLink)
);
var readFanout = (n) => {
  if (Math.log2(n) % 1 === 0) {
    return n;
  } else {
    throw new TypeError(
      `Expected hamt size to be a power of two instead got ${n}`
    );
  }
};
var readInt3 = (n) => {
  if (Number.isInteger(n)) {
    return n;
  } else {
    throw new TypeError(`Expected an integer value instead got ${n}`);
  }
};
var createSymlink = (path, metadata = BLANK) => ({
  type: NodeType.Symlink,
  content: path,
  metadata: decodeMetadata(metadata)
});
var encodeSymlink = (node, ignoreMetadata = false) => {
  const metadata = ignoreMetadata ? BLANK : Object(node).metadata;
  return encodePB(
    {
      Type: NodeType.Symlink,
      Data: node.content,
      ...encodeMetadata(metadata || BLANK)
    },
    []
  );
};
var encode29 = (node, root2 = true) => {
  switch (node.type) {
    case NodeType.Raw:
      return encodeRaw(node.content);
    case NodeType.File:
      return encodeFile(node);
    case NodeType.Directory:
      return encodeDirectory(node);
    case NodeType.HAMTShard:
      return encodeHAMTShard(node);
    case NodeType.Symlink:
      return encodeSymlink(node);
    default:
      throw new Error(`Unknown node type ${Object(node).type}`);
  }
};
var decode38 = (bytes2) => {
  const pb = decode37(bytes2);
  const message = Data.decode(
    /** @type {Uint8Array} */
    pb.Data
  );
  const {
    Type: type2,
    Data: data,
    mtime,
    mode,
    blocksizes,
    ...rest
  } = Data.toObject(message, {
    defaults: false,
    arrays: true,
    longs: Number,
    objects: false
  });
  const metadata = {
    ...mode && { mode },
    ...decodeMtime(mtime)
  };
  const links3 = pb.Links;
  switch (message.Type) {
    case NodeType.Raw:
      return createRaw(data);
    case NodeType.File:
      if (links3.length === 0) {
        return new SimpleFileView(data, metadata);
      } else if (data.byteLength === 0) {
        return new AdvancedFileView(
          decodeFileLinks(rest.blocksizes, links3),
          metadata
        );
      } else {
        return new ComplexFileView(
          data,
          decodeFileLinks(rest.blocksizes, links3),
          metadata
        );
      }
    case NodeType.Directory:
      return createFlatDirectory(decodeDirectoryLinks(links3), metadata);
    case NodeType.HAMTShard:
      return createShardedDirectory(
        decodeDirectoryLinks(links3),
        data || EMPTY_BUFFER,
        rest.fanout,
        rest.hashType,
        metadata
      );
    case NodeType.Symlink:
      return createSymlink(data, metadata);
    default:
      throw new TypeError(`Unsupported node type ${message.Type}`);
  }
};
var decodeMtime = (mtime) => mtime == null ? void 0 : {
  mtime: { secs: mtime.Seconds, nsecs: mtime.FractionalNanoseconds || 0 }
};
var decodeFileLinks = (blocksizes, links3) => {
  const parts = [];
  const length4 = blocksizes.length;
  let n = 0;
  while (n < length4) {
    parts.push(
      /** @type {UnixFS.FileLink} */
      {
        cid: links3[n].Hash,
        dagByteLength: links3[n].Tsize || 0,
        contentByteLength: blocksizes[n]
      }
    );
  }
  return parts;
};
var decodeDirectoryLinks = (links3) => links3.map(
  (link5) => (
    /** @type {UnixFS.DirectoryEntryLink} */
    {
      cid: link5.Hash,
      name: link5.Name || "",
      dagByteLength: link5.Tsize || 0
    }
  )
);
var cumulativeContentByteLength = (links3) => links3.reduce((size5, link5) => size5 + link5.contentByteLength, 0);
var cumulativeDagByteLength = (root2, links3) => links3.reduce((size5, link5) => size5 + link5.dagByteLength, root2.byteLength);
var contentByteLength = (link5) => link5.contentByteLength;
var encodeNamedLink = ({ name: name14, dagByteLength, cid }) => ({
  Name: name14,
  Tsize: dagByteLength,
  Hash: cid
});
var encodeDirectoryMetadata = (metadata) => encodeMetadata(metadata, DEFAULT_DIRECTORY_MODE);
var encodeMetadata = ({ mode, mtime }, defaultMode = DEFAULT_FILE_MODE) => ({
  mode: mode != null ? encodeMode(mode, defaultMode) : void 0,
  mtime: mtime != null ? encodeMTime(mtime) : void 0
});
var decodeMetadata = (data) => data == null ? BLANK : {
  ...data.mode == null ? void 0 : { mode: decodeMode(data.mode) },
  ...data.mtime == null ? void 0 : { mtime: data.mtime }
};
var encodeMTime = (mtime) => {
  return mtime == null ? void 0 : mtime.nsecs !== 0 ? { Seconds: mtime.secs, FractionalNanoseconds: mtime.nsecs } : { Seconds: mtime.secs };
};
var encodeMode = (specifiedMode, defaultMode) => {
  const mode = specifiedMode == null ? void 0 : decodeMode(specifiedMode);
  return mode === defaultMode || mode == null ? void 0 : mode;
};
var decodeMode = (mode) => mode & 4095 | mode & 4294963200;
var matchFile = ({
  content: content2 = EMPTY_BUFFER,
  parts = EMPTY2,
  metadata = BLANK,
  ...rest
}) => {
  if (parts.length === 0) {
    return new SimpleFileView(content2, metadata);
  } else if (content2.byteLength === 0) {
    return new AdvancedFileView(parts, metadata);
  } else {
    return new ComplexFileView(content2, parts, metadata);
  }
};
var SimpleFileView = class {
  /**
   * @param {Uint8Array} content
   * @param {UnixFS.Metadata} metadata
   */
  constructor(content2, metadata) {
    this.content = content2;
    this.metadata = metadata;
    this.layout = "simple";
    this.type = NodeType.File;
  }
  get filesize() {
    return this.content.byteLength;
  }
  encode() {
    return encodeSimpleFile(this.content, this.metadata);
  }
};
var AdvancedFileView = class {
  /**
   * @param {ReadonlyArray<UnixFS.FileLink>} parts
   * @param {UnixFS.Metadata} metadata
   */
  constructor(parts, metadata) {
    this.parts = parts;
    this.metadata = metadata;
  }
  /** @type {"advanced"} */
  get layout() {
    return "advanced";
  }
  /**
   * @returns {NodeType.File}
   */
  get type() {
    return NodeType.File;
  }
  get fileSize() {
    return cumulativeContentByteLength(this.parts);
  }
  get blockSizes() {
    return this.parts.map(contentByteLength);
  }
  encode() {
    return encodeAdvancedFile(this.parts, this.metadata);
  }
};
var ComplexFileView = class {
  /**
   * @param {Uint8Array} content
   * @param {ReadonlyArray<UnixFS.FileLink>} parts
   * @param {UnixFS.Metadata} metadata
   */
  constructor(content2, parts, metadata) {
    this.content = content2;
    this.parts = parts;
    this.metadata = metadata;
  }
  /** @type {"complex"} */
  get layout() {
    return "complex";
  }
  /**
   * @returns {NodeType.File}
   */
  get type() {
    return NodeType.File;
  }
  get fileSize() {
    return this.content.byteLength + cumulativeContentByteLength(this.parts);
  }
  get blockSizes() {
    return this.parts.map(contentByteLength);
  }
  encode() {
    return encodeComplexFile(this.content, this.parts, this.metadata);
  }
};
var filesize = (node) => {
  switch (node.type) {
    case NodeType.Raw:
    case NodeType.Symlink:
      return node.content.byteLength;
    case NodeType.File:
      switch (node.layout) {
        case "simple":
          return node.content.byteLength;
        case "advanced":
          return cumulativeContentByteLength(node.parts);
        case "complex":
          return node.content.byteLength + cumulativeContentByteLength(node.parts);
      }
    default:
      return 0;
  }
};

// ../../node_modules/.pnpm/actor@2.3.1/node_modules/actor/src/lib.js
var effect = function* (task) {
  const message = yield* task;
  yield* send(message);
};
function* current() {
  return (
    /** @type {Task.Controller<T, X, M>} */
    yield CURRENT
  );
}
var suspend = function* () {
  yield SUSPEND;
};
var wait = function* (input10) {
  const task = yield* current();
  if (isAsync(input10)) {
    let failed = false;
    let output = void 0;
    input10.then(
      (value) => {
        failed = false;
        output = value;
        enqueue(task);
      },
      (error3) => {
        failed = true;
        output = error3;
        enqueue(task);
      }
    );
    yield* suspend();
    if (failed) {
      throw output;
    } else {
      return (
        /** @type {T} */
        output
      );
    }
  } else {
    main(wake(task));
    yield* suspend();
    return input10;
  }
};
function* wake(task) {
  enqueue(task);
}
var isAsync = (node) => node != null && typeof /** @type {{then?:unknown}} */
node.then === "function";
var send = function* (message) {
  yield (
    /** @type {Task.Message<T>} */
    message
  );
};
var listen = function* (source) {
  const forks = [];
  for (const entry of Object.entries(source)) {
    const [name14, effect2] = (
      /** @type {[Tag, Task.Effect<T>]} */
      entry
    );
    if (effect2 !== NONE) {
      forks.push(yield* fork(tag(effect2, name14)));
    }
  }
  yield* group(forks);
};
var effects = (tasks) => tasks.length > 0 ? batch(tasks.map(effect)) : NONE;
function* batch(effects2) {
  const forks = [];
  for (const effect2 of effects2) {
    forks.push(yield* fork(effect2));
  }
  yield* group(forks);
}
var tag = (effect2, tag2) => (
  // @ts-ignore
  effect2 === NONE ? NONE : effect2 instanceof Tagger ? new Tagger([...effect2.tags, tag2], effect2.source) : new Tagger([tag2], effect2)
);
var Tagger = class {
  /**
   * @param {Task.Task<Success, Failure, Message>} source
   * @param {string[]} tags
   */
  constructor(tags, source) {
    this.tags = tags;
    this.source = source;
    this.controller;
  }
  /* c8 ignore next 3 */
  [Symbol.iterator]() {
    if (!this.controller) {
      this.controller = this.source[Symbol.iterator]();
    }
    return this;
  }
  /**
   * @param {Task.TaskState<Success, Message>} state
   * @returns {Task.TaskState<Success, Tagged<Tag, Message>>}
   */
  box(state) {
    if (state.done) {
      return state;
    } else {
      switch (state.value) {
        case SUSPEND:
        case CURRENT:
          return (
            /** @type {Task.TaskState<Success, Tagged<Tag, Message>>} */
            state
          );
        default: {
          const tagged = (
            /** @type {{ done: false, value: any }} */
            state
          );
          let { value } = tagged;
          for (const tag2 of this.tags) {
            value = withTag(tag2, value);
          }
          tagged.value = value;
          return tagged;
        }
      }
    }
  }
  /**
   *
   * @param {Task.Instruction<Message>} instruction
   */
  next(instruction) {
    return this.box(this.controller.next(instruction));
  }
  /**
   *
   * @param {Failure} error
   */
  throw(error3) {
    return this.box(this.controller.throw(error3));
  }
  /**
   * @param {Success} value
   */
  return(value) {
    return this.box(this.controller.return(value));
  }
  get [Symbol.toStringTag]() {
    return "TaggedEffect";
  }
};
var none = () => NONE;
var withTag = (tag2, value) => (
  /** @type {Tagged<Tag, T>} */
  { type: tag2, [tag2]: value }
);
var CURRENT = Symbol("current");
var SUSPEND = Symbol("suspend");
var Group = class _Group {
  /**
   * @template T, X, M
   * @param {Task.Controller<T, X, M>|Task.Fork<T, X, M>} member
   * @returns {Task.Group<T, X, M>}
   */
  static of(member) {
    return (
      /** @type {{group?:Task.TaskGroup<T, X, M>}} */
      member.group || MAIN
    );
  }
  /**
   * @template T, X, M
   * @param {(Task.Controller<T, X, M>|Task.Fork<T, X, M>) & {group?:Task.TaskGroup<T, X, M>}} member
   * @param {Task.TaskGroup<T, X, M>} group
   */
  static enqueue(member, group2) {
    member.group = group2;
    group2.stack.active.push(member);
  }
  /**
   * @param {Task.Controller<T, X, M>} driver
   * @param {Task.Controller<T, X, M>[]} [active]
   * @param {Set<Task.Controller<T, X, M>>} [idle]
   * @param {Task.Stack<T, X, M>} [stack]
   */
  constructor(driver, active = [], idle = /* @__PURE__ */ new Set(), stack = new Stack(active, idle)) {
    this.driver = driver;
    this.parent = _Group.of(driver);
    this.stack = stack;
    this.id = ++ID;
  }
};
var Main = class {
  constructor() {
    this.status = IDLE;
    this.stack = new Stack();
    this.id = /** @type {0} */
    0;
  }
};
var Stack = class {
  /**
   * @param {Task.Controller<T, X, M>[]} [active]
   * @param {Set<Task.Controller<T, X, M>>} [idle]
   */
  constructor(active = [], idle = /* @__PURE__ */ new Set()) {
    this.active = active;
    this.idle = idle;
  }
  /**
   *
   * @param {Task.Stack<unknown, unknown, unknown>} stack
   * @returns
   */
  static size({ active, idle }) {
    return active.length + idle.size;
  }
};
var main = (task) => enqueue(task[Symbol.iterator]());
var enqueue = (task) => {
  let group2 = Group.of(task);
  group2.stack.active.push(task);
  group2.stack.idle.delete(task);
  while (group2.parent) {
    const { idle, active } = group2.parent.stack;
    if (idle.has(group2.driver)) {
      idle.delete(group2.driver);
      active.push(group2.driver);
    } else {
      break;
    }
    group2 = group2.parent;
  }
  if (MAIN.status === IDLE) {
    MAIN.status = ACTIVE;
    while (true) {
      try {
        for (const _message of step(MAIN)) {
        }
        MAIN.status = IDLE;
        break;
      } catch (_error) {
        MAIN.stack.active.shift();
      }
    }
  }
};
var resume = (task) => enqueue(task);
var step = function* (group2) {
  const { active } = group2.stack;
  let task = active[0];
  group2.stack.idle.delete(task);
  while (task) {
    let state = INIT;
    loop: while (!state.done && task === active[0]) {
      const instruction = state.value;
      switch (instruction) {
        case SUSPEND:
          group2.stack.idle.add(task);
          break loop;
        case CURRENT:
          state = task.next(task);
          break;
        default:
          state = task.next(
            yield (
              /** @type {M & Task.Message<M>}*/
              instruction
            )
          );
          break;
      }
    }
    active.shift();
    task = active[0];
    group2.stack.idle.delete(task);
  }
};
var fork = (task, options) => new Fork(task, options);
var exit = (handle, value) => conclude2(handle, { ok: true, value });
var abort = (handle, error3) => conclude2(handle, { ok: false, error: error3 });
function* conclude2(handle, result) {
  try {
    const task = handle;
    const state = result.ok ? task.return(result.value) : task.throw(result.error);
    if (!state.done) {
      if (state.value === SUSPEND) {
        const { idle } = Group.of(task).stack;
        idle.add(task);
      } else {
        enqueue(task);
      }
    }
  } catch (error3) {
  }
}
function* group(forks) {
  if (forks.length === 0) return;
  const self2 = yield* current();
  const group2 = new Group(self2);
  let failure = null;
  for (const fork5 of forks) {
    const { result } = fork5;
    if (result) {
      if (!result.ok && !failure) {
        failure = result;
      }
      continue;
    }
    move(fork5, group2);
  }
  try {
    if (failure) {
      throw failure.error;
    }
    while (true) {
      yield* step(group2);
      if (Stack.size(group2.stack) > 0) {
        yield* suspend();
      } else {
        break;
      }
    }
  } catch (error3) {
    for (const task of group2.stack.active) {
      yield* abort(task, error3);
    }
    for (const task of group2.stack.idle) {
      yield* abort(task, error3);
      enqueue(task);
    }
    throw error3;
  }
}
var move = (fork5, group2) => {
  const from19 = Group.of(fork5);
  if (from19 !== group2) {
    const { active, idle } = from19.stack;
    const target = group2.stack;
    fork5.group = group2;
    if (idle.has(fork5)) {
      idle.delete(fork5);
      target.idle.add(fork5);
    } else {
      const index2 = active.indexOf(fork5);
      if (index2 >= 0) {
        active.splice(index2, 1);
        target.active.push(fork5);
      }
    }
  }
};
function* join(fork5) {
  if (fork5.status === IDLE) {
    yield* fork5;
  }
  if (!fork5.result) {
    yield* group([fork5]);
  }
  const result = (
    /** @type {Task.Result<T, X>} */
    fork5.result
  );
  if (result.ok) {
    return result.value;
  } else {
    throw result.error;
  }
}
var Future = class {
  /**
   * @param {Task.StateHandler<T, X>} handler
   */
  constructor(handler) {
    this.handler = handler;
    this.result;
  }
  /**
   * @type {Promise<T>}
   */
  get promise() {
    const { result } = this;
    const promise = result == null ? new Promise((succeed, fail3) => {
      this.handler.onsuccess = succeed;
      this.handler.onfailure = fail3;
    }) : result.ok ? Promise.resolve(result.value) : Promise.reject(result.error);
    Object.defineProperty(this, "promise", { value: promise });
    return promise;
  }
  /**
   * @template U, [E=never]
   * @param {((value:T) => U | PromiseLike<U>)|undefined|null} [onresolve]
   * @param {((error:X) => E|PromiseLike<E>)|undefined|null} [onreject]
   * @returns {Promise<U|E>}
   */
  then(onresolve, onreject) {
    return this.activate().promise.then(onresolve, onreject);
  }
  /**
   * @template [U=never]
   * @param {(error:X) => U} onreject
   */
  catch(onreject) {
    return (
      /** @type {Task.Future<T|U, never>} */
      this.activate().promise.catch(onreject)
    );
  }
  /**
   * @param {() => void} onfinally
   * @returns {Task.Future<T, X>}
   */
  finally(onfinally) {
    return (
      /** @type {Task.Future<T, X>} */
      this.activate().promise.finally(onfinally)
    );
  }
  /**
   * @abstract
   */
  /* c8 ignore next 3 */
  activate() {
    return this;
  }
};
var Fork = class extends Future {
  /**
   * @param {Task.Task<T, X, M>} task
   * @param {Task.ForkOptions} [options]
   * @param {Task.StateHandler<T, X>} [handler]
   * @param {Task.TaskState<T, M>} [state]
   */
  constructor(task, options = BLANK2, handler = {}, state = INIT) {
    super(handler);
    this.id = ++ID;
    this.name = options.name || "";
    this.task = task;
    this.state = state;
    this.status = IDLE;
    this.result;
    this.handler = handler;
    this.controller;
  }
  *resume() {
    resume(this);
  }
  /**
   * @returns {Task.Task<T, X, M>}
   */
  join() {
    return join(this);
  }
  /**
   * @param {X} error
   */
  abort(error3) {
    return abort(this, error3);
  }
  /**
   * @param {T} value
   */
  exit(value) {
    return exit(this, value);
  }
  get [Symbol.toStringTag]() {
    return "Fork";
  }
  /**
   * @returns {Task.Controller<Task.Fork<T, X, M>, never, never>}
   */
  *[Symbol.iterator]() {
    return this.activate();
  }
  activate() {
    this.controller = this.task[Symbol.iterator]();
    this.status = ACTIVE;
    enqueue(this);
    return this;
  }
  /**
   * @private
   * @param {any} error
   * @returns {never}
   */
  panic(error3) {
    this.result = { ok: false, error: error3 };
    this.status = FINISHED;
    const { handler } = this;
    if (handler.onfailure) {
      handler.onfailure(error3);
    }
    throw error3;
  }
  /**
   * @private
   * @param {Task.TaskState<T, M>} state
   */
  step(state) {
    this.state = state;
    if (state.done) {
      this.result = { ok: true, value: state.value };
      this.status = FINISHED;
      const { handler } = this;
      if (handler.onsuccess) {
        handler.onsuccess(state.value);
      }
    }
    return state;
  }
  /**
   * @param {unknown} value
   */
  next(value) {
    try {
      return this.step(this.controller.next(value));
    } catch (error3) {
      return this.panic(error3);
    }
  }
  /**
   * @param {T} value
   */
  return(value) {
    try {
      return this.step(this.controller.return(value));
    } catch (error3) {
      return this.panic(error3);
    }
  }
  /**
   * @param {X} error
   */
  throw(error3) {
    try {
      return this.step(this.controller.throw(error3));
    } catch (error4) {
      return this.panic(error4);
    }
  }
};
var loop = function* (init2, next) {
  const controller = yield* current();
  const group2 = new Group(controller);
  Group.enqueue(init2[Symbol.iterator](), group2);
  while (true) {
    for (const message of step(group2)) {
      Group.enqueue(next(message)[Symbol.iterator](), group2);
    }
    if (Stack.size(group2.stack) > 0) {
      yield* suspend();
    } else {
      break;
    }
  }
};
var ID = 0;
var IDLE = "idle";
var ACTIVE = "active";
var FINISHED = "finished";
var INIT = { done: false, value: CURRENT };
var BLANK2 = {};
var NONE = function* none2() {
}();
var MAIN = new Main();

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/chunker/indexed.js
function Indexed() {
}
Object.defineProperties(Indexed, {
  prototype: {
    value: new Proxy(Object.prototype, {
      /**
       * @param {object} target
       * @param {PropertyKey} property
       * @param {{get(key:PropertyKey): any}} receiver
       */
      get(target, property, receiver) {
        return typeof property === "symbol" ? Reflect.get(target, property, receiver) : receiver.get(property);
      }
    })
  }
});

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/chunker/buffer.js
var empty5 = () => new BufferView();
var slice2 = (buffer2, startOffset = 0, endOffset = buffer2.byteLength) => {
  const segments = [];
  const start = startOffset < 0 ? buffer2.byteLength - startOffset : startOffset;
  const end = endOffset < 0 ? buffer2.byteLength - endOffset : endOffset;
  if (start === 0 && end >= buffer2.byteLength) {
    return buffer2;
  }
  if (start > end || start > buffer2.byteLength || end <= 0) {
    return empty5();
  }
  let byteLength = 0;
  let offset2 = 0;
  for (const segment of buffer2.segments) {
    const nextOffset = offset2 + segment.byteLength;
    if (byteLength === 0) {
      if (end <= nextOffset) {
        const range = segment.subarray(start - offset2, end - offset2);
        segments.push(range);
        byteLength = range.byteLength;
        break;
      } else if (start < nextOffset) {
        const range = start === offset2 ? segment : segment.subarray(start - offset2);
        segments.push(range);
        byteLength = range.byteLength;
      }
    } else if (end <= nextOffset) {
      const range = end === nextOffset ? segment : segment.subarray(0, end - offset2);
      segments.push(range);
      byteLength += range.byteLength;
      break;
    } else {
      segments.push(segment);
      byteLength += segment.byteLength;
    }
    offset2 = nextOffset;
  }
  return new BufferView(segments, buffer2.byteOffset + start, byteLength);
};
var push = (buffer2, part) => {
  if (part.byteLength > 0) {
    buffer2.segments.push(part);
    return new BufferView(
      buffer2.segments,
      buffer2.byteOffset,
      buffer2.byteLength + part.byteLength
    );
  } else {
    return buffer2;
  }
};
var get9 = (buffer2, n) => {
  if (n < buffer2.byteLength) {
    let offset2 = 0;
    for (const segment of buffer2.segments) {
      if (n < offset2 + segment.byteLength) {
        return segment[n - offset2];
      } else {
        offset2 += segment.byteLength;
      }
    }
  }
  return void 0;
};
var copyTo = (buffer2, target, byteOffset) => {
  let offset2 = byteOffset;
  for (const segment of buffer2.segments) {
    target.set(segment, offset2);
    offset2 += segment.byteLength;
  }
  return target;
};
function* iterate2(buffer2) {
  for (const part of buffer2.segments) {
    yield* part;
  }
}
var BufferView = class extends Indexed {
  /**
   * @param {Uint8Array[]} segments
   * @param {number} byteOffset
   * @param {number} byteLength
   */
  constructor(segments = [], byteOffset = 0, byteLength = 0) {
    super();
    this.segments = segments;
    this.byteLength = byteLength;
    this.length = byteLength;
    this.byteOffset = byteOffset;
  }
  [Symbol.iterator]() {
    return iterate2(this);
  }
  /**
   * @param {number} [start]
   * @param {number} [end]
   */
  slice(start, end) {
    return (
      /** @type {BufferView} */
      slice2(this, start, end)
    );
  }
  /**
   * @param {number} [start]
   * @param {number} [end]
   */
  subarray(start, end) {
    return (
      /** @type {BufferView} */
      slice2(this, start, end)
    );
  }
  /**
   *
   * @param {Uint8Array} bytes
   */
  push(bytes2) {
    return (
      /** @type {BufferView} */
      push(this, bytes2)
    );
  }
  /**
   * @param {number} n
   */
  get(n) {
    return get9(this, n);
  }
  /**
   *
   * @param {Uint8Array} target
   * @param {number} offset
   */
  copyTo(target, offset2) {
    return copyTo(this, target, offset2);
  }
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/writer/util.js
var panic2 = (reason) => {
  throw new Error(reason);
};
var unreachable = (template, subject, ...substitutions) => panic2(String.raw(template, JSON.stringify(subject), ...substitutions));
var EMPTY_BUFFER2 = new Uint8Array(0);
var EMPTY3 = [];

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/chunker.js
var open2 = (config2) => ({
  config: config2,
  buffer: empty5()
});
var write4 = (state, bytes2) => bytes2.byteLength > 0 ? split2(state.config, state.buffer.push(bytes2), false) : { ...state, chunks: EMPTY3 };
var close2 = (state) => split2(state.config, state.buffer, true);
var split2 = (config2, buffer2, end) => {
  const chunker = config2.chunker;
  const chunks = [];
  let offset2 = 0;
  for (const size5 of chunker.cut(chunker.context, buffer2, end)) {
    if (size5 > 0) {
      const chunk = buffer2.subarray(offset2, offset2 + size5);
      chunks.push(chunk);
      offset2 += size5;
    }
  }
  return { config: config2, chunks, buffer: buffer2.subarray(offset2) };
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/layout/queue.js
var mutable = () => ({
  mutable: true,
  needs: {},
  nodes: {},
  links: {},
  linked: EMPTY4
});
var addNodes = (newNodes, input10) => {
  let queue = patch(input10, {});
  for (const node of newNodes) {
    const { ready, has: has2, wants } = collect(node.children, queue.links);
    if (wants.length === 0) {
      queue = patch(queue, {
        links: assign(void 0, has2),
        linked: [{ id: node.id, links: ready }]
      });
    } else {
      queue = patch(queue, {
        needs: assign(node.id, wants),
        nodes: {
          [node.id]: {
            children: node.children,
            count: wants.length
          }
        }
      });
    }
  }
  return queue;
};
var addLink = (id, link5, queue) => {
  const nodeID = queue.needs[id];
  const node = queue.nodes[nodeID];
  if (node != null) {
    if (node.count === 1) {
      const { ready, has: has2 } = collect(node.children, {
        ...queue.links,
        [id]: link5
      });
      return patch(queue, {
        needs: { [id]: void 0 },
        links: assign(void 0, has2),
        nodes: { [nodeID]: void 0 },
        linked: [{ id: nodeID, links: ready }]
      });
    } else {
      return patch(queue, {
        needs: { [id]: void 0 },
        links: { [id]: link5 },
        nodes: {
          [nodeID]: {
            ...node,
            count: node.count - 1
          }
        }
      });
    }
  } else {
    return patch(queue, {
      links: { [id]: link5 }
    });
  }
};
var patch = (queue, { needs, nodes, links: links3, linked }) => {
  const result = queue.mutable ? queue : { ...queue };
  const original = queue.mutable ? BLANK3 : void 0;
  if (needs) {
    result.needs = patchDict(queue.needs, needs, original);
  }
  if (nodes) {
    result.nodes = patchDict(queue.nodes, nodes, original);
  }
  if (links3) {
    result.links = patchDict(queue.links, links3, original);
  }
  result.linked = linked ? append(queue.linked || EMPTY4, linked, EMPTY4) : queue.linked || [];
  return (
    /** @type {Queue.Result} */
    result
  );
};
var assign = (value, keys2) => {
  const delta = (
    /** @type {Record<K, V>} */
    {}
  );
  for (const key of keys2) {
    delta[key] = value;
  }
  return delta;
};
var patchDict = (target, delta, original = target) => {
  const result = target === original ? { ...target } : target;
  for (const entry of Object.entries(delta)) {
    const [id, value] = (
      /** @type {[K, V|void]} */
      entry
    );
    if (value == null) {
      delete result[id];
    } else {
      result[id] = value;
    }
  }
  return result;
};
var append = (target, items, original = target) => {
  if (target === original) {
    return [...target, ...items];
  } else {
    for (const item of items) {
      target.push(item);
    }
    return target;
  }
};
var collect = (children, source) => {
  const has2 = [];
  const wants = [];
  const ready = [];
  for (const child of children) {
    const link5 = source[child];
    if (link5) {
      has2.push(child);
      ready.push(link5);
    } else {
      wants.push(child);
    }
  }
  return { has: has2, wants, ready };
};
var EMPTY4 = (
  /** @type {never[]} */
  Object.freeze([])
);
var BLANK3 = (
  /** @type {Record<never, never>} */
  Object.freeze({})
);

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/writer.js
var update = (message, state) => {
  switch (message.type) {
    case "write":
      return write5(state, message.bytes);
    case "link":
      return link4(state, message.link);
    case "block":
      return { state, effect: none() };
    case "close":
      return close3(state);
    case "end":
      return { state, effect: none() };
    default:
      return unreachable`File Writer got unknown message ${message}`;
  }
};
var init = (writer, metadata, config2) => {
  return {
    status: "open",
    metadata,
    config: config2,
    writer,
    chunker: open2({ chunker: config2.chunker }),
    layout: config2.fileLayout.open(),
    // Note: Writing in large slices e.g. 1GiB at a time creates large queues
    // with around `16353` items. Immutable version ends up copying it every
    // time state of the queue changes, which introduces significant overhead.
    // To avoid this overhead we use mutable implementation which is API
    // compatible but makes in place updates.
    // TODO: We should consider using Persistent bit-partitioned vector tries
    // instead of arrays which would provide immutable interface with neglegable
    // overhead.
    // @see https://github.com/Gozala/vectrie
    nodeQueue: mutable()
  };
};
var write5 = (state, bytes2) => {
  if (state.status === "open") {
    const { chunks, ...chunker } = write4(state.chunker, bytes2);
    const { nodes, leaves, layout } = state.config.fileLayout.write(
      state.layout,
      chunks
    );
    const { linked, ...nodeQueue } = addNodes(nodes, state.nodeQueue);
    const tasks = [
      ...encodeLeaves(leaves, state.config),
      ...encodeBranches(linked, state.config)
    ];
    return {
      state: {
        ...state,
        chunker,
        layout,
        nodeQueue
      },
      effect: listen({
        link: effects(tasks)
      })
    };
  } else {
    return panic2("Unable to perform write on closed file");
  }
};
var link4 = (state, { id, link: link5, block }) => {
  let { linked, ...nodeQueue } = addLink(id, link5, state.nodeQueue);
  const tasks = encodeBranches(linked, state.config);
  const newState = state.status === "closed" && id === state.rootID ? {
    ...state,
    status: "linked",
    link: link5,
    nodeQueue
  } : { ...state, nodeQueue };
  const end = state.status === "closed" && id === state.rootID && state.end ? state.end.resume() : none();
  return {
    state: newState,
    effect: listen({
      link: effects(tasks),
      block: writeBlock(state.writer, block),
      end
    })
  };
};
var close3 = (state) => {
  if (state.status === "open") {
    const { chunks } = close2(state.chunker);
    const { layout, ...write8 } = state.config.fileLayout.write(
      state.layout,
      chunks
    );
    const { root: root2, ...close9 } = state.config.fileLayout.close(
      layout,
      state.metadata
    );
    const [nodes, leaves] = isLeafNode(root2) ? [
      [...write8.nodes, ...close9.nodes],
      [...write8.leaves, ...close9.leaves, root2]
    ] : [
      [...write8.nodes, ...close9.nodes, root2],
      [...write8.leaves, ...close9.leaves]
    ];
    const { linked, ...nodeQueue } = addNodes(nodes, state.nodeQueue);
    const tasks = [
      ...encodeLeaves(leaves, state.config),
      ...encodeBranches(linked, state.config)
    ];
    const fork5 = fork(suspend());
    return {
      state: {
        ...state,
        chunker: null,
        layout: null,
        rootID: root2.id,
        status: "closed",
        end: fork5,
        nodeQueue
      },
      effect: listen({
        link: effects(tasks),
        end: join(fork5)
      })
    };
  } else {
    return { state, effect: none() };
  }
};
var encodeLeaves = (leaves, config2) => leaves.map((leaf) => encodeLeaf(config2, leaf, config2.fileChunkEncoder));
var encodeLeaf = function* ({ hasher, linker }, { id, content: content2 }, encoder3) {
  const bytes2 = encoder3.encode(content2 ? asUint8Array(content2) : EMPTY_BUFFER2);
  const hash = yield* wait(hasher.digest(bytes2));
  const cid = linker.createLink(encoder3.code, hash);
  const block = { cid, bytes: bytes2 };
  const link5 = (
    /** @type {UnixFS.FileLink} */
    {
      cid,
      contentByteLength: content2 ? content2.byteLength : 0,
      dagByteLength: bytes2.byteLength
    }
  );
  return { id, block, link: link5 };
};
var encodeBranches = (nodes, config2) => nodes.map((node) => encodeBranch(config2, node));
var encodeBranch = function* (config2, { id, links: links3 }, metadata) {
  const bytes2 = config2.fileEncoder.encode({
    type: NodeType.File,
    layout: "advanced",
    parts: links3,
    metadata
  });
  const hash = yield* wait(Promise.resolve(config2.hasher.digest(bytes2)));
  const cid = config2.linker.createLink(config2.fileEncoder.code, hash);
  const block = { bytes: bytes2, cid };
  const link5 = (
    /** @type {UnixFS.FileLink} */
    {
      cid,
      contentByteLength: cumulativeContentByteLength(links3),
      dagByteLength: cumulativeDagByteLength(bytes2, links3)
    }
  );
  return { id, block, link: link5 };
};
var writeBlock = function* (writer, block) {
  if ((writer.desiredSize || 0) <= 0) {
    yield* wait(writer.ready);
  }
  writer.write(block);
};
var asUint8Array = (buffer2) => buffer2 instanceof Uint8Array ? buffer2 : buffer2.copyTo(new Uint8Array(buffer2.byteLength), 0);
var isLeafNode = (node) => node.children == null;

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/chunker/fixed.js
var fixed_exports = {};
__export(fixed_exports, {
  context: () => context,
  cut: () => cut,
  name: () => name12,
  type: () => type,
  withMaxChunkSize: () => withMaxChunkSize
});
var name12 = "fixed";
var context = {
  maxChunkSize: 262144
};
var type = "Stateless";
var withMaxChunkSize = (maxChunkSize) => ({
  type: "Stateless",
  context: { maxChunkSize },
  name: name12,
  cut
});
var cut = ({ maxChunkSize }, { byteLength }, end) => {
  const n = byteLength / maxChunkSize | 0;
  const chunks = new Array(n).fill(maxChunkSize);
  const lastChunkSize = end ? byteLength - n * maxChunkSize : 0;
  if (lastChunkSize > 0) {
    chunks.push(lastChunkSize);
  }
  return chunks;
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file/layout/balanced.js
var Node = class {
  /**
   *
   * @param {number} id
   * @param {number[]} children
   * @param {Layout.Metadata} [metadata]
   */
  constructor(id, children, metadata) {
    this.id = id;
    this.children = children;
    this.metadata = metadata;
  }
};
var withWidth = (width) => ({
  open: () => open3({ width }),
  write: write6,
  close: close4
});
var defaults = { width: 174 };
var open3 = ({ width } = defaults) => ({
  width,
  head: null,
  leafIndex: [],
  nodeIndex: [],
  lastID: 0
});
var write6 = (layout, chunks) => {
  if (chunks.length === 0) {
    return { layout, nodes: EMPTY5, leaves: EMPTY5 };
  } else {
    let { lastID } = layout;
    const [head, slices] = layout.head ? (
      // If we had a head we have more then two chunks (we already checked
      // chunks weren't empty) so we process head along with other chunks.
      [null, (chunks.unshift(layout.head), chunks)]
    ) : (
      // If we have no head no leaves and got only one chunk we have to save it
      // until we can decide what to do with it.
      chunks.length === 1 && layout.leafIndex.length === 0 ? [chunks[0], EMPTY5] : (
        // Otherwise we have no head but got enough chunks to know we'll have a
        // node.
        [null, chunks]
      )
    );
    if (slices.length === 0) {
      return { layout: { ...layout, head }, nodes: EMPTY5, leaves: EMPTY5 };
    } else {
      const leafIndex = [...layout.leafIndex];
      const leaves = [];
      for (const chunk of slices) {
        const leaf = { id: ++lastID, content: chunk };
        leaves.push(leaf);
        leafIndex.push(leaf.id);
      }
      if (leafIndex.length > layout.width) {
        return flush2({ ...layout, leafIndex, head, lastID }, leaves);
      } else {
        return {
          layout: { ...layout, head, leafIndex, lastID },
          leaves,
          nodes: EMPTY5
        };
      }
    }
  }
};
var flush2 = (state, leaves = EMPTY5, nodes = [], close9 = false) => {
  let { lastID } = state;
  const nodeIndex = state.nodeIndex.map((row) => [...row]);
  const leafIndex = [...state.leafIndex];
  const { width } = state;
  while (leafIndex.length > width || leafIndex.length > 0 && close9) {
    grow(nodeIndex, 1);
    const node = new Node(++lastID, leafIndex.splice(0, width));
    nodeIndex[0].push(node.id);
    nodes.push(node);
  }
  let depth = 0;
  while (depth < nodeIndex.length) {
    const row = nodeIndex[depth];
    depth++;
    while (row.length > width || row.length > 0 && close9 && depth < nodeIndex.length) {
      const node = new Node(++lastID, row.splice(0, width));
      grow(nodeIndex, depth + 1);
      nodeIndex[depth].push(node.id);
      nodes.push(node);
    }
  }
  return { layout: { ...state, lastID, leafIndex, nodeIndex }, leaves, nodes };
};
var close4 = (layout, metadata) => {
  const state = layout;
  if (layout.head) {
    return {
      root: { id: 1, content: layout.head, metadata },
      leaves: EMPTY5,
      nodes: EMPTY5
    };
  } else if (layout.leafIndex.length === 0) {
    return {
      root: { id: 1, metadata },
      leaves: EMPTY5,
      nodes: EMPTY5
    };
  } else {
    const { nodes, layout: layout2 } = flush2(state, EMPTY5, [], true);
    const { nodeIndex } = layout2;
    const height2 = nodeIndex.length - 1;
    const top = nodeIndex[height2];
    if (top.length === 1) {
      const root2 = nodes[nodes.length - 1];
      nodes.length = nodes.length - 1;
      return { root: root2, nodes, leaves: EMPTY5 };
    } else {
      const root2 = new Node(layout2.lastID + 1, top, metadata);
      return { root: root2, nodes, leaves: EMPTY5 };
    }
  }
};
var grow = (index2, length4) => {
  while (index2.length < length4) {
    index2.push([]);
  }
  return index2;
};
var EMPTY5 = [];

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/file.js
var defaults2 = () => ({
  chunker: fixed_exports,
  fileChunkEncoder: UnixFSLeaf,
  smallFileEncoder: UnixFSLeaf,
  fileEncoder: codec_exports2,
  fileLayout: withWidth(174),
  hasher: sha2562,
  linker: { createLink: CID2.createV1 }
});
var configure = (config2) => ({
  ...defaults2(),
  ...config2
});
var UnixFSLeaf = {
  code: code16,
  name: name11,
  encode: encodeFileChunk
};
var create12 = ({ writer, metadata = {}, settings = defaults2() }) => new FileWriterView(init(writer, metadata, configure(settings)));
var write7 = async (view6, bytes2) => {
  await perform(view6, send({ type: "write", bytes: bytes2 }));
  return view6;
};
var close5 = async (view6, { releaseLock = false, closeWriter = false } = {}) => {
  await perform(view6, send({ type: "close" }));
  const { state } = view6;
  if (state.status === "linked") {
    if (closeWriter) {
      await view6.state.writer.close();
    } else if (releaseLock) {
      view6.state.writer.releaseLock();
    }
    return state.link;
  } else {
    panic2(
      `Expected writer to be in 'linked' state after close, but it is in "${state.status}" instead`
    );
  }
};
var perform = (view6, effect2) => fork(
  loop(effect2, (message) => {
    const { state, effect: effect3 } = update(message, view6.state);
    view6.state = state;
    return effect3;
  })
);
var FileWriterView = class {
  /**
   * @param {Writer.State<Layout>} state
   */
  constructor(state) {
    this.state = state;
  }
  get writer() {
    return this.state.writer;
  }
  get settings() {
    return this.state.config;
  }
  /**
   * @param {Uint8Array} bytes
   * @returns {Promise<API.View<Layout>>}
   */
  write(bytes2) {
    return write7(this, bytes2);
  }
  /**
   * @param {API.CloseOptions} [options]
   * @returns {Promise<UnixFS.FileLink>}
   */
  close(options) {
    return close5(this, options);
  }
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/directory.js
var defaults3 = defaults2;
var create13 = ({ writer, settings = defaults3(), metadata = {} }) => new DirectoryWriter({
  writer,
  metadata,
  settings,
  entries: /* @__PURE__ */ new Map(),
  closed: false
});
var set = (view6, name14, link5, { overwrite = false } = {}) => {
  const writable = asWritable(view6.state);
  if (name14.includes("/")) {
    throw new Error(
      `Directory entry name "${name14}" contains forbidden "/" character`
    );
  }
  if (!overwrite && writable.entries.has(name14)) {
    throw new Error(`Directory already contains entry with name "${name14}"`);
  } else {
    writable.entries.set(name14, link5);
    return view6;
  }
};
var remove7 = (view6, name14) => {
  const writer = asWritable(view6.state);
  writer.entries.delete(name14);
  return view6;
};
var asWritable = (writer) => {
  if (!writer.closed) {
    return writer;
  } else {
    throw new Error(
      `Can not change written directory, but you can .fork() and make changes to it`
    );
  }
};
var close6 = async (view6, { closeWriter = false, releaseLock = false } = {}) => {
  const { writer, settings, metadata } = asWritable(view6.state);
  view6.state.closed = true;
  const entries3 = [...links(view6)];
  const node = createFlatDirectory(entries3, metadata);
  const bytes2 = encodeDirectory(node);
  const digest5 = await settings.hasher.digest(bytes2);
  const cid = settings.linker.createLink(code16, digest5);
  if ((writer.desiredSize || 0) <= 0) {
    await writer.ready;
  }
  writer.write({ cid, bytes: bytes2 });
  if (closeWriter) {
    await writer.close();
  } else if (releaseLock) {
    writer.releaseLock();
  }
  return {
    cid,
    dagByteLength: cumulativeDagByteLength(bytes2, entries3)
  };
};
var links = function* ({ state }) {
  for (const [name14, { dagByteLength, cid }] of state.entries) {
    yield (
      /** @type {UnixFS.DirectoryEntryLink} */
      {
        name: name14,
        dagByteLength,
        cid
      }
    );
  }
};
var fork2 = ({ state }, {
  writer = state.writer,
  metadata = state.metadata,
  settings = state.settings
} = {}) => new DirectoryWriter({
  writer,
  metadata,
  settings,
  entries: new Map(state.entries.entries()),
  closed: false
});
var DirectoryWriter = class {
  /**
   * @param {API.State<Layout>} state
   */
  constructor(state) {
    this.state = state;
  }
  get writer() {
    return this.state.writer;
  }
  get settings() {
    return this.state.settings;
  }
  links() {
    return links(this);
  }
  /**
   * @param {string} name
   * @param {UnixFS.FileLink | UnixFS.DirectoryLink} link
   * @param {API.WriteOptions} [options]
   */
  set(name14, link5, options) {
    return set(this, name14, link5, options);
  }
  /**
   * @param {string} name
   */
  remove(name14) {
    return remove7(this, name14);
  }
  /**
   * @template L
   * @param {Partial<API.Options<L>>} [options]
   * @returns {API.View<Layout|L>}
   */
  fork(options) {
    return fork2(this, options);
  }
  /**
   * @param {API.CloseOptions} [options]
   * @returns {Promise<UnixFS.DirectoryLink>}
   */
  close(options) {
    return close6(this, options);
  }
  entries() {
    return this.state.entries.entries();
  }
  /**
   * @param {string} name
   */
  has(name14) {
    return this.state.entries.has(name14);
  }
  get size() {
    return this.state.entries.size;
  }
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/bitfield/Uint32.js
var Uint32_exports = {};
__export(Uint32_exports, {
  API: () => api_exports2,
  and: () => and5,
  bitCount: () => bitCount,
  empty: () => empty6,
  from: () => from15,
  fromBytes: () => fromBytes3,
  get: () => get10,
  or: () => or11,
  popcount: () => popcount,
  set: () => set2,
  size: () => size3,
  toBytes: () => toBytes2,
  unset: () => unset
});

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/bitfield/api.js
var api_exports2 = {};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/bitfield/Uint32.js
var empty6 = (size5 = 32) => {
  if (size5 !== 32) {
    throw new Error(`Uint32 BitField does not support size: ${size5}`);
  }
  return 0;
};
var from15 = (bits, size5) => {
  let bitfield = empty6(size5);
  for (const bit of bits) {
    bitfield = set2(bitfield, bit);
  }
  return bitfield;
};
var size3 = (_bitField) => 32;
var mask = (bitField2, index2) => bitField2 >>> index2 & 31;
var offset = (bitField2, index2) => 1 << mask(bitField2, index2);
var popcount = (bitField2, index2 = 31) => bitCount(bitField2 & offset(index2, 0) - 1);
var set2 = (bitField2, index2) => bitField2 | 1 << index2;
var unset = (bitField2, index2) => bitField2 & (255 ^ 1 << index2);
var get10 = (bitField2, index2) => (bitField2 >> index2 & 1) !== 0;
var bitCount = (bitField2) => {
  const n1 = bitField2 - (bitField2 >> 1 & 1431655765);
  const n2 = (n1 & 858993459) + (n1 >> 2 & 858993459);
  const n3 = (n2 + (n2 >> 4) & 252645135) * 16843009;
  return n3 >> 24;
};
var and5 = (left, right) => left & right;
var or11 = (left, right) => left | right;
var toBytes2 = (bitField2) => Uint8Array.of(
  bitField2 >> 24 & 255,
  bitField2 >> 16 & 255,
  bitField2 >> 8 & 255,
  bitField2 & 255
);
var fromBytes3 = (bytes2) => {
  if (bytes2.length !== 4) {
    throw new Error(`Expected 4 bytes instead got ${bytes2.length}`);
  }
  return (bytes2[0] << 24) + (bytes2[1] << 16) + (bytes2[2] << 8) + bytes2[3];
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/path/Uint32.js
var import_murmurhash3js_revisited = __toESM(require_murmurhash3js_revisited(), 1);
var utf8 = new TextEncoder();
var hash32 = import_murmurhash3js_revisited.default.x64.hash126;
var configure2 = ({ bitWidth: bitWidth2 = 5, hash = hash32 }) => {
  const hashSize = 4;
  if (bitWidth2 > hashSize * 8) {
    throw new RangeError(
      `Can not use bitWidth ${bitWidth2} which exceeds the hashSize ${hashSize}`
    );
  }
  if (hashSize * 8 > 32) {
    throw new RangeError(
      `Can not use hashSize ${hashSize} as it can not be encoded in Uint32`
    );
  }
  const mask2 = 4294967295 >>> 32 - bitWidth2;
  const at2 = (path, depth) => path >>> depth * bitWidth2 & mask2;
  const from19 = (key) => hash(utf8.encode(key));
  return { at: at2, from: from19, size: Math.ceil(hashSize * 8 / bitWidth2) };
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/node.js
var BitmapIndexedNode = class {
  /**
   * @param {API.Edit|null} edit
   * @param {ReturnType<C['BitField']['empty']>} datamap
   * @param {ReturnType<C['BitField']['empty']>} nodemap
   * @param {API.Children<T, K, C>} children
   * @param {C} config
   */
  constructor(edit, datamap, nodemap, children, config2) {
    this.edit = edit;
    this.config = config2;
    this.datamap = datamap;
    this.nodemap = nodemap;
    this.children = children;
  }
  get nodeArity() {
    return this.config.BitField.popcount(this.nodemap);
  }
  get dataArity() {
    return this.config.BitField.popcount(this.datamap);
  }
  /**
   * @returns {API.BitmapIndexedNode<T, K, C>}
   */
  /* c8 ignore next 3 */
  empty() {
    return create14(this.config);
  }
  /**
   * @template X
   * @param {API.Uint32} depth
   * @param {ReturnType<C['Path']['from']>} path
   * @param {K} key
   * @param {X} notFound
   * @returns {T|X}
   */
  lookup(depth, path, key, notFound2) {
    return lookup(this, depth, path, key, notFound2);
  }
  /**
   * @template {string} R
   * @param {API.Edit|null} edit
   * @param {API.Uint32} depth
   * @param {ReturnType<C['Path']['from']>} path
   * @param {K|R} key
   * @param {T} value
   * @param {{value:boolean}} addedLeaf
   * @returns {API.BitmapIndexedNode<T, K | R, C>}
   */
  associate(edit, depth, path, key, value, addedLeaf) {
    return associate(this, edit, depth, path, key, value, addedLeaf);
  }
  /**
   * @param {API.Edit|null} edit
   * @param {API.Uint32} depth
   * @param {ReturnType<C['Path']['from']>} path
   * @param {K} key
   * @param {{value:boolean}} removedLeaf
   * @returns {API.BitmapIndexedNode<T, K, C>}
   */
  dissociate(edit, depth, path, key, removedLeaf) {
    return dissociate(this, edit, depth, path, key, removedLeaf);
  }
  /**
   * @param {API.Edit|null} edit
   * @returns {API.BitmapIndexedNode<T, K, C>}
   */
  fork(edit = null) {
    return fork3(this, edit);
  }
  /**
   * @returns {IterableIterator<[K, T]>}
   */
  entries() {
    return entries2(this);
  }
  /**
   * @returns {IterableIterator<K>}
   */
  keys() {
    return keys(this);
  }
  /**
   * @returns {IterableIterator<T>}
   */
  values() {
    return values(this);
  }
};
var HashCollisionNode = class {
  /**
   * @param {API.Edit|null} edit
   * @param {number} count
   * @param {API.CollisionEntries<T, K>} children
   * @param {C} config
   */
  /* c8 ignore next 12 */
  constructor(edit, count, children, config2) {
    this.edit = edit;
    this.count = count;
    this.children = children;
    this.config = config2;
  }
  get nodeArity() {
    return (
      /** @type {0} */
      0
    );
  }
  get dataArity() {
    return this.count;
  }
  /**
   * @template X
   * @param {API.Uint32} _shift
   * @param {unknown} _path
   * @param {K} key
   * @param {X} notFound
   * @returns {T|X}
   */
  /* c8 ignore next 3 */
  lookup(_shift, _path, key, notFound2) {
    return lookupCollision(this, key, notFound2);
  }
  /**
   * @template {string} R
   * @param {API.Edit|null} edit
   * @param {API.Uint32} _shift
   * @param {ReturnType<C['Path']['from']>} path
   * @param {K|R} key
   * @param {T} value
   * @param {{value:boolean}} addedLeaf
   * @returns {API.HashCollisionNode<T, K | R, C>}
   */
  /* c8 ignore next 3 */
  associate(edit, _shift, path, key, value, addedLeaf) {
    return associateCollision(this, edit, path, key, value, addedLeaf);
  }
  /**
   * @param {API.Edit|null} edit
   * @param {API.Uint32} _shift
   * @param {ReturnType<C['Path']['from']>} path
   * @param {K} key
   * @param {{value:boolean}} removedLeaf
   * @returns {API.Node<T, K, C>}
   */
  /* c8 ignore next 3 */
  dissociate(edit, _shift, path, key, removedLeaf) {
    return dissociateCollision(this, edit, path, key, removedLeaf);
  }
  /**
   * @param {API.Edit|null} edit
   * @returns {this}
   */
  /* c8 ignore next 3 */
  fork(edit = null) {
    return (
      /** @type {this} */
      forkCollision(this, edit)
    );
  }
  /**
   * @returns {IterableIterator<[K, T]>}
   */
  /* c8 ignore next 3 */
  entries() {
    return entries2(this);
  }
  /**
   * @returns {IterableIterator<K>}
   */
  /* c8 ignore next 3 */
  keys() {
    return keys(this);
  }
  /**
   * @returns {IterableIterator<T>}
   */
  /* c8 ignore next 3 */
  values() {
    return values(this);
  }
};
var lookupCollision = (node, name14, notFound2) => {
  const { children: entries3, count } = node;
  const n = findHashCollisionNodeIndex(entries3, count, name14);
  return entries3[n] === name14 ? (
    /** @type {T} */
    entries3[n + 1]
  ) : notFound2;
};
var associateCollision = (node, edit, key, name14, value, addedLeaf) => {
  const { children, count } = node;
  const index2 = findHashCollisionNodeIndex(children, count, name14);
  if (children[index2] !== name14) {
    const newNode = node.fork(edit);
    addedLeaf.value = true;
    newNode.count += 1;
    newNode.children.splice(index2, key, value);
    return newNode;
  } else if (children[index2 + 1] !== value) {
    const newNode = node.fork(edit);
    newNode.children[index2 + 1] = value;
    return newNode;
  } else {
    return node;
  }
};
var dissociateCollision = (node, edit, hash, name14, removedLeaf) => {
  const { children: entries3, count, config: config2 } = node;
  const index2 = findHashCollisionNodeIndex(entries3, count, name14);
  if (entries3[index2] !== name14) {
    return node;
  } else {
    removedLeaf.value = true;
    if (count === 2) {
      const offset2 = index2 === 0 ? 2 : 0;
      return (
        /** @type {API.BitmapIndexedNode<T, K, C>} */
        associate(
          create14(config2),
          edit,
          0,
          hash,
          /** @type {K} */
          entries3[offset2],
          /** @type {T} */
          entries3[offset2 + 1],
          removedLeaf
        )
      );
    } else {
      const newNode = node.fork(edit);
      newNode.children.splice(index2, 2);
      newNode.count -= 1;
      return newNode;
    }
  }
};
var forkCollision = (node, edit = null) => {
  if (canEdit(node.edit, edit)) {
    return node;
  } else {
    return new HashCollisionNode(
      edit,
      node.count,
      /** @type {API.CollisionEntries<T, K>} */
      node.children.slice(),
      node.config
    );
  }
};
var findHashCollisionNodeIndex = (entries3, count, key) => {
  let index2 = 0;
  while (index2 < count && entries3[index2] > key) {
    index2 += 2;
  }
  return index2;
};
var create14 = (config2, edit = null) => new BitmapIndexedNode(
  edit,
  config2.BitField.empty(Math.pow(2, config2.bitWidth)),
  config2.BitField.empty(Math.pow(2, config2.bitWidth)),
  /** @type {API.Children<T, K, C>} */
  [],
  config2
);
var get11 = (node, key, notFound2) => lookup(node, 0, node.config.Path.from(key), key, notFound2);
var lookup = (node, depth, path, key, notFound2) => {
  const { datamap, nodemap, config: config2 } = node;
  const { Path, BitField } = config2;
  const offset2 = Path.at(path, depth);
  if (BitField.get(datamap, offset2)) {
    const index2 = BitField.popcount(datamap, offset2);
    if (keyAt(node, index2) === key) {
      return valueAt(node, index2);
    } else {
      return notFound2;
    }
  } else if (BitField.get(nodemap, offset2)) {
    const child = resolveNode(node, offset2);
    return child.lookup(depth + 1, path, key, notFound2);
  } else {
    return notFound2;
  }
};
var set3 = (node, edit, key, value, addedLeaf) => associate(node, edit, 0, node.config.Path.from(key), key, value, addedLeaf);
var associate = (node, edit, depth, path, key, value, addedLeaf) => {
  const { datamap, nodemap, config: config2 } = node;
  const { Path, BitField } = config2;
  const offset2 = Path.at(path, depth);
  if (BitField.get(datamap, offset2)) {
    const index2 = BitField.popcount(datamap, offset2);
    const found = keyAt(node, index2);
    if (key === found) {
      return valueAt(node, index2) === value ? node : forkAndSet(node, edit, index2, value);
    } else {
      const branch = mergeTwoLeaves(
        config2,
        edit,
        depth + 1,
        Path.from(found),
        found,
        valueAt(node, index2),
        path,
        key,
        value
      );
      addedLeaf.value = true;
      return migrateLeafToBranch(node, edit, offset2, branch);
    }
  } else if (BitField.get(nodemap, offset2)) {
    const child = resolveNode(node, offset2);
    const newChild = child.associate(
      edit,
      depth + 1,
      path,
      key,
      value,
      addedLeaf
    );
    if (child === newChild) {
      return node;
    } else {
      return copyAndSetChild(node, edit, offset2, newChild);
    }
  } else {
    const index2 = BitField.popcount(datamap, offset2);
    addedLeaf.value = true;
    const newNode = node.fork(edit);
    newNode.datamap = BitField.set(datamap, offset2);
    newNode.children.splice(keyPosition(index2), 0, key, value);
    return newNode;
  }
};
var remove8 = (node, edit, key, removedLeaf) => dissociate(node, edit, 0, node.config.Path.from(key), key, removedLeaf);
var dissociate = (source, edit, depth, path, key, removedLeaf) => {
  const { datamap, nodemap, config: config2 } = source;
  const { BitField, Path } = config2;
  const offset2 = Path.at(path, depth);
  if (BitField.get(datamap, offset2)) {
    const index2 = BitField.popcount(datamap, offset2);
    if (key === keyAt(source, index2)) {
      removedLeaf.value = true;
      const node = fork3(source, edit);
      node.datamap = BitField.unset(source.datamap, offset2);
      node.children.splice(keyPosition(index2), 2);
      return node;
    } else {
      return source;
    }
  } else if (BitField.get(nodemap, offset2)) {
    const node = resolveNode(source, offset2);
    const child = node.dissociate(edit, depth + 1, path, key, removedLeaf);
    if (hasSingleLeaf(child)) {
      return hasSingleNode(source) ? child : inlineChild(source, edit, offset2, child);
    } else if (node === child) {
      return source;
    } else {
      return copyAndSetChild(source, edit, offset2, child);
    }
  } else {
    return source;
  }
};
var entries2 = function* ({ children }) {
  let offset2 = 0;
  const count = children.length;
  while (offset2 < count) {
    const key = children[offset2];
    if (typeof key === "string") {
      offset2 += 1;
      const value = children[offset2];
      yield (
        /** @type {[K, T]} */
        [key, value]
      );
      offset2 += 1;
    } else {
      break;
    }
  }
  while (offset2 < count) {
    const node = (
      /** @type {API.BitmapIndexedNode<T, K, C>} */
      children[offset2]
    );
    yield* node.entries();
    offset2 += 1;
  }
};
var fork3 = (node, edit) => {
  if (canEdit(node.edit, edit)) {
    return node;
  } else {
    const newNode = new BitmapIndexedNode(
      edit,
      node.datamap,
      node.nodemap,
      node.children.slice(),
      node.config
    );
    return newNode;
  }
};
var keys = function* ({ children }) {
  let offset2 = 0;
  const count = children.length;
  while (offset2 < count) {
    const key = children[offset2];
    if (typeof key === "string") {
      yield (
        /** @type {K} */
        key
      );
      offset2 += 2;
    } else {
      break;
    }
  }
  while (offset2 < count) {
    const node = (
      /** @type {API.BitmapIndexedNode<T, K>} */
      children[offset2]
    );
    yield* node.keys();
    offset2 += 1;
  }
};
var values = function* ({ children }) {
  let offset2 = 0;
  const count = children.length;
  while (offset2 < count) {
    const key = children[offset2];
    if (typeof key === "string") {
      offset2 += 1;
      yield (
        /** @type {T} */
        children[offset2]
      );
      offset2 += 1;
    } else {
      break;
    }
  }
  while (offset2 < count) {
    const node = (
      /** @type {API.BitmapIndexedNode<T, K>} */
      children[offset2]
    );
    yield* node.values();
    offset2 += 1;
  }
};
var forkAndSet = (node, edit, offset2, value) => {
  const newNode = node.fork(edit);
  newNode.children[valuePosition(offset2)] = value;
  return newNode;
};
var inlineChild = (source, edit, offset2, child) => {
  const { datamap, nodemap, config: config2 } = source;
  const { BitField } = config2;
  const node = fork3(source, edit);
  node.children.splice(nodePosition(source, offset2), 1);
  node.children.splice(
    keyPosition(BitField.popcount(datamap, offset2)),
    0,
    child.children[0],
    child.children[1]
  );
  node.datamap = BitField.set(datamap, offset2);
  node.nodemap = BitField.unset(nodemap, offset2);
  return node;
};
var copyAndSetChild = (node, edit, offset2, child) => {
  const newNode = fork3(node, edit);
  newNode.children[nodePosition(node, offset2)] = child;
  return newNode;
};
var migrateLeafToBranch = (source, edit, offset2, branch) => {
  const { nodemap, datamap, config: config2 } = source;
  const { BitField } = config2;
  const index2 = BitField.popcount(datamap, offset2);
  const oldId = keyPosition(index2);
  const newId = nodePosition(source, offset2);
  const node = fork3(source, edit);
  node.datamap = BitField.unset(datamap, offset2);
  node.children.splice(oldId, 2);
  node.nodemap = BitField.set(nodemap, offset2);
  node.children.splice(newId - 1, 0, branch);
  return node;
};
var mergeTwoLeaves = (config2, edit, depth, oldPath, oldKey, oldValue, newPath, newKey, newValue) => {
  const { BitField, Path } = config2;
  if (Path.size < depth) {
    return new HashCollisionNode(
      edit,
      2,
      [oldKey, oldValue, newKey, newValue],
      config2
    );
  } else {
    const oldOffset = Path.at(oldPath, depth);
    const newOffset = Path.at(newPath, depth);
    if (oldOffset === newOffset) {
      return new BitmapIndexedNode(
        edit,
        BitField.empty(Math.pow(2, config2.bitWidth)),
        BitField.from([oldOffset], Math.pow(2, config2.bitWidth)),
        [
          mergeTwoLeaves(
            config2,
            edit,
            depth + 1,
            oldPath,
            oldKey,
            oldValue,
            newPath,
            newKey,
            newValue
          )
        ],
        config2
      );
    } else {
      return new BitmapIndexedNode(
        edit,
        BitField.from([oldOffset, newOffset], Math.pow(2, config2.bitWidth)),
        BitField.empty(Math.pow(2, config2.bitWidth)),
        /** @type {API.Children<T, K, C>} */
        // We insert child with a lower index first so that we can derive it's
        // index on access via popcount
        oldOffset < newOffset ? [oldKey, oldValue, newKey, newValue] : [newKey, newValue, oldKey, oldValue],
        config2
      );
    }
  }
};
var keyAt = ({ children }, index2) => (
  /** @type {K} */
  children[keyPosition(index2)]
);
var keyPosition = (index2) => index2 * 2;
var valueAt = ({ children }, index2) => (
  /** @type {T} */
  children[valuePosition(index2)]
);
var valuePosition = (index2) => index2 * 2 + 1;
var resolveNode = (node, offset2) => (
  /** @type {API.BitmapIndexedNode<T, K, C>|API.HashCollisionNode<T, K, C>} */
  node.children[nodePosition(node, offset2)]
);
var nodePosition = ({ children, nodemap, config: config2 }, offset2) => children.length - 1 - config2.BitField.popcount(nodemap, offset2);
var canEdit = (owner, editor) => owner != null && owner === editor;
var hasSingleLeaf = (node) => node.nodeArity === 0 && node.dataArity === 1;
var hasSingleNode = ({ config: { BitField }, datamap, nodemap }) => BitField.popcount(datamap) === 0 && BitField.popcount(nodemap) === 1;

// ../../node_modules/.pnpm/@multiformats+murmur3@2.1.8/node_modules/@multiformats/murmur3/src/index.js
var import_murmurhash3js_revisited2 = __toESM(require_murmurhash3js_revisited(), 1);
function fromNumberTo32BitBuf(number2) {
  const bytes2 = new Array(4);
  for (let i = 0; i < 4; i++) {
    bytes2[i] = number2 & 255;
    number2 = number2 >> 8;
  }
  return new Uint8Array(bytes2);
}
var murmur332 = from6({
  name: "murmur3-32",
  code: 35,
  encode: (input10) => fromNumberTo32BitBuf(import_murmurhash3js_revisited2.default.x86.hash32(input10))
});
var murmur3128 = from6({
  name: "murmur3-128",
  code: 34,
  encode: (input10) => bytes_exports2.fromHex(import_murmurhash3js_revisited2.default.x64.hash128(input10))
});
var murmur364 = from6({
  name: "murmur3-x64-64",
  code: 34,
  encode: (input10) => bytes_exports2.fromHex(import_murmurhash3js_revisited2.default.x64.hash128(input10)).subarray(0, 8)
});

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/path/Uint8Array.js
var utf82 = new TextEncoder();
var hash64 = (bytes2) => (
  /** @type {Uint8Array} */
  murmur364.encode(bytes2)
);
var configure3 = ({ bitWidth: bitWidth2 = 8, hash = hash64 } = {}) => {
  const hashSize = hash(new Uint8Array()).byteLength;
  const at2 = (path, depth) => {
    const offset2 = depth * bitWidth2;
    if (offset2 > hashSize) {
      throw new RangeError(`Out of bounds`);
    }
    return toInt(path, offset2, bitWidth2);
  };
  const from19 = (key) => hash(utf82.encode(key));
  return { from: from19, at: at2, size: Math.ceil(hashSize * 8 / bitWidth2) };
};
var toInt = (bytes2, offset2, count) => {
  let byteOffset = offset2 / 8 | 0;
  let bitOffset = offset2 % 8;
  let desired = count;
  let bits = 0;
  while (desired > 0 && byteOffset < bytes2.byteLength) {
    const byte = bytes2[byteOffset];
    const available = 8 - bitOffset;
    const taking = available < desired ? available : desired;
    const bitsLeft = 8 - bitOffset - taking;
    const mask2 = 255 >> bitOffset;
    const value = (mask2 & byte) >> bitsLeft;
    bits = (bits << taking) + value;
    desired -= taking;
    byteOffset++;
    bitOffset = 0;
  }
  return bits;
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/bitfield/Uint8Array.js
var Uint8Array_exports = {};
__export(Uint8Array_exports, {
  API: () => api_exports2,
  and: () => and6,
  empty: () => empty7,
  from: () => from16,
  fromBytes: () => fromBytes4,
  get: () => get12,
  or: () => or12,
  popcount: () => popcount2,
  set: () => set4,
  size: () => size4,
  toBytes: () => toBytes3,
  unset: () => unset2
});
var empty7 = (size5 = 256) => {
  if (size5 % 8 !== 0) {
    throw new Error(`Must be multiple of 8`);
  }
  return new Uint8Array(size5 / 8);
};
var from16 = (bits, size5) => {
  let bitfield = empty7(size5);
  for (const index2 of bits) {
    const { byte, byteOffset, bitOffset } = at(bitfield, index2);
    bitfield[byteOffset] = byte | 1 << bitOffset;
  }
  return bitfield;
};
var size4 = (bitfield) => bitfield.byteLength * 8;
var at = (bitfield, index2) => {
  const byteOffset = bitfield.byteLength - 1 - (index2 / 8 | 0);
  const bitOffset = index2 % 8;
  const byte = bitfield[byteOffset];
  return { byte, byteOffset, bitOffset };
};
var setByte = (bytes2, index2, byte) => {
  if (bytes2[index2] !== byte) {
    const result = bytes2.slice(0);
    result[index2] = byte;
    return result;
  }
  return bytes2;
};
var set4 = (bitfield, index2) => {
  const { byte, byteOffset, bitOffset } = at(bitfield, index2);
  return setByte(bitfield, byteOffset, byte | 1 << bitOffset);
};
var unset2 = (bitfield, index2) => {
  const { byte, byteOffset, bitOffset } = at(bitfield, index2);
  return setByte(bitfield, byteOffset, byte & (255 ^ 1 << bitOffset));
};
var get12 = (bitfield, index2) => {
  var { byte, bitOffset } = at(bitfield, index2);
  return (byte >> bitOffset & 1) !== 0;
};
var toBytes3 = (bitfield) => bitfield;
var fromBytes4 = (bytes2) => bytes2;
var popcount2 = (bitfield, index2 = bitfield.byteLength * 8) => {
  const { byteOffset, bitOffset, byte } = at(bitfield, index2);
  let count = popcount(byte, bitOffset);
  let offset2 = bitfield.byteLength - 1;
  while (offset2 > byteOffset) {
    const byte2 = bitfield[offset2];
    count += bitCount(byte2);
    offset2--;
  }
  return count;
};
var or12 = (left, right) => {
  const result = left.slice();
  let offset2 = 0;
  while (offset2 < left.length) {
    result[offset2] |= right[offset2];
    offset2++;
  }
  return result;
};
var and6 = (left, right) => {
  const result = left.slice();
  let offset2 = 0;
  while (offset2 < left.length) {
    result[offset2] &= right[offset2];
    offset2++;
  }
  return result;
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/lib.js
var NOT_FOUND = new RangeError("Not Found");
var configure4 = ({
  bitWidth: bitWidth2 = 5,
  /* c8 ignore next 4 */
  BitField = bitWidth2 === 5 ? Uint32_exports : Uint8Array_exports,
  Path = bitWidth2 === 5 ? configure2({ bitWidth: bitWidth2 }) : configure3({ bitWidth: bitWidth2 })
} = {}) => (
  /** @type {C} */
  { bitWidth: bitWidth2, BitField, Path }
);
var from17 = (entries3, options) => {
  const node = (
    /** @type {API.HashMapBuilder<V, K, C>} */
    builder(options)
  );
  for (const [key, value] of entries3) {
    node.set(key, value);
  }
  return node.build();
};
var has = (hamt, key) => get11(hamt.root, key, NOT_FOUND) !== NOT_FOUND;
var get13 = (hamt, key, notFound2 = (
  /** @type {U} */
  void 0
)) => get11(hamt.root, key, notFound2);
var builder = (options) => {
  const edit = {};
  const config2 = configure4(options);
  return new HashMapBuilder(
    edit,
    0,
    create14(config2, edit),
    config2
  );
};
var PersistentHashMap = class _PersistentHashMap {
  /**
   *
   * @param {number} count
   * @param {API.BitmapIndexedNode<T, K, C>} root
   * @param {C} config
   */
  constructor(count = 0, root2, config2) {
    this.count = count;
    this.root = root2;
    this.config = config2;
  }
  get size() {
    return this.count;
  }
  clone() {
    return new _PersistentHashMap(this.count, this.root, this.config);
  }
  /**
   * @returns {API.PersistentHashMap<T, K, C>}
   */
  empty() {
    return new _PersistentHashMap(
      0,
      create14(this.config, null),
      this.config
    );
  }
  /**
   * @param {K} key
   * @returns {boolean}
   */
  has(key) {
    return has(this, key);
  }
  /**
   * @param {K} key
   * @returns {T|undefined}
   */
  get(key) {
    return get11(this.root, key, void 0);
  }
  /**
   * @template {string} R
   * @param {R} key
   * @param {T} value
   * @returns {PersistentHashMap<T, K|R, C>}
   */
  set(key, value) {
    const addedLeaf = { value: false };
    const root2 = set3(this.root, null, key, value, addedLeaf);
    if (root2 === this.root) {
      return this;
    } else {
      return new _PersistentHashMap(
        addedLeaf.value ? this.count + 1 : this.count,
        root2,
        this.config
      );
    }
  }
  /**
   * @param {K} key
   */
  delete(key) {
    const root2 = remove8(this.root, null, key, { value: false });
    if (root2 === this.root) {
      return this;
    } else {
      return new _PersistentHashMap(this.count - 1, root2, this.config);
    }
  }
  /* c8 ignore next 3 */
  get bitField() {
    return this.config.BitField.or(this.root.datamap, this.root.nodemap);
  }
  [Symbol.iterator]() {
    return this.entries();
  }
  entries() {
    return this.root.entries();
  }
  keys() {
    return this.root.keys();
  }
  values() {
    return this.root.values();
  }
  /**
   * @returns {API.HashMapBuilder<T, K, C>}
   */
  createBuilder() {
    return new HashMapBuilder({}, this.count, this.root, this.config);
  }
};
var HashMapBuilder = class {
  /**
   * @param {API.Edit} edit
   * @param {number} count
   * @param {API.BitmapIndexedNode<T, K, C>} root
   * @param {C} config
   */
  constructor(edit, count, root2, config2) {
    this.edit = edit;
    this.count = count;
    this.root = root2;
    this.config = config2;
  }
  get size() {
    if (this.edit) {
      return this.count;
    } else {
      throw new Error(`.size was accessed on the finalized builder`);
    }
  }
  /**
   * @template {string} R
   * @param {R} key
   * @param {T} value
   * @returns {HashMapBuilder<T, K|R, C>}
   */
  set(key, value) {
    if (this.edit) {
      const addedLeaf = { value: false };
      const root2 = set3(this.root, this.edit, key, value, addedLeaf);
      if (this.root !== root2) {
        this.root = /** @type {API.BitmapIndexedNode<T, K, C>} */
        root2;
      }
      if (addedLeaf.value) {
        this.count += 1;
      }
      return this;
    } else {
      throw new Error(`.set was called on the finalized builder`);
    }
  }
  /**
   * @param {K} key
   */
  delete(key) {
    if (this.edit) {
      if (this.count === 0) {
        return this;
      }
      const removedLeaf = { value: false };
      const root2 = remove8(this.root, this.edit, key, removedLeaf);
      if (root2 !== this.root) {
        this.root = root2;
      }
      if (removedLeaf.value) {
        this.count -= 1;
      }
      return this;
    } else {
      throw new Error(`.delete was called on the finalized builder`);
    }
  }
  build() {
    if (this.edit) {
      this.edit = null;
      return new PersistentHashMap(this.count, this.root, this.config);
    } else {
      throw new Error(`.build was called on the finalized builder`);
    }
  }
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/path/InfiniteUint8Array.js
var utf83 = new TextEncoder();
var hash642 = (bytes2) => (
  /** @type {Uint8Array} */
  murmur364.encode(bytes2)
);
var configure5 = ({ bitWidth: bitWidth2 = 8, hash = hash642 }) => {
  const hashSize = hash(new Uint8Array()).byteLength;
  const options = { bitWidth: bitWidth2, hash, hashSize };
  const at2 = (path, depth) => read8(path, depth, options);
  const from19 = (key) => utf83.encode(key);
  return { at: at2, from: from19, size: Infinity };
};
var read8 = (key, depth = 0, { bitWidth: bitWidth2 = 8, hash, hashSize }) => {
  const frameBitSize = hashSize * 8;
  let digest5 = 0;
  let bitCount2 = bitWidth2;
  let bitOffset = bitWidth2 * depth;
  while (bitCount2 > 0) {
    const frameOffset = bitOffset / frameBitSize >> 0;
    const frame = frameOffset === 0 ? hash(key) : hash(appendByte(key, frameOffset));
    const offset2 = frameBitSize <= bitOffset ? bitOffset % frameBitSize : bitOffset;
    const maxBits = frameBitSize - offset2;
    const count = maxBits < bitCount2 ? maxBits : bitCount2;
    digest5 = (digest5 << count) + toInt(frame, offset2, count);
    bitCount2 -= count;
    bitOffset += count;
  }
  return digest5;
};
var appendByte = (source, byte) => {
  const bytes2 = new Uint8Array(source.byteLength + 1).fill(
    byte,
    source.byteLength
  );
  bytes2.set(source);
  return bytes2;
};

// ../../node_modules/.pnpm/@perma+map@1.0.3/node_modules/@perma/map/src/unixfs.js
var bitWidth = 8;
var config = {
  bitWidth,
  Path: configure5({ bitWidth })
};
var tableSize = (hamt) => Math.pow(2, hamt.config.bitWidth);
var builder2 = (options = (
  /** @type {C} */
  config
)) => builder(options);
var from18 = (entries3, options = (
  /** @type {C} */
  config
)) => from17(entries3, options);
var bitField = ({ datamap, nodemap, config: { BitField } }) => withoutLeadingZeros(BitField.toBytes(BitField.or(datamap, nodemap)));
var withoutLeadingZeros = (bytes2) => {
  let offset2 = 0;
  while (offset2 < bytes2.byteLength) {
    if (bytes2[offset2] !== 0) {
      return bytes2.subarray(offset2);
    }
    offset2 += 1;
  }
  return bytes2.subarray(offset2);
};
var iterate3 = function* (root2) {
  const { config: config2, datamap, nodemap } = root2;
  const { BitField: bitfield } = config2;
  const size5 = bitfield.size(datamap);
  let bitOffset = 0;
  let dataCount = 0;
  while (bitOffset < size5) {
    const prefix2 = bitOffset.toString(16).toUpperCase().padStart(2, "0");
    if (bitfield.get(datamap, bitOffset)) {
      const key = keyAt(root2, dataCount);
      yield {
        prefix: prefix2,
        key,
        value: valueAt(root2, dataCount)
      };
      dataCount++;
    } else if (bitfield.get(nodemap, bitOffset)) {
      yield {
        prefix: prefix2,
        // UnixFS never contains hash collision nodes because it uses
        // inifinite hashes
        node: (
          /** @type {HAMT.BitmapIndexedNode<T, K, C>} */
          resolveNode(root2, bitOffset)
        )
      };
    }
    bitOffset++;
  }
};

// ../../node_modules/.pnpm/multiformats@11.0.2/node_modules/multiformats/src/block.js
function readonly({ enumerable = true, configurable = false } = {}) {
  return { enumerable, configurable, writable: false };
}
function* linksWithin(path, value) {
  if (value != null && typeof value === "object") {
    if (Array.isArray(value)) {
      for (const [index2, element] of value.entries()) {
        const elementPath = [...path, index2];
        const cid = CID2.asCID(element);
        if (cid) {
          yield [elementPath.join("/"), cid];
        } else if (typeof element === "object") {
          yield* links2(element, elementPath);
        }
      }
    } else {
      const cid = CID2.asCID(value);
      if (cid) {
        yield [path.join("/"), cid];
      } else {
        yield* links2(value, path);
      }
    }
  }
}
function* links2(source, base4) {
  if (source == null || source instanceof Uint8Array) {
    return;
  }
  const cid = CID2.asCID(source);
  if (cid) {
    yield [base4.join("/"), cid];
  }
  for (const [key, value] of Object.entries(source)) {
    const path = (
      /** @type {[string|number, string]} */
      [...base4, key]
    );
    yield* linksWithin(path, value);
  }
}
function* treeWithin(path, value) {
  if (Array.isArray(value)) {
    for (const [index2, element] of value.entries()) {
      const elementPath = [...path, index2];
      yield elementPath.join("/");
      if (typeof element === "object" && !CID2.asCID(element)) {
        yield* tree(element, elementPath);
      }
    }
  } else {
    yield* tree(value, path);
  }
}
function* tree(source, base4) {
  if (source == null || typeof source !== "object") {
    return;
  }
  for (const [key, value] of Object.entries(source)) {
    const path = (
      /** @type {[string|number, string]} */
      [...base4, key]
    );
    yield path.join("/");
    if (value != null && !(value instanceof Uint8Array) && typeof value === "object" && !CID2.asCID(value)) {
      yield* treeWithin(path, value);
    }
  }
}
function get14(source, path) {
  let node = (
    /** @type {Record<string, any>} */
    source
  );
  for (const [index2, key] of path.entries()) {
    node = node[key];
    if (node == null) {
      throw new Error(`Object has no property at ${path.slice(0, index2 + 1).map((part) => `[${JSON.stringify(part)}]`).join("")}`);
    }
    const cid = CID2.asCID(node);
    if (cid) {
      return { value: cid, remaining: path.slice(index2 + 1).join("/") };
    }
  }
  return { value: node };
}
var Block = class {
  /**
   * @param {object} options
   * @param {CID<T, C, A, V>} options.cid
   * @param {API.ByteView<T>} options.bytes
   * @param {T} options.value
   */
  constructor({ cid, bytes: bytes2, value }) {
    if (!cid || !bytes2 || typeof value === "undefined") {
      throw new Error("Missing required argument");
    }
    this.cid = cid;
    this.bytes = bytes2;
    this.value = value;
    this.asBlock = this;
    Object.defineProperties(this, {
      cid: readonly(),
      bytes: readonly(),
      value: readonly(),
      asBlock: readonly()
    });
  }
  links() {
    return links2(this.value, []);
  }
  tree() {
    return tree(this.value, []);
  }
  /**
   *
   * @param {string} [path]
   * @returns {API.BlockCursorView<unknown>}
   */
  get(path = "/") {
    return get14(this.value, path.split("/").filter(Boolean));
  }
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/sharded-directory.js
var defaults4 = defaults2;
var create15 = ({ writer, settings = defaults4(), metadata = {} }) => new HAMTDirectoryWriter({
  writer,
  metadata,
  settings,
  entries: new HashMap(),
  closed: false
});
var asWritable2 = (writer) => {
  if (!writer.closed) {
    return writer;
  } else {
    throw new Error("Can not change written HAMT directory, but you can .fork() and make changes to it");
  }
};
var close7 = async (view6, { closeWriter = false, releaseLock = false } = {}) => {
  const { writer, settings, metadata } = asWritable2(view6.state);
  view6.state.closed = true;
  const { entries: entries3 } = view6.state;
  if (!(entries3 instanceof HashMap)) {
    throw new Error(`not a HAMT: ${entries3}`);
  }
  const hamt = entries3.builder.build();
  const blocks = iterateBlocks(hamt, hamt.root, settings);
  let root2 = null;
  for await (const block of blocks) {
    root2 = block;
    if ((writer.desiredSize || 0) <= 0) {
      await writer.ready;
    }
    writer.write(block);
  }
  if (root2 == null) throw new Error("no root block yielded");
  if (closeWriter) {
    await writer.close();
  } else if (releaseLock) {
    writer.releaseLock();
  }
  return {
    cid: root2.cid,
    dagByteLength: cumulativeDagByteLength(root2.bytes, root2.value.entries)
  };
};
var iterateBlocks = async function* (hamt, node, settings) {
  const entries3 = [];
  for (const ent of iterate3(node)) {
    if ("key" in ent) {
      entries3.push(
        /** @type {UnixFS.DirectoryEntryLink} */
        {
          name: `${ent.prefix ?? ""}${ent.key ?? ""}`,
          dagByteLength: ent.value.dagByteLength,
          cid: ent.value.cid
        }
      );
    } else {
      let root2 = null;
      for await (const block of iterateBlocks(hamt, ent.node, settings)) {
        yield block;
        root2 = block;
      }
      if (root2 == null) throw new Error("no root block yielded");
      entries3.push(
        /** @type {UnixFS.ShardedDirectoryLink} */
        {
          name: ent.prefix,
          dagByteLength: cumulativeDagByteLength(root2.bytes, root2.value.entries),
          cid: root2.cid
        }
      );
    }
  }
  const shard = createDirectoryShard(
    entries3,
    bitField(node),
    tableSize(hamt),
    murmur364.code
  );
  yield await encodeHAMTShardBlock(shard, settings);
};
async function encodeHAMTShardBlock(shard, settings) {
  const bytes2 = encodeHAMTShard(shard);
  const hash = await settings.hasher.digest(bytes2);
  const cid = settings.linker.createLink(code15, hash);
  return new Block({ cid, bytes: bytes2, value: shard });
}
var fork4 = ({ state }, {
  writer = state.writer,
  metadata = state.metadata,
  settings = state.settings
} = {}) => new HAMTDirectoryWriter({
  writer,
  metadata,
  settings,
  entries: new HashMap(from18(state.entries.entries()).createBuilder()),
  closed: false
});
var HAMTDirectoryWriter = class {
  /**
   * @param {API.State<Layout>} state
   */
  constructor(state) {
    this.state = state;
  }
  get writer() {
    return this.state.writer;
  }
  get settings() {
    return this.state.settings;
  }
  /**
   * @param {string} name
   * @param {UnixFS.FileLink | UnixFS.DirectoryLink} link
   * @param {API.WriteOptions} [options]
   */
  set(name14, link5, options) {
    return set(this, name14, link5, options);
  }
  /**
   * @param {string} name
   */
  remove(name14) {
    return remove7(this, name14);
  }
  /**
   * @template L
   * @param {Partial<API.Options<L>>} [options]
   * @returns {API.View<Layout|L>}
   */
  fork(options) {
    return fork4(this, options);
  }
  /**
   * @param {API.CloseOptions} [options]
   * @returns {Promise<UnixFS.DirectoryLink>}
   */
  close(options) {
    return close7(this, options);
  }
  entries() {
    return this.state.entries.entries();
  }
  /**
   * @param {string} name
   */
  has(name14) {
    return this.state.entries.has(name14);
  }
  get size() {
    return this.state.entries.size;
  }
};
var HashMap = class extends Map {
  /**
   * @param {UnixFSPermaMap.HashMapBuilder} [builder]
   */
  constructor(builder3 = builder2()) {
    super();
    this.builder = builder3;
  }
  clear() {
    this.builder = builder2();
  }
  /**
   * @param {string} key
   */
  delete(key) {
    const { root: root2 } = this.builder;
    this.builder.delete(key);
    return this.builder.root !== root2;
  }
  /**
   * @param {(value: API.EntryLink, key: string, map: Map<string, API.EntryLink>) => void} callbackfn
   * @param {any} [thisArg]
   */
  forEach(callbackfn, thisArg = this) {
    for (const [k, v] of this.builder.root.entries()) {
      callbackfn.call(thisArg, v, k, this);
    }
  }
  /**
   * @param {string} key
   */
  get(key) {
    return get13(this.builder, key);
  }
  /**
   * @param {string} key
   */
  has(key) {
    return has(this.builder, key);
  }
  /**
   * @param {string} key 
   * @param {API.EntryLink} value 
   */
  set(key, value) {
    this.builder.set(key, value);
    return this;
  }
  get size() {
    return this.builder.size;
  }
  [Symbol.iterator]() {
    return this.builder.root.entries();
  }
  entries() {
    return this.builder.root.entries();
  }
  keys() {
    return this.builder.root.keys();
  }
  values() {
    return this.builder.root.values();
  }
};

// ../../node_modules/.pnpm/@ipld+unixfs@2.2.0/node_modules/@ipld/unixfs/src/lib.js
var createWriter3 = ({ writable, settings = defaults2() }) => new FileSystemWriter({
  writer: writable.getWriter(),
  settings
});
var close8 = async (view6, { releaseLock = true, closeWriter = true } = {}) => {
  if (closeWriter) {
    await view6.writer.close();
  } else if (releaseLock) {
    view6.writer.releaseLock();
  }
  return view6;
};
var FileSystemWriter = class {
  /**
   * @param {object} options
   * @param {API.BlockWriter} options.writer
   * @param {Partial<API.EncoderSettings<Layout>>} options.settings
   */
  constructor({ writer, settings }) {
    this.writer = writer;
    this.settings = configure(settings);
  }
  /**
   * @template [L=unknown]
   * @param {API.WriterOptions<L|Layout>} config
   */
  createFileWriter({ settings = this.settings, metadata } = {}) {
    return create12({
      writer: this.writer,
      settings,
      metadata
    });
  }
  /**
   * @template [L=unknown]
   * @param {API.WriterOptions<L|Layout>} config
   */
  createDirectoryWriter({ settings = this.settings, metadata } = {}) {
    return create13({
      writer: this.writer,
      settings,
      metadata
    });
  }
  /**
   * @param {API.CloseOptions} [options]
   */
  close(options) {
    return close8(this, options);
  }
};
var BLOCK_SIZE_LIMIT = 1048576;
var defaultCapacity = BLOCK_SIZE_LIMIT * 100;
var withCapacity = (byteLength = defaultCapacity) => ({
  highWaterMark: byteLength,
  size: (block) => block.bytes.length
});

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/unixfs.js
var SHARD_THRESHOLD = 1e3;
var queuingStrategy = withCapacity();
var defaultSettings = configure({
  fileChunkEncoder: raw_exports2,
  smallFileEncoder: raw_exports2,
  chunker: withMaxChunkSize(1024 * 1024),
  fileLayout: withWidth(1024)
});
async function encodeFile2(blob3, options) {
  const readable = createFileEncoderStream(blob3, options);
  const blocks = await collect2(readable);
  return { cid: blocks.at(-1).cid, blocks };
}
function createFileEncoderStream(blob3, options) {
  const { readable, writable } = new TransformStream({}, queuingStrategy);
  const settings = options?.settings ?? defaultSettings;
  const unixfsWriter = createWriter3({ writable, settings });
  const fileBuilder = new UnixFSFileBuilder("", blob3);
  void (async () => {
    await fileBuilder.finalize(unixfsWriter);
    await unixfsWriter.close();
  })();
  return readable;
}
var _file;
var UnixFSFileBuilder = class {
  /**
   * @param {string} name
   * @param {import('./types.js').BlobLike} file
   */
  constructor(name14, file) {
    __privateAdd(this, _file);
    this.name = name14;
    __privateSet(this, _file, file);
  }
  /** @param {import('@ipld/unixfs').View} writer */
  async finalize(writer) {
    const unixfsFileWriter = create12(writer);
    await __privateGet(this, _file).stream().pipeTo(new WritableStream({
      async write(chunk) {
        await unixfsFileWriter.write(chunk);
      }
    }));
    return await unixfsFileWriter.close();
  }
};
_file = new WeakMap();
var _options;
var UnixFSDirectoryBuilder = class {
  /**
   * @param {string} name
   * @param {import('./types.js').UnixFSDirectoryEncoderOptions} [options]
   */
  constructor(name14, options) {
    __privateAdd(this, _options);
    /** @type {Map<string, UnixFSFileBuilder | UnixFSDirectoryBuilder>} */
    __publicField(this, "entries", /* @__PURE__ */ new Map());
    this.name = name14;
    __privateSet(this, _options, options);
  }
  /** @param {import('@ipld/unixfs').View} writer */
  async finalize(writer) {
    const dirWriter = this.entries.size <= SHARD_THRESHOLD ? create13(writer) : create15(writer);
    for (const [name14, entry] of this.entries) {
      const link5 = await entry.finalize(writer);
      if (__privateGet(this, _options)?.onDirectoryEntryLink) {
        __privateGet(this, _options).onDirectoryEntryLink({ name: entry.name, ...link5 });
      }
      dirWriter.set(name14, link5);
    }
    return await dirWriter.close();
  }
};
_options = new WeakMap();
async function encodeDirectory2(files, options) {
  const readable = createDirectoryEncoderStream(files, options);
  const blocks = await collect2(readable);
  return { cid: blocks.at(-1).cid, blocks };
}
function createDirectoryEncoderStream(files, options) {
  const rootDir = new UnixFSDirectoryBuilder("", options);
  for (const file of files) {
    const path = file.name.split("/");
    if (path[0] === "" || path[0] === ".") {
      path.shift();
    }
    let dir = rootDir;
    for (const [i, name14] of path.entries()) {
      if (i === path.length - 1) {
        dir.entries.set(name14, new UnixFSFileBuilder(path.join("/"), file));
        break;
      }
      let dirBuilder = dir.entries.get(name14);
      if (dirBuilder == null) {
        const dirName = dir === rootDir ? name14 : `${dir.name}/${name14}`;
        dirBuilder = new UnixFSDirectoryBuilder(dirName, options);
        dir.entries.set(name14, dirBuilder);
      }
      if (!(dirBuilder instanceof UnixFSDirectoryBuilder)) {
        throw new Error(`"${file.name}" cannot be a file and a directory`);
      }
      dir = dirBuilder;
    }
  }
  const { readable, writable } = new TransformStream({}, queuingStrategy);
  const settings = options?.settings ?? defaultSettings;
  const unixfsWriter = createWriter3({ writable, settings });
  void (async () => {
    const link5 = await rootDir.finalize(unixfsWriter);
    if (options?.onDirectoryEntryLink) {
      options.onDirectoryEntryLink({ name: "", ...link5 });
    }
    await unixfsWriter.close();
  })();
  return readable;
}
async function collect2(collectable) {
  const chunks = [];
  await collectable.pipeTo(new WritableStream({
    write(chunk) {
      chunks.push(chunk);
    }
  }));
  return chunks;
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/car.js
var car_exports3 = {};
__export(car_exports3, {
  BlockStream: () => BlockStream,
  blockEncodingLength: () => blockEncodingLength,
  blockHeaderEncodingLength: () => blockHeaderEncodingLength,
  code: () => code17,
  encode: () => encode30,
  headerEncodingLength: () => headerEncodingLength
});

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/indexed-reader.js
init_empty();
init_empty();

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/decoder.js
async function readHeader2(reader, strictVersion) {
  const length4 = decodeVarint(await reader.upTo(8), reader);
  if (length4 === 0) {
    throw new Error("Invalid CAR header (zero length)");
  }
  const header = await reader.exactly(length4, true);
  const block = decode6(header);
  if (CarV1HeaderOrV2Pragma.toTyped(block) === void 0) {
    throw new Error("Invalid CAR header format");
  }
  if (block.version !== 1 && block.version !== 2 || strictVersion !== void 0 && block.version !== strictVersion) {
    throw new Error(`Invalid CAR version: ${block.version}${strictVersion !== void 0 ? ` (expected ${strictVersion})` : ""}`);
  }
  if (block.version === 1) {
    if (!Array.isArray(block.roots)) {
      throw new Error("Invalid CAR header format");
    }
    return block;
  }
  if (block.roots !== void 0) {
    throw new Error("Invalid CAR header format");
  }
  const v2Header = decodeV2Header(await reader.exactly(V2_HEADER_LENGTH, true));
  reader.seek(v2Header.dataOffset - reader.pos);
  const v1Header = await readHeader2(reader, 1);
  return Object.assign(v1Header, v2Header);
}
async function readCid2(reader) {
  const first = await reader.exactly(2, false);
  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {
    const bytes3 = await reader.exactly(34, true);
    const multihash2 = decode5(bytes3);
    return CID.create(0, CIDV0_BYTES.DAG_PB, multihash2);
  }
  const version2 = decodeVarint(await reader.upTo(8), reader);
  if (version2 !== 1) {
    throw new Error(`Unexpected CID version (${version2})`);
  }
  const codec = decodeVarint(await reader.upTo(8), reader);
  const bytes2 = await reader.exactly(getMultihashLength(await reader.upTo(8)), true);
  const multihash = decode5(bytes2);
  return CID.create(version2, codec, multihash);
}
async function readBlockHead2(reader) {
  const start = reader.pos;
  let length4 = decodeVarint(await reader.upTo(8), reader);
  if (length4 === 0) {
    throw new Error("Invalid CAR section (zero length)");
  }
  length4 += reader.pos - start;
  const cid = await readCid2(reader);
  const blockLength2 = length4 - Number(reader.pos - start);
  return { cid, length: length4, blockLength: blockLength2 };
}
async function readBlock(reader) {
  const { cid, blockLength: blockLength2 } = await readBlockHead2(reader);
  const bytes2 = await reader.exactly(blockLength2, true);
  return { bytes: bytes2, cid };
}
async function readBlockIndex(reader) {
  const offset2 = reader.pos;
  const { cid, length: length4, blockLength: blockLength2 } = await readBlockHead2(reader);
  const index2 = { cid, length: length4, blockLength: blockLength2, offset: offset2, blockOffset: reader.pos };
  reader.seek(index2.blockLength);
  return index2;
}
function createDecoder(reader) {
  const headerPromise = (async () => {
    const header = await readHeader2(reader);
    if (header.version === 2) {
      const v1length = reader.pos - header.dataOffset;
      reader = limitReader2(reader, header.dataSize - v1length);
    }
    return header;
  })();
  return {
    header: () => headerPromise,
    async *blocks() {
      await headerPromise;
      while ((await reader.upTo(8)).length > 0) {
        yield await readBlock(reader);
      }
    },
    async *blocksIndex() {
      await headerPromise;
      while ((await reader.upTo(8)).length > 0) {
        yield await readBlockIndex(reader);
      }
    }
  };
}
function bytesReader2(bytes2) {
  let pos = 0;
  return {
    async upTo(length4) {
      const out = bytes2.subarray(pos, pos + Math.min(length4, bytes2.length - pos));
      return out;
    },
    async exactly(length4, seek = false) {
      if (length4 > bytes2.length - pos) {
        throw new Error("Unexpected end of data");
      }
      const out = bytes2.subarray(pos, pos + length4);
      if (seek) {
        pos += length4;
      }
      return out;
    },
    seek(length4) {
      pos += length4;
    },
    get pos() {
      return pos;
    }
  };
}
function chunkReader(readChunk) {
  let pos = 0;
  let have = 0;
  let offset2 = 0;
  let currentChunk = new Uint8Array(0);
  const read9 = async (length4) => {
    have = currentChunk.length - offset2;
    const bufa = [currentChunk.subarray(offset2)];
    while (have < length4) {
      const chunk = await readChunk();
      if (chunk == null) {
        break;
      }
      if (have < 0) {
        if (chunk.length > have) {
          bufa.push(chunk.subarray(-have));
        }
      } else {
        bufa.push(chunk);
      }
      have += chunk.length;
    }
    currentChunk = new Uint8Array(bufa.reduce((p, c) => p + c.length, 0));
    let off = 0;
    for (const b of bufa) {
      currentChunk.set(b, off);
      off += b.length;
    }
    offset2 = 0;
  };
  return {
    async upTo(length4) {
      if (currentChunk.length - offset2 < length4) {
        await read9(length4);
      }
      return currentChunk.subarray(offset2, offset2 + Math.min(currentChunk.length - offset2, length4));
    },
    async exactly(length4, seek = false) {
      if (currentChunk.length - offset2 < length4) {
        await read9(length4);
      }
      if (currentChunk.length - offset2 < length4) {
        throw new Error("Unexpected end of data");
      }
      const out = currentChunk.subarray(offset2, offset2 + length4);
      if (seek) {
        pos += length4;
        offset2 += length4;
      }
      return out;
    },
    seek(length4) {
      pos += length4;
      offset2 += length4;
    },
    get pos() {
      return pos;
    }
  };
}
function asyncIterableReader(asyncIterable) {
  const iterator = asyncIterable[Symbol.asyncIterator]();
  async function readChunk() {
    const next = await iterator.next();
    if (next.done) {
      return null;
    }
    return next.value;
  }
  return chunkReader(readChunk);
}
function limitReader2(reader, byteLimit) {
  let bytesRead = 0;
  return {
    async upTo(length4) {
      let bytes2 = await reader.upTo(length4);
      if (bytes2.length + bytesRead > byteLimit) {
        bytes2 = bytes2.subarray(0, byteLimit - bytesRead);
      }
      return bytes2;
    },
    async exactly(length4, seek = false) {
      const bytes2 = await reader.exactly(length4, seek);
      if (bytes2.length + bytesRead > byteLimit) {
        throw new Error("Unexpected end of data");
      }
      if (seek) {
        bytesRead += length4;
      }
      return bytes2;
    },
    seek(length4) {
      bytesRead += length4;
      reader.seek(length4);
    },
    get pos() {
      return reader.pos;
    }
  };
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/iterator.js
var CarIteratorBase = class {
  /**
   * @param {number} version
   * @param {CID[]} roots
   * @param {AsyncIterable<Block>|void} iterable
   */
  constructor(version2, roots, iterable) {
    this._version = version2;
    this._roots = roots;
    this._iterable = iterable;
    this._decoded = false;
  }
  get version() {
    return this._version;
  }
  /**
   * @returns {Promise<CID[]>}
   */
  async getRoots() {
    return this._roots;
  }
};
var CarBlockIterator = class _CarBlockIterator extends CarIteratorBase {
  // inherited method
  /**
   * Get the list of roots defined by the CAR referenced by this iterator. May be
   * zero or more `CID`s.
   *
   * @function getRoots
   * @memberof CarBlockIterator
   * @instance
   * @async
   * @returns {Promise<CID[]>}
   */
  /**
   * @returns {AsyncIterator<Block>}
   */
  [Symbol.asyncIterator]() {
    if (this._decoded) {
      throw new Error("Cannot decode more than once");
    }
    if (!this._iterable) {
      throw new Error("Block iterable not found");
    }
    this._decoded = true;
    return this._iterable[Symbol.asyncIterator]();
  }
  /**
   * Instantiate a {@link CarBlockIterator} from a `Uint8Array` blob. Rather
   * than decoding the entire byte array prior to returning the iterator, as in
   * {@link CarReader.fromBytes}, only the header is decoded and the remainder
   * of the CAR is parsed as the `Block`s as yielded.
   *
   * @async
   * @static
   * @memberof CarBlockIterator
   * @param {Uint8Array} bytes
   * @returns {Promise<CarBlockIterator>}
   */
  static async fromBytes(bytes2) {
    const { version: version2, roots, iterator } = await fromBytes5(bytes2);
    return new _CarBlockIterator(version2, roots, iterator);
  }
  /**
   * Instantiate a {@link CarBlockIterator} from a `AsyncIterable<Uint8Array>`,
   * such as a [modern Node.js stream](https://nodejs.org/api/stream.html#stream_streams_compatibility_with_async_generators_and_async_iterators).
   * Rather than decoding the entire byte array prior to returning the iterator,
   * as in {@link CarReader.fromIterable}, only the header is decoded and the
   * remainder of the CAR is parsed as the `Block`s as yielded.
   *
   * @async
   * @static
   * @param {AsyncIterable<Uint8Array>} asyncIterable
   * @returns {Promise<CarBlockIterator>}
   */
  static async fromIterable(asyncIterable) {
    const { version: version2, roots, iterator } = await fromIterable(asyncIterable);
    return new _CarBlockIterator(version2, roots, iterator);
  }
};
async function fromBytes5(bytes2) {
  if (!(bytes2 instanceof Uint8Array)) {
    throw new TypeError("fromBytes() requires a Uint8Array");
  }
  return decodeIterator(bytesReader2(bytes2));
}
async function fromIterable(asyncIterable) {
  if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === "function")) {
    throw new TypeError("fromIterable() requires an async iterable");
  }
  return decodeIterator(asyncIterableReader(asyncIterable));
}
async function decodeIterator(reader) {
  const decoder3 = createDecoder(reader);
  const { version: version2, roots } = await decoder3.header();
  return { version: version2, roots, iterator: decoder3.blocks() };
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/encoder.js
var import_varint6 = __toESM(require_varint(), 1);
var CAR_V1_VERSION = 1;
function createHeader(roots) {
  const headerBytes = encode4({ version: CAR_V1_VERSION, roots });
  const varintBytes = import_varint6.default.encode(headerBytes.length);
  const header = new Uint8Array(varintBytes.length + headerBytes.length);
  header.set(varintBytes, 0);
  header.set(headerBytes, varintBytes.length);
  return header;
}
function createEncoder(writer) {
  return {
    /**
     * @param {CID[]} roots
     * @returns {Promise<void>}
     */
    async setRoots(roots) {
      const bytes2 = createHeader(roots);
      await writer.write(bytes2);
    },
    /**
     * @param {Block} block
     * @returns {Promise<void>}
     */
    async writeBlock(block) {
      const { cid, bytes: bytes2 } = block;
      await writer.write(new Uint8Array(import_varint6.default.encode(cid.bytes.length + bytes2.length)));
      await writer.write(cid.bytes);
      if (bytes2.length) {
        await writer.write(bytes2);
      }
    },
    /**
     * @returns {Promise<void>}
     */
    async close() {
      await writer.end();
    },
    /**
     * @returns {number}
     */
    version() {
      return CAR_V1_VERSION;
    }
  };
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/iterator-channel.js
function noop() {
}
function create16() {
  const chunkQueue = [];
  let drainer = null;
  let drainerResolver = noop;
  let ended = false;
  let outWait = null;
  let outWaitResolver = noop;
  const makeDrainer = () => {
    if (!drainer) {
      drainer = new Promise((resolve) => {
        drainerResolver = () => {
          drainer = null;
          drainerResolver = noop;
          resolve();
        };
      });
    }
    return drainer;
  };
  const writer = {
    /**
     * @param {T} chunk
     * @returns {Promise<void>}
     */
    write(chunk) {
      chunkQueue.push(chunk);
      const drainer2 = makeDrainer();
      outWaitResolver();
      return drainer2;
    },
    async end() {
      ended = true;
      const drainer2 = makeDrainer();
      outWaitResolver();
      await drainer2;
    }
  };
  const iterator = {
    /** @returns {Promise<IteratorResult<T>>} */
    async next() {
      const chunk = chunkQueue.shift();
      if (chunk) {
        if (chunkQueue.length === 0) {
          drainerResolver();
        }
        return { done: false, value: chunk };
      }
      if (ended) {
        drainerResolver();
        return { done: true, value: void 0 };
      }
      if (!outWait) {
        outWait = new Promise((resolve) => {
          outWaitResolver = () => {
            outWait = null;
            outWaitResolver = noop;
            return resolve(iterator.next());
          };
        });
      }
      return outWait;
    }
  };
  return { writer, iterator };
}

// ../../node_modules/.pnpm/@ipld+car@5.3.2/node_modules/@ipld/car/src/writer-browser.js
var CarWriter = class _CarWriter {
  /**
   * @param {CID[]} roots
   * @param {CarEncoder} encoder
   */
  constructor(roots, encoder3) {
    this._encoder = encoder3;
    this._mutex = encoder3.setRoots(roots);
    this._ended = false;
  }
  /**
   * Write a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) to the archive.
   *
   * @function
   * @memberof CarWriter
   * @instance
   * @async
   * @param {Block} block - A `{ cid:CID, bytes:Uint8Array }` pair.
   * @returns {Promise<void>} The returned promise will only resolve once the
   * bytes this block generates are written to the `out` iterable.
   */
  async put(block) {
    if (!(block.bytes instanceof Uint8Array) || !block.cid) {
      throw new TypeError("Can only write {cid, bytes} objects");
    }
    if (this._ended) {
      throw new Error("Already closed");
    }
    const cid = CID.asCID(block.cid);
    if (!cid) {
      throw new TypeError("Can only write {cid, bytes} objects");
    }
    this._mutex = this._mutex.then(() => this._encoder.writeBlock({ cid, bytes: block.bytes }));
    return this._mutex;
  }
  /**
   * Finalise the CAR archive and signal that the `out` iterable should end once
   * any remaining bytes are written.
   *
   * @function
   * @memberof CarWriter
   * @instance
   * @async
   * @returns {Promise<void>}
   */
  async close() {
    if (this._ended) {
      throw new Error("Already closed");
    }
    await this._mutex;
    this._ended = true;
    return this._encoder.close();
  }
  /**
   * Returns the version number of the CAR file being written
   *
   * @returns {number}
   */
  version() {
    return this._encoder.version();
  }
  /**
   * Create a new CAR writer "channel" which consists of a
   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }` pair.
   *
   * @async
   * @static
   * @memberof CarWriter
   * @param {CID[] | CID | void} roots
   * @returns {WriterChannel} The channel takes the form of
   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }`.
   */
  static create(roots) {
    roots = toRoots(roots);
    const { encoder: encoder3, iterator } = encodeWriter();
    const writer = new _CarWriter(roots, encoder3);
    const out = new CarWriterOut(iterator);
    return { writer, out };
  }
  /**
   * Create a new CAR appender "channel" which consists of a
   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }` pair.
   * This appender does not consider roots and does not produce a CAR header.
   * It is designed to append blocks to an _existing_ CAR archive. It is
   * expected that `out` will be concatenated onto the end of an existing
   * archive that already has a properly formatted header.
   *
   * @async
   * @static
   * @memberof CarWriter
   * @returns {WriterChannel} The channel takes the form of
   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }`.
   */
  static createAppender() {
    const { encoder: encoder3, iterator } = encodeWriter();
    encoder3.setRoots = () => Promise.resolve();
    const writer = new _CarWriter([], encoder3);
    const out = new CarWriterOut(iterator);
    return { writer, out };
  }
  /**
   * Update the list of roots in the header of an existing CAR as represented
   * in a Uint8Array.
   *
   * This operation is an _overwrite_, the total length of the CAR will not be
   * modified. A rejection will occur if the new header will not be the same
   * length as the existing header, in which case the CAR will not be modified.
   * It is the responsibility of the user to ensure that the roots being
   * replaced encode as the same length as the new roots.
   *
   * The byte array passed in an argument will be modified and also returned
   * upon successful modification.
   *
   * @async
   * @static
   * @memberof CarWriter
   * @param {Uint8Array} bytes
   * @param {CID[]} roots - A new list of roots to replace the existing list in
   * the CAR header. The new header must take up the same number of bytes as the
   * existing header, so the roots should collectively be the same byte length
   * as the existing roots.
   * @returns {Promise<Uint8Array>}
   */
  static async updateRootsInBytes(bytes2, roots) {
    const reader = bytesReader2(bytes2);
    await readHeader2(reader);
    const newHeader = createHeader(roots);
    if (Number(reader.pos) !== newHeader.length) {
      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${reader.pos} bytes, new header is ${newHeader.length} bytes)`);
    }
    bytes2.set(newHeader, 0);
    return bytes2;
  }
};
var CarWriterOut = class {
  /**
   * @param {AsyncIterator<Uint8Array>} iterator
   */
  constructor(iterator) {
    this._iterator = iterator;
  }
  [Symbol.asyncIterator]() {
    if (this._iterating) {
      throw new Error("Multiple iterator not supported");
    }
    this._iterating = true;
    return this._iterator;
  }
};
function encodeWriter() {
  const iw = create16();
  const { writer, iterator } = iw;
  const encoder3 = createEncoder(writer);
  return { encoder: encoder3, iterator };
}
function toRoots(roots) {
  if (roots === void 0) {
    return [];
  }
  if (!Array.isArray(roots)) {
    const cid = CID.asCID(roots);
    if (!cid) {
      throw new TypeError("roots must be a single CID or an array of CIDs");
    }
    return [cid];
  }
  const _roots = [];
  for (const root2 of roots) {
    const _root = CID.asCID(root2);
    if (!_root) {
      throw new TypeError("roots must be a single CID or an array of CIDs");
    }
    _roots.push(_root);
  }
  return _roots;
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/car.js
var import_varint7 = __toESM(require_varint(), 1);
var code17 = 514;
var NO_ROOTS_HEADER_LENGTH = 18;
function headerEncodingLength(root2) {
  if (!root2)
    return NO_ROOTS_HEADER_LENGTH;
  const headerLength2 = encode4({ version: 1, roots: [root2] }).length;
  const varintLength = import_varint7.default.encodingLength(headerLength2);
  return varintLength + headerLength2;
}
function blockHeaderEncodingLength(block) {
  const payloadLength = block.cid.bytes.length + block.bytes.length;
  const varintLength = import_varint7.default.encodingLength(payloadLength);
  return varintLength + block.cid.bytes.length;
}
function blockEncodingLength(block) {
  return blockHeaderEncodingLength(block) + block.bytes.length;
}
async function encode30(blocks, root2) {
  const { writer, out } = CarWriter.create(root2);
  let error3;
  void (async () => {
    try {
      for await (const block of blocks) {
        await writer.put(block);
      }
    } catch (err) {
      error3 = err;
    } finally {
      await writer.close();
    }
  })();
  const chunks = [];
  for await (const chunk of out)
    chunks.push(chunk);
  if (error3 != null)
    throw error3;
  const roots = root2 != null ? [root2] : [];
  return Object.assign(new Blob(chunks), { version: 1, roots });
}
var BlockStream = class extends ReadableStream {
  /** @param {import('./types.js').BlobLike} car */
  constructor(car) {
    let blocksPromise = null;
    const getBlocksIterable = () => {
      if (blocksPromise)
        return blocksPromise;
      blocksPromise = CarBlockIterator.fromIterable(toIterable(car.stream()));
      return blocksPromise;
    };
    let iterator = null;
    super({
      async start() {
        const blocks = await getBlocksIterable();
        iterator = /** @type {AsyncIterator<Block>} */
        blocks[Symbol.asyncIterator]();
      },
      async pull(controller) {
        if (!iterator)
          throw new Error("missing blocks iterator");
        const { value, done } = await iterator.next();
        if (done)
          return controller.close();
        controller.enqueue(value);
      }
    });
    this.getRoots = async () => {
      const blocks = await getBlocksIterable();
      return await blocks.getRoots();
    };
  }
};
function toIterable(stream) {
  return Symbol.asyncIterator in stream ? stream : async function* () {
    const reader = stream.getReader();
    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done)
          return;
        yield value;
      }
    } finally {
      reader.releaseLock();
    }
  }();
}

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/alloc.js
function alloc2(size5 = 0) {
  return new Uint8Array(size5);
}
function allocUnsafe(size5 = 0) {
  return new Uint8Array(size5);
}

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/util/as-uint8array.js
function asUint8Array2(buf2) {
  return buf2;
}

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/compare.js
function compare2(a, b) {
  for (let i = 0; i < a.byteLength; i++) {
    if (a[i] < b[i]) {
      return -1;
    }
    if (a[i] > b[i]) {
      return 1;
    }
  }
  if (a.byteLength > b.byteLength) {
    return 1;
  }
  if (a.byteLength < b.byteLength) {
    return -1;
  }
  return 0;
}

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/concat.js
function concat2(arrays, length4) {
  if (length4 == null) {
    length4 = arrays.reduce((acc, curr) => acc + curr.length, 0);
  }
  const output = allocUnsafe(length4);
  let offset2 = 0;
  for (const arr of arrays) {
    output.set(arr, offset2);
    offset2 += arr.length;
  }
  return asUint8Array2(output);
}

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base10.js
var base10_exports = {};
__export(base10_exports, {
  base10: () => base10
});
var base10 = baseX({
  prefix: "9",
  name: "base10",
  alphabet: "0123456789"
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base16.js
var base16_exports = {};
__export(base16_exports, {
  base16: () => base16,
  base16upper: () => base16upper
});
var base16 = rfc4648({
  prefix: "f",
  name: "base16",
  alphabet: "0123456789abcdef",
  bitsPerChar: 4
});
var base16upper = rfc4648({
  prefix: "F",
  name: "base16upper",
  alphabet: "0123456789ABCDEF",
  bitsPerChar: 4
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base2.js
var base2_exports = {};
__export(base2_exports, {
  base2: () => base22
});
var base22 = rfc4648({
  prefix: "0",
  name: "base2",
  alphabet: "01",
  bitsPerChar: 1
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base256emoji.js
var base256emoji_exports = {};
__export(base256emoji_exports, {
  base256emoji: () => base256emoji
});
var alphabet = Array.from("\u{1F680}\u{1FA90}\u2604\u{1F6F0}\u{1F30C}\u{1F311}\u{1F312}\u{1F313}\u{1F314}\u{1F315}\u{1F316}\u{1F317}\u{1F318}\u{1F30D}\u{1F30F}\u{1F30E}\u{1F409}\u2600\u{1F4BB}\u{1F5A5}\u{1F4BE}\u{1F4BF}\u{1F602}\u2764\u{1F60D}\u{1F923}\u{1F60A}\u{1F64F}\u{1F495}\u{1F62D}\u{1F618}\u{1F44D}\u{1F605}\u{1F44F}\u{1F601}\u{1F525}\u{1F970}\u{1F494}\u{1F496}\u{1F499}\u{1F622}\u{1F914}\u{1F606}\u{1F644}\u{1F4AA}\u{1F609}\u263A\u{1F44C}\u{1F917}\u{1F49C}\u{1F614}\u{1F60E}\u{1F607}\u{1F339}\u{1F926}\u{1F389}\u{1F49E}\u270C\u2728\u{1F937}\u{1F631}\u{1F60C}\u{1F338}\u{1F64C}\u{1F60B}\u{1F497}\u{1F49A}\u{1F60F}\u{1F49B}\u{1F642}\u{1F493}\u{1F929}\u{1F604}\u{1F600}\u{1F5A4}\u{1F603}\u{1F4AF}\u{1F648}\u{1F447}\u{1F3B6}\u{1F612}\u{1F92D}\u2763\u{1F61C}\u{1F48B}\u{1F440}\u{1F62A}\u{1F611}\u{1F4A5}\u{1F64B}\u{1F61E}\u{1F629}\u{1F621}\u{1F92A}\u{1F44A}\u{1F973}\u{1F625}\u{1F924}\u{1F449}\u{1F483}\u{1F633}\u270B\u{1F61A}\u{1F61D}\u{1F634}\u{1F31F}\u{1F62C}\u{1F643}\u{1F340}\u{1F337}\u{1F63B}\u{1F613}\u2B50\u2705\u{1F97A}\u{1F308}\u{1F608}\u{1F918}\u{1F4A6}\u2714\u{1F623}\u{1F3C3}\u{1F490}\u2639\u{1F38A}\u{1F498}\u{1F620}\u261D\u{1F615}\u{1F33A}\u{1F382}\u{1F33B}\u{1F610}\u{1F595}\u{1F49D}\u{1F64A}\u{1F639}\u{1F5E3}\u{1F4AB}\u{1F480}\u{1F451}\u{1F3B5}\u{1F91E}\u{1F61B}\u{1F534}\u{1F624}\u{1F33C}\u{1F62B}\u26BD\u{1F919}\u2615\u{1F3C6}\u{1F92B}\u{1F448}\u{1F62E}\u{1F646}\u{1F37B}\u{1F343}\u{1F436}\u{1F481}\u{1F632}\u{1F33F}\u{1F9E1}\u{1F381}\u26A1\u{1F31E}\u{1F388}\u274C\u270A\u{1F44B}\u{1F630}\u{1F928}\u{1F636}\u{1F91D}\u{1F6B6}\u{1F4B0}\u{1F353}\u{1F4A2}\u{1F91F}\u{1F641}\u{1F6A8}\u{1F4A8}\u{1F92C}\u2708\u{1F380}\u{1F37A}\u{1F913}\u{1F619}\u{1F49F}\u{1F331}\u{1F616}\u{1F476}\u{1F974}\u25B6\u27A1\u2753\u{1F48E}\u{1F4B8}\u2B07\u{1F628}\u{1F31A}\u{1F98B}\u{1F637}\u{1F57A}\u26A0\u{1F645}\u{1F61F}\u{1F635}\u{1F44E}\u{1F932}\u{1F920}\u{1F927}\u{1F4CC}\u{1F535}\u{1F485}\u{1F9D0}\u{1F43E}\u{1F352}\u{1F617}\u{1F911}\u{1F30A}\u{1F92F}\u{1F437}\u260E\u{1F4A7}\u{1F62F}\u{1F486}\u{1F446}\u{1F3A4}\u{1F647}\u{1F351}\u2744\u{1F334}\u{1F4A3}\u{1F438}\u{1F48C}\u{1F4CD}\u{1F940}\u{1F922}\u{1F445}\u{1F4A1}\u{1F4A9}\u{1F450}\u{1F4F8}\u{1F47B}\u{1F910}\u{1F92E}\u{1F3BC}\u{1F975}\u{1F6A9}\u{1F34E}\u{1F34A}\u{1F47C}\u{1F48D}\u{1F4E3}\u{1F942}");
var alphabetBytesToChars = alphabet.reduce((p, c, i) => {
  p[i] = c;
  return p;
}, []);
var alphabetCharsToBytes = alphabet.reduce((p, c, i) => {
  p[c.codePointAt(0)] = i;
  return p;
}, []);
function encode31(data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars[c];
    return p;
  }, "");
}
function decode39(str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes[char.codePointAt(0)];
    if (byt === void 0) {
      throw new Error(`Non-base256emoji character: ${char}`);
    }
    byts.push(byt);
  }
  return new Uint8Array(byts);
}
var base256emoji = from2({
  prefix: "\u{1F680}",
  name: "base256emoji",
  encode: encode31,
  decode: decode39
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base36.js
var base36_exports = {};
__export(base36_exports, {
  base36: () => base36,
  base36upper: () => base36upper
});
var base36 = baseX({
  prefix: "k",
  name: "base36",
  alphabet: "0123456789abcdefghijklmnopqrstuvwxyz"
});
var base36upper = baseX({
  prefix: "K",
  name: "base36upper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/base8.js
var base8_exports = {};
__export(base8_exports, {
  base8: () => base8
});
var base8 = rfc4648({
  prefix: "7",
  name: "base8",
  alphabet: "01234567",
  bitsPerChar: 3
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/bases/identity.js
var identity_exports = {};
__export(identity_exports, {
  identity: () => identity2
});
var identity2 = from2({
  prefix: "\0",
  name: "identity",
  encode: (buf2) => toString2(buf2),
  decode: (str) => fromString2(str)
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/codecs/json.js
var textEncoder4 = new TextEncoder();
var textDecoder3 = new TextDecoder();

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/hashes/identity.js
var identity_exports2 = {};
__export(identity_exports2, {
  identity: () => identity3
});
var code18 = 0;
var name13 = "identity";
var encode32 = coerce2;
function digest4(input10) {
  return create(code18, encode32(input10));
}
var identity3 = { code: code18, name: name13, encode: encode32, digest: digest4 };

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/hashes/sha2-browser.js
var sha2_browser_exports = {};
__export(sha2_browser_exports, {
  sha256: () => sha2564,
  sha512: () => sha5123
});
function sha3(name14) {
  return async (data) => new Uint8Array(await crypto.subtle.digest(name14, data));
}
var sha2564 = from6({
  name: "sha2-256",
  code: 18,
  encode: sha3("SHA-256")
});
var sha5123 = from6({
  name: "sha2-512",
  code: 19,
  encode: sha3("SHA-512")
});

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/basics.js
var bases = { ...identity_exports, ...base2_exports, ...base8_exports, ...base10_exports, ...base16_exports, ...base32_exports, ...base36_exports, ...base58_exports, ...base64_exports, ...base256emoji_exports };
var hashes = { ...sha2_browser_exports, ...identity_exports2 };

// ../../node_modules/.pnpm/uint8arrays@5.1.0/node_modules/uint8arrays/dist/src/util/bases.js
function createCodec(name14, prefix2, encode34, decode41) {
  return {
    name: name14,
    prefix: prefix2,
    encoder: {
      name: name14,
      prefix: prefix2,
      encode: encode34
    },
    decoder: {
      decode: decode41
    }
  };
}
var string2 = createCodec("utf8", "u", (buf2) => {
  const decoder3 = new TextDecoder("utf8");
  return "u" + decoder3.decode(buf2);
}, (str) => {
  const encoder3 = new TextEncoder();
  return encoder3.encode(str.substring(1));
});
var ascii = createCodec("ascii", "a", (buf2) => {
  let string3 = "a";
  for (let i = 0; i < buf2.length; i++) {
    string3 += String.fromCharCode(buf2[i]);
  }
  return string3;
}, (str) => {
  str = str.substring(1);
  const buf2 = allocUnsafe(str.length);
  for (let i = 0; i < str.length; i++) {
    buf2[i] = str.charCodeAt(i);
  }
  return buf2;
});
var BASES = {
  utf8: string2,
  "utf-8": string2,
  hex: bases.base16,
  latin1: ascii,
  ascii,
  binary: ascii,
  ...bases
};

// ../../node_modules/.pnpm/multiformats@13.2.2/node_modules/multiformats/dist/src/link.js
var DAG_PB_CODE5 = 112;
function createLegacy2(digest5) {
  return CID.create(0, DAG_PB_CODE5, digest5);
}
function create17(code19, digest5) {
  return CID.create(1, code19, digest5);
}

// ../../node_modules/.pnpm/@web3-storage+blob-index@1.0.4/node_modules/@web3-storage/blob-index/dist/src/digest-map.js
var cache4 = /* @__PURE__ */ new WeakMap();
var toBase58String = (digest5) => {
  let str = cache4.get(digest5.bytes);
  if (!str) {
    str = base58btc.encode(digest5.bytes);
    cache4.set(digest5.bytes, str);
  }
  return str;
};
var _data;
var DigestMap = class {
  /**
   * @param {Array<[Key, Value]>} [entries]
   */
  constructor(entries3) {
    /** @type {Map<string, [Key, Value]>} */
    __privateAdd(this, _data);
    __privateSet(this, _data, /* @__PURE__ */ new Map());
    for (const [k, v] of entries3 ?? []) {
      this.set(k, v);
    }
  }
  get [Symbol.toStringTag]() {
    return "DigestMap";
  }
  clear() {
    __privateGet(this, _data).clear();
  }
  /**
   * @param {Key} key
   * @returns {boolean}
   */
  delete(key) {
    const mhstr = toBase58String(key);
    return __privateGet(this, _data).delete(mhstr);
  }
  /**
   * @param {(value: Value, key: Key, map: Map<Key, Value>) => void} callbackfn
   * @param {any} [thisArg]
   */
  forEach(callbackfn, thisArg) {
    for (const [k, v] of __privateGet(this, _data).values()) {
      callbackfn.call(thisArg, v, k, this);
    }
  }
  /**
   * @param {Key} key
   * @returns {Value|undefined}
   */
  get(key) {
    const data = __privateGet(this, _data).get(toBase58String(key));
    if (data)
      return data[1];
  }
  /**
   * @param {Key} key
   * @returns {boolean}
   */
  has(key) {
    return __privateGet(this, _data).has(toBase58String(key));
  }
  /**
   * @param {Key} key
   * @param {Value} value
   */
  set(key, value) {
    __privateGet(this, _data).set(toBase58String(key), [key, value]);
    return this;
  }
  /** @returns {number} */
  get size() {
    return __privateGet(this, _data).size;
  }
  /** @returns */
  [Symbol.iterator]() {
    return this.entries();
  }
  /** @returns {IterableIterator<[Key, Value]>} */
  *entries() {
    yield* __privateGet(this, _data).values();
  }
  /** @returns {IterableIterator<Key>} */
  *keys() {
    for (const [k] of __privateGet(this, _data).values()) {
      yield k;
    }
  }
  /** @returns {IterableIterator<Value>} */
  *values() {
    for (const [, v] of __privateGet(this, _data).values()) {
      yield v;
    }
  }
};
_data = new WeakMap();

// ../../node_modules/.pnpm/@web3-storage+blob-index@1.0.4/node_modules/@web3-storage/blob-index/dist/src/sharded-dag-index.js
var version = "index/sharded/dag@0.1";
var ShardedDAGIndexSchema = schema_exports3.variant({
  [version]: schema_exports3.struct({
    /** DAG root. */
    content: schema_exports3.link(),
    /** Shards the DAG can be found in. */
    shards: schema_exports3.array(schema_exports3.link())
  })
});
var MultihashSchema = schema_exports3.bytes();
var BlobIndexSchema = schema_exports3.tuple([
  MultihashSchema,
  schema_exports3.array(
    /** multihash bytes, offset, length. */
    schema_exports3.tuple([
      MultihashSchema,
      schema_exports3.tuple([schema_exports3.number(), schema_exports3.number()])
    ])
  )
]);
var _content, _shards;
var ShardedDAGIndex = class {
  /** @param {API.UnknownLink} content */
  constructor(content2) {
    __privateAdd(this, _content);
    __privateAdd(this, _shards);
    __privateSet(this, _content, content2);
    __privateSet(this, _shards, new DigestMap());
  }
  get content() {
    return __privateGet(this, _content);
  }
  get shards() {
    return __privateGet(this, _shards);
  }
  /**
   * @param {API.ShardDigest} shard
   * @param {API.SliceDigest} slice
   * @param {API.Position} pos
   */
  setSlice(shard, slice3, pos) {
    let index2 = __privateGet(this, _shards).get(shard);
    if (!index2) {
      index2 = new DigestMap();
      __privateGet(this, _shards).set(shard, index2);
    }
    index2.set(slice3, pos);
  }
  archive() {
    return archive2(this);
  }
};
_content = new WeakMap();
_shards = new WeakMap();
var create18 = (content2) => new ShardedDAGIndex(content2);
var archive2 = async (model) => {
  const blocks = /* @__PURE__ */ new Map();
  const shards = [...model.shards.entries()].sort((a, b) => compare2(a[0].digest, b[0].digest));
  const index2 = {
    content: model.content,
    shards: (
      /** @type {API.Link[]} */
      []
    )
  };
  for (const s of shards) {
    const slices = [...s[1].entries()].sort((a, b) => compare2(a[0].digest, b[0].digest)).map((e) => [e[0].bytes, e[1]]);
    const bytes3 = encode4([s[0].bytes, slices]);
    const digest6 = await sha2564.digest(bytes3);
    const cid2 = create17(code3, digest6);
    blocks.set(cid2.toString(), { cid: cid2, bytes: bytes3 });
    index2.shards.push(cid2);
  }
  const bytes2 = encode4({ [version]: index2 });
  const digest5 = await sha2564.digest(bytes2);
  const cid = create17(code3, digest5);
  return ok(car_exports.encode({ roots: [{ cid, bytes: bytes2 }], blocks }));
};

// ../../node_modules/.pnpm/uint8arraylist@2.4.8/node_modules/uint8arraylist/dist/src/index.js
var symbol = Symbol.for("@achingbrain/uint8arraylist");
function findBufAndOffset(bufs, index2) {
  if (index2 == null || index2 < 0) {
    throw new RangeError("index is out of bounds");
  }
  let offset2 = 0;
  for (const buf2 of bufs) {
    const bufEnd = offset2 + buf2.byteLength;
    if (index2 < bufEnd) {
      return {
        buf: buf2,
        index: index2 - offset2
      };
    }
    offset2 = bufEnd;
  }
  throw new RangeError("index is out of bounds");
}
function isUint8ArrayList(value) {
  return Boolean(value?.[symbol]);
}
var _a2;
var Uint8ArrayList = class _Uint8ArrayList {
  constructor(...data) {
    __publicField(this, "bufs");
    __publicField(this, "length");
    __publicField(this, _a2, true);
    this.bufs = [];
    this.length = 0;
    if (data.length > 0) {
      this.appendAll(data);
    }
  }
  *[(_a2 = symbol, Symbol.iterator)]() {
    yield* this.bufs;
  }
  get byteLength() {
    return this.length;
  }
  /**
   * Add one or more `bufs` to the end of this Uint8ArrayList
   */
  append(...bufs) {
    this.appendAll(bufs);
  }
  /**
   * Add all `bufs` to the end of this Uint8ArrayList
   */
  appendAll(bufs) {
    let length4 = 0;
    for (const buf2 of bufs) {
      if (buf2 instanceof Uint8Array) {
        length4 += buf2.byteLength;
        this.bufs.push(buf2);
      } else if (isUint8ArrayList(buf2)) {
        length4 += buf2.byteLength;
        this.bufs.push(...buf2.bufs);
      } else {
        throw new Error("Could not append value, must be an Uint8Array or a Uint8ArrayList");
      }
    }
    this.length += length4;
  }
  /**
   * Add one or more `bufs` to the start of this Uint8ArrayList
   */
  prepend(...bufs) {
    this.prependAll(bufs);
  }
  /**
   * Add all `bufs` to the start of this Uint8ArrayList
   */
  prependAll(bufs) {
    let length4 = 0;
    for (const buf2 of bufs.reverse()) {
      if (buf2 instanceof Uint8Array) {
        length4 += buf2.byteLength;
        this.bufs.unshift(buf2);
      } else if (isUint8ArrayList(buf2)) {
        length4 += buf2.byteLength;
        this.bufs.unshift(...buf2.bufs);
      } else {
        throw new Error("Could not prepend value, must be an Uint8Array or a Uint8ArrayList");
      }
    }
    this.length += length4;
  }
  /**
   * Read the value at `index`
   */
  get(index2) {
    const res = findBufAndOffset(this.bufs, index2);
    return res.buf[res.index];
  }
  /**
   * Set the value at `index` to `value`
   */
  set(index2, value) {
    const res = findBufAndOffset(this.bufs, index2);
    res.buf[res.index] = value;
  }
  /**
   * Copy bytes from `buf` to the index specified by `offset`
   */
  write(buf2, offset2 = 0) {
    if (buf2 instanceof Uint8Array) {
      for (let i = 0; i < buf2.length; i++) {
        this.set(offset2 + i, buf2[i]);
      }
    } else if (isUint8ArrayList(buf2)) {
      for (let i = 0; i < buf2.length; i++) {
        this.set(offset2 + i, buf2.get(i));
      }
    } else {
      throw new Error("Could not write value, must be an Uint8Array or a Uint8ArrayList");
    }
  }
  /**
   * Remove bytes from the front of the pool
   */
  consume(bytes2) {
    bytes2 = Math.trunc(bytes2);
    if (Number.isNaN(bytes2) || bytes2 <= 0) {
      return;
    }
    if (bytes2 === this.byteLength) {
      this.bufs = [];
      this.length = 0;
      return;
    }
    while (this.bufs.length > 0) {
      if (bytes2 >= this.bufs[0].byteLength) {
        bytes2 -= this.bufs[0].byteLength;
        this.length -= this.bufs[0].byteLength;
        this.bufs.shift();
      } else {
        this.bufs[0] = this.bufs[0].subarray(bytes2);
        this.length -= bytes2;
        break;
      }
    }
  }
  /**
   * Extracts a section of an array and returns a new array.
   *
   * This is a copy operation as it is with Uint8Arrays and Arrays
   * - note this is different to the behaviour of Node Buffers.
   */
  slice(beginInclusive, endExclusive) {
    const { bufs, length: length4 } = this._subList(beginInclusive, endExclusive);
    return concat2(bufs, length4);
  }
  /**
   * Returns a alloc from the given start and end element index.
   *
   * In the best case where the data extracted comes from a single Uint8Array
   * internally this is a no-copy operation otherwise it is a copy operation.
   */
  subarray(beginInclusive, endExclusive) {
    const { bufs, length: length4 } = this._subList(beginInclusive, endExclusive);
    if (bufs.length === 1) {
      return bufs[0];
    }
    return concat2(bufs, length4);
  }
  /**
   * Returns a allocList from the given start and end element index.
   *
   * This is a no-copy operation.
   */
  sublist(beginInclusive, endExclusive) {
    const { bufs, length: length4 } = this._subList(beginInclusive, endExclusive);
    const list7 = new _Uint8ArrayList();
    list7.length = length4;
    list7.bufs = [...bufs];
    return list7;
  }
  _subList(beginInclusive, endExclusive) {
    beginInclusive = beginInclusive ?? 0;
    endExclusive = endExclusive ?? this.length;
    if (beginInclusive < 0) {
      beginInclusive = this.length + beginInclusive;
    }
    if (endExclusive < 0) {
      endExclusive = this.length + endExclusive;
    }
    if (beginInclusive < 0 || endExclusive > this.length) {
      throw new RangeError("index is out of bounds");
    }
    if (beginInclusive === endExclusive) {
      return { bufs: [], length: 0 };
    }
    if (beginInclusive === 0 && endExclusive === this.length) {
      return { bufs: this.bufs, length: this.length };
    }
    const bufs = [];
    let offset2 = 0;
    for (let i = 0; i < this.bufs.length; i++) {
      const buf2 = this.bufs[i];
      const bufStart = offset2;
      const bufEnd = bufStart + buf2.byteLength;
      offset2 = bufEnd;
      if (beginInclusive >= bufEnd) {
        continue;
      }
      const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
      const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
      if (sliceStartInBuf && sliceEndsInBuf) {
        if (beginInclusive === bufStart && endExclusive === bufEnd) {
          bufs.push(buf2);
          break;
        }
        const start = beginInclusive - bufStart;
        bufs.push(buf2.subarray(start, start + (endExclusive - beginInclusive)));
        break;
      }
      if (sliceStartInBuf) {
        if (beginInclusive === 0) {
          bufs.push(buf2);
          continue;
        }
        bufs.push(buf2.subarray(beginInclusive - bufStart));
        continue;
      }
      if (sliceEndsInBuf) {
        if (endExclusive === bufEnd) {
          bufs.push(buf2);
          break;
        }
        bufs.push(buf2.subarray(0, endExclusive - bufStart));
        break;
      }
      bufs.push(buf2);
    }
    return { bufs, length: endExclusive - beginInclusive };
  }
  indexOf(search, offset2 = 0) {
    if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
      throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
    }
    const needle = search instanceof Uint8Array ? search : search.subarray();
    offset2 = Number(offset2 ?? 0);
    if (isNaN(offset2)) {
      offset2 = 0;
    }
    if (offset2 < 0) {
      offset2 = this.length + offset2;
    }
    if (offset2 < 0) {
      offset2 = 0;
    }
    if (search.length === 0) {
      return offset2 > this.length ? this.length : offset2;
    }
    const M = needle.byteLength;
    if (M === 0) {
      throw new TypeError("search must be at least 1 byte long");
    }
    const radix = 256;
    const rightmostPositions = new Int32Array(radix);
    for (let c = 0; c < radix; c++) {
      rightmostPositions[c] = -1;
    }
    for (let j = 0; j < M; j++) {
      rightmostPositions[needle[j]] = j;
    }
    const right = rightmostPositions;
    const lastIndex = this.byteLength - needle.byteLength;
    const lastPatIndex = needle.byteLength - 1;
    let skip2;
    for (let i = offset2; i <= lastIndex; i += skip2) {
      skip2 = 0;
      for (let j = lastPatIndex; j >= 0; j--) {
        const char = this.get(i + j);
        if (needle[j] !== char) {
          skip2 = Math.max(1, j - right[char]);
          break;
        }
      }
      if (skip2 === 0) {
        return i;
      }
    }
    return -1;
  }
  getInt8(byteOffset) {
    const buf2 = this.subarray(byteOffset, byteOffset + 1);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getInt8(0);
  }
  setInt8(byteOffset, value) {
    const buf2 = allocUnsafe(1);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setInt8(0, value);
    this.write(buf2, byteOffset);
  }
  getInt16(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 2);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getInt16(0, littleEndian);
  }
  setInt16(byteOffset, value, littleEndian) {
    const buf2 = alloc2(2);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setInt16(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getInt32(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getInt32(0, littleEndian);
  }
  setInt32(byteOffset, value, littleEndian) {
    const buf2 = alloc2(4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setInt32(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getBigInt64(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getBigInt64(0, littleEndian);
  }
  setBigInt64(byteOffset, value, littleEndian) {
    const buf2 = alloc2(8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setBigInt64(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getUint8(byteOffset) {
    const buf2 = this.subarray(byteOffset, byteOffset + 1);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getUint8(0);
  }
  setUint8(byteOffset, value) {
    const buf2 = allocUnsafe(1);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setUint8(0, value);
    this.write(buf2, byteOffset);
  }
  getUint16(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 2);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getUint16(0, littleEndian);
  }
  setUint16(byteOffset, value, littleEndian) {
    const buf2 = alloc2(2);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setUint16(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getUint32(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getUint32(0, littleEndian);
  }
  setUint32(byteOffset, value, littleEndian) {
    const buf2 = alloc2(4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setUint32(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getBigUint64(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getBigUint64(0, littleEndian);
  }
  setBigUint64(byteOffset, value, littleEndian) {
    const buf2 = alloc2(8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setBigUint64(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getFloat32(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getFloat32(0, littleEndian);
  }
  setFloat32(byteOffset, value, littleEndian) {
    const buf2 = alloc2(4);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setFloat32(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  getFloat64(byteOffset, littleEndian) {
    const buf2 = this.subarray(byteOffset, byteOffset + 8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    return view6.getFloat64(0, littleEndian);
  }
  setFloat64(byteOffset, value, littleEndian) {
    const buf2 = alloc2(8);
    const view6 = new DataView(buf2.buffer, buf2.byteOffset, buf2.byteLength);
    view6.setFloat64(0, value, littleEndian);
    this.write(buf2, byteOffset);
  }
  equals(other) {
    if (other == null) {
      return false;
    }
    if (!(other instanceof _Uint8ArrayList)) {
      return false;
    }
    if (other.bufs.length !== this.bufs.length) {
      return false;
    }
    for (let i = 0; i < this.bufs.length; i++) {
      if (!equals5(this.bufs[i], other.bufs[i])) {
        return false;
      }
    }
    return true;
  }
  /**
   * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
   * method if you know the total size of all the Uint8Arrays ahead of time.
   */
  static fromUint8Arrays(bufs, length4) {
    const list7 = new _Uint8ArrayList();
    list7.bufs = bufs;
    if (length4 == null) {
      length4 = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
    }
    list7.length = length4;
    return list7;
  }
};

// ../../node_modules/.pnpm/carstream@2.2.0/node_modules/carstream/src/varint.js
var MSB4 = 128;
var REST4 = 127;
var MSBALL4 = ~REST4;
var INT4 = Math.pow(2, 31);
var encode33 = (num) => {
  const out = [];
  let offset2 = 0;
  while (num >= INT4) {
    out[offset2++] = num & 255 | MSB4;
    num /= 128;
  }
  while (num & MSBALL4) {
    out[offset2++] = num & 255 | MSB4;
    num >>>= 7;
  }
  out[offset2] = num | 0;
  return out;
};
var decode40 = (buf2, offset2) => {
  let res = 0;
  offset2 = offset2 || 0;
  let shift = 0;
  let counter = offset2;
  let b;
  const l = buf2.length;
  do {
    if (counter >= l || shift > 49) throw new RangeError("Could not decode varint");
    b = buf2.get(counter++);
    res += shift < 28 ? (b & REST4) << shift : (b & REST4) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB4);
  return [res, counter - offset2];
};

// ../../node_modules/.pnpm/carstream@2.2.0/node_modules/carstream/src/reader.js
var State = {
  ReadHeaderLength: 0,
  ReadHeader: 1,
  ReadBlockLength: 2,
  ReadBlock: 3
};
var CIDV0_BYTES2 = {
  SHA2_256: 18,
  LENGTH: 32,
  DAG_PB: 112
};
var _headerPromise;
var CARReaderStream = class extends TransformStream {
  /**
   * @param {QueuingStrategy<Uint8Array>} [writableStrategy]
   * An object that optionally defines a queuing strategy for the stream.
   * @param {QueuingStrategy<import('./api.js').Block & import('./api.js').Position>} [readableStrategy]
   * An object that optionally defines a queuing strategy for the stream.
   * Defaults to a CountQueuingStrategy with highWaterMark of `1` to allow
   * `getHeader` to be called before the stream is consumed.
   */
  constructor(writableStrategy, readableStrategy) {
    const buffer2 = new Uint8ArrayList();
    let offset2 = 0;
    let prevOffset = offset2;
    let wanted = 8;
    let state = State.ReadHeaderLength;
    let resolveHeader;
    const headerPromise = new Promise((resolve) => {
      resolveHeader = resolve;
    });
    super({
      transform(chunk, controller) {
        buffer2.append(chunk);
        while (true) {
          if (buffer2.length < wanted) break;
          if (state === State.ReadHeaderLength) {
            const [length4, bytes2] = decode40(buffer2);
            buffer2.consume(bytes2);
            prevOffset = offset2;
            offset2 += bytes2;
            state = State.ReadHeader;
            wanted = length4;
          } else if (state === State.ReadHeader) {
            const header = decode6(buffer2.slice(0, wanted));
            resolveHeader && resolveHeader(header);
            buffer2.consume(wanted);
            prevOffset = offset2;
            offset2 += wanted;
            state = State.ReadBlockLength;
            wanted = 8;
          } else if (state === State.ReadBlockLength) {
            const [length4, bytes2] = decode40(buffer2);
            buffer2.consume(bytes2);
            prevOffset = offset2;
            offset2 += bytes2;
            state = State.ReadBlock;
            wanted = length4;
          } else if (state === State.ReadBlock) {
            const _offset = prevOffset;
            const length4 = offset2 - prevOffset + wanted;
            prevOffset = offset2;
            let cid;
            if (buffer2.get(0) === CIDV0_BYTES2.SHA2_256 && buffer2.get(1) === CIDV0_BYTES2.LENGTH) {
              const bytes3 = buffer2.subarray(0, 34);
              const multihash = decode5(bytes3);
              cid = createLegacy2(multihash);
              buffer2.consume(34);
              offset2 += 34;
            } else {
              const [version2, versionBytes] = decode40(buffer2);
              if (version2 !== 1) throw new Error(`unexpected CID version (${version2})`);
              buffer2.consume(versionBytes);
              offset2 += versionBytes;
              const [codec, codecBytes] = decode40(buffer2);
              buffer2.consume(codecBytes);
              offset2 += codecBytes;
              const multihashBytes = getMultihashLength2(buffer2);
              const multihash = decode5(buffer2.subarray(0, multihashBytes));
              cid = create17(codec, multihash);
              buffer2.consume(multihashBytes);
              offset2 += multihashBytes;
            }
            const blockBytes = wanted - (offset2 - prevOffset);
            const bytes2 = buffer2.subarray(0, blockBytes);
            controller.enqueue({ cid, bytes: bytes2, offset: _offset, length: length4, blockOffset: offset2, blockLength: blockBytes });
            buffer2.consume(blockBytes);
            prevOffset = offset2;
            offset2 += blockBytes;
            state = State.ReadBlockLength;
            wanted = 8;
          }
        }
      },
      flush(controller) {
        if (state !== State.ReadBlockLength) {
          controller.error(new Error("unexpected end of data"));
        }
      }
    }, writableStrategy, readableStrategy ?? new CountQueuingStrategy({ highWaterMark: 1 }));
    /** @type {Promise<import('./api.js').CARHeader>} */
    __privateAdd(this, _headerPromise);
    __privateSet(this, _headerPromise, headerPromise);
  }
  /**
   * Get the decoded CAR header.
   */
  getHeader() {
    return __privateGet(this, _headerPromise);
  }
};
_headerPromise = new WeakMap();
var getMultihashLength2 = (bytes2) => {
  const [, codeBytes] = decode40(bytes2);
  const [length4, lengthBytes] = decode40(bytes2, codeBytes);
  return codeBytes + lengthBytes + length4;
};

// ../../node_modules/.pnpm/carstream@2.2.0/node_modules/carstream/src/writer.js
var encodeHeader2 = (roots) => {
  const headerBytes = encode4({ version: 1, roots });
  const varintBytes = encode33(headerBytes.length);
  const header = new Uint8Array(varintBytes.length + headerBytes.length);
  header.set(varintBytes, 0);
  header.set(headerBytes, varintBytes.length);
  return header;
};
var encodeBlock = (block) => {
  const varintBytes = encode33(block.cid.bytes.length + block.bytes.length);
  const bytes2 = new Uint8Array(varintBytes.length + block.cid.bytes.length + block.bytes.length);
  bytes2.set(varintBytes);
  bytes2.set(block.cid.bytes, varintBytes.length);
  bytes2.set(block.bytes, varintBytes.length + block.cid.bytes.length);
  return bytes2;
};
var CARWriterStream = class extends TransformStream {
  /**
   * @param {import('multiformats').UnknownLink[]} [roots]
   * @param {QueuingStrategy<import('./api.js').Block>} [writableStrategy]
   * @param {QueuingStrategy<Uint8Array>} [readableStrategy]
   */
  constructor(roots = [], writableStrategy, readableStrategy) {
    super({
      start: (controller) => controller.enqueue(encodeHeader2(roots)),
      transform: (block, controller) => controller.enqueue(encodeBlock(block))
    }, writableStrategy, readableStrategy);
  }
};

// ../../node_modules/.pnpm/@web3-storage+blob-index@1.0.4/node_modules/@web3-storage/blob-index/dist/src/util.js
async function indexShardedDAG(root2, shards, shardIndexes) {
  const index2 = create18(root2);
  for (const [i, shard] of shards.entries()) {
    const slices = shardIndexes[i];
    index2.shards.set(shard.multihash, slices);
  }
  return await index2.archive();
}

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/sharding.js
var SHARD_SIZE = 133169152;
var ShardingStream = class extends TransformStream {
  /**
   * @param {import('./types.js').ShardingOptions} [options]
   */
  constructor(options = {}) {
    const shardSize = options.shardSize ?? SHARD_SIZE;
    const maxBlockLength = shardSize - headerEncodingLength();
    let blocks = [];
    let readyBlocks = null;
    let slices = new DigestMap();
    let readySlices = null;
    let currentLength = 0;
    super({
      async transform(block, controller) {
        if (readyBlocks != null && readySlices != null) {
          controller.enqueue(await encodeCAR(readyBlocks, readySlices));
          readyBlocks = null;
          readySlices = null;
        }
        const blockHeaderLength = blockHeaderEncodingLength(block);
        const blockLength2 = blockHeaderLength + block.bytes.length;
        if (blockLength2 > maxBlockLength) {
          throw new Error(`block will cause CAR to exceed shard size: ${block.cid}`);
        }
        if (blocks.length && currentLength + blockLength2 > maxBlockLength) {
          readyBlocks = blocks;
          readySlices = slices;
          blocks = [];
          slices = new DigestMap();
          currentLength = 0;
        }
        blocks.push(block);
        slices.set(block.cid.multihash, [
          headerEncodingLength() + currentLength + blockHeaderLength,
          block.bytes.length
        ]);
        currentLength += blockLength2;
      },
      async flush(controller) {
        if (readyBlocks != null && readySlices != null) {
          controller.enqueue(await encodeCAR(readyBlocks, readySlices));
        }
        const rootBlock = blocks.at(-1);
        if (rootBlock == null)
          return;
        const rootCID = options.rootCID ?? rootBlock.cid;
        const headerLength2 = headerEncodingLength(rootCID);
        if (headerLength2 + currentLength > shardSize) {
          const overage = headerLength2 + currentLength - shardSize;
          const overflowBlocks = [];
          let overflowCurrentLength = 0;
          while (overflowCurrentLength < overage) {
            const block = blocks[blocks.length - 1];
            blocks.pop();
            slices.delete(block.cid.multihash);
            overflowBlocks.unshift(block);
            overflowCurrentLength += blockEncodingLength(block);
            if (blocks.length < 1)
              throw new Error(`block will cause CAR to exceed shard size: ${block.cid}`);
          }
          controller.enqueue(await encodeCAR(blocks, slices));
          overflowCurrentLength = 0;
          const overflowSlices = new DigestMap();
          for (const block of blocks) {
            const overflowBlockHeaderLength = blockHeaderEncodingLength(block);
            overflowSlices.set(block.cid.multihash, [
              headerLength2 + overflowCurrentLength + overflowBlockHeaderLength,
              block.bytes.length
            ]);
            overflowCurrentLength += overflowBlockHeaderLength + block.bytes.length;
          }
          controller.enqueue(await encodeCAR(overflowBlocks, overflowSlices, rootCID));
        } else {
          const diff = headerLength2 - headerEncodingLength();
          for (const slice3 of slices.values()) {
            slice3[0] += diff;
          }
          controller.enqueue(await encodeCAR(blocks, slices, rootCID));
        }
      }
    });
  }
};
var defaultFileComparator = (a, b, getComparedValue = (file) => file.name) => {
  return ascending(a, b, getComparedValue);
};
function ascending(a, b, getComparedValue) {
  const ask = getComparedValue(a);
  const bsk = getComparedValue(b);
  if (ask === bsk)
    return 0;
  else if (ask < bsk)
    return -1;
  return 1;
}
var encodeCAR = async (blocks, slices, root2) => Object.assign(await encode30(blocks, root2), { slices });

// ../../node_modules/.pnpm/@web3-storage+upload-client@17.0.1/node_modules/@web3-storage/upload-client/dist/src/index.js
async function uploadFile(conf, file, options = {}) {
  return await uploadBlockStream(conf, createFileEncoderStream(file, options), options);
}
async function uploadDirectory(conf, files, options = {}) {
  const { customOrder = false } = options;
  const entries3 = customOrder ? files : [...files].sort(defaultFileComparator);
  return await uploadBlockStream(conf, createDirectoryEncoderStream(entries3, options), options);
}
async function uploadCAR(conf, car, options = {}) {
  const blocks = new BlockStream(car);
  options.rootCID = options.rootCID ?? (await blocks.getRoots())[0];
  return await uploadBlockStream(conf, blocks, options);
}
async function uploadBlockStream(conf, blocks, { pieceHasher = multihash_exports, ...options } = {}) {
  const configure6 = typeof conf === "function" ? conf : () => conf;
  const shardIndexes = [];
  const shards = [];
  let root2 = null;
  await blocks.pipeThrough(new ShardingStream(options)).pipeThrough(
    /** @type {TransformStream<import('./types.js').IndexedCARFile, import('./types.js').CARMetadata>} */
    new TransformStream({
      async transform(car, controller) {
        const bytes2 = new Uint8Array(await car.arrayBuffer());
        const digest5 = await sha2563.digest(bytes2);
        const conf2 = await configure6([
          {
            can: ability,
            nb: input(digest5, bytes2.length)
          }
        ]);
        await add4(conf2, digest5, bytes2, options);
        const cid = create10(code17, digest5);
        let piece;
        if (pieceHasher) {
          const multihashDigest = await pieceHasher.digest(bytes2);
          piece = create10(code10, multihashDigest);
          const content2 = create10(code10, digest5);
          const result = await storefront_exports.filecoinOffer({
            issuer: conf2.issuer,
            audience: conf2.audience,
            // Resource of invocation is the issuer did for being self issued
            with: conf2.issuer.did(),
            proofs: conf2.proofs
          }, content2, piece, options);
          if (result.out.error) {
            throw new Error("failed to offer piece for aggregation into filecoin deal", { cause: result.out.error });
          }
        }
        const { version: version2, roots, size: size5, slices } = car;
        controller.enqueue({ version: version2, roots, size: size5, cid, piece, slices });
      }
    })
  ).pipeTo(new WritableStream({
    write(meta) {
      root2 = root2 || meta.roots[0];
      shards.push(meta.cid);
      meta.slices.set(meta.cid.multihash, [0, meta.size]);
      shardIndexes.push(meta.slices);
      if (options.onShardStored)
        options.onShardStored(meta);
    }
  }));
  if (!root2)
    throw new Error("missing root CID");
  const indexBytes = await indexShardedDAG(root2, shards, shardIndexes);
  if (!indexBytes.ok) {
    throw new Error("failed to archive DAG index", { cause: indexBytes.error });
  }
  const indexDigest = await sha2563.digest(indexBytes.ok);
  const indexLink = create10(code17, indexDigest);
  const [blobAddConf, indexAddConf, uploadAddConf] = await Promise.all([
    configure6([
      {
        can: ability,
        nb: input(indexDigest, indexBytes.ok.length)
      }
    ]),
    configure6([
      {
        can: ability5,
        nb: input5(indexLink)
      }
    ]),
    configure6([
      {
        can: ability6,
        nb: input6(root2, shards)
      }
    ])
  ]);
  await add4(blobAddConf, indexDigest, indexBytes.ok, options);
  await add6(indexAddConf, indexLink, options);
  await add8(uploadAddConf, root2, shards, options);
  return root2;
}

export {
  base323 as base32,
  receiptsEndpoint,
  store_exports,
  receipts_exports,
  blob_exports3 as blob_exports,
  index_exports2 as index_exports,
  upload_exports2 as upload_exports,
  unixfs_exports3 as unixfs_exports,
  car_exports3 as car_exports,
  ShardingStream,
  defaultFileComparator,
  uploadFile,
  uploadDirectory,
  uploadCAR
};
/*! Bundled license information:

@noble/ed25519/lib/esm/index.js:
  (*! noble-ed25519 - MIT License (c) 2019 Paul Miller (paulmillr.com) *)
*/
